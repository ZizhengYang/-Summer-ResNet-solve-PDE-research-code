{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special\n",
    "\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import exp,arange\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sin(\\pi x) e^{-\\pi^2 t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_equ_analytical_solu(x, t):\n",
    "    return np.sin(np.pi * x) * np.exp(-np.power(np.pi, 2) * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# save and load: json\n",
    "# ============\n",
    "\n",
    "def save_json(save_path, data):\n",
    "    assert save_path.split('.')[-1] == 'json'\n",
    "    with open(save_path,'w+') as file:\n",
    "        json.dump(data,file)\n",
    "\n",
    "def load_json(file_path):\n",
    "    assert file_path.split('.')[-1] == 'json'\n",
    "    with open(file_path,'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# ============\n",
    "# save and load: csv\n",
    "# ============\n",
    "\n",
    "def save_csv(save_path, data):\n",
    "    with open(save_path, \"w+\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def load_csv(file_path):\n",
    "    string = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            if i%2==0:\n",
    "                string.append(row)\n",
    "    ret = []\n",
    "    for p in string:\n",
    "        ret.append(np.array([float(i) for i in p]))\n",
    "    return ret\n",
    "\n",
    "# ==============\n",
    "# save and load: normal\n",
    "# ==============\n",
    "\n",
    "def save_list(save_path, data):\n",
    "    file = open(save_path, 'w+')\n",
    "    for value in data:\n",
    "        file.write(str(value)+\" \")\n",
    "    file.close()\n",
    "\n",
    "# def load_list(file_path):\n",
    "\n",
    "# ==========\n",
    "# make directory\n",
    "# ==========\n",
    "\n",
    "def mkdir(folder_name):\n",
    "    folder = os.path.exists(folder_name)\n",
    "    if not folder:\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======\n",
    "# OPTIONS\n",
    "# =======\n",
    "\n",
    "# ===========\n",
    "# padding method\n",
    "# ===========\n",
    "\n",
    "def padding(starting_padding, original, end_padding):\n",
    "    return np.hstack((starting_padding, original, end_padding)).tolist()\n",
    "\n",
    "def zero_padding(original, num1, num2):\n",
    "    starting_padding = [0 for i in range(num1)]\n",
    "    end_padding = [0 for i in range(num2)]\n",
    "    return padding(starting_padding, original, end_padding)\n",
    "\n",
    "def border_padding(original, num1, num2):\n",
    "    starting = original[0]\n",
    "    ending = original[len(original)-1]\n",
    "    starting_padding = [starting for i in range(num1)]\n",
    "    end_padding = [ending for i in range(num2)]\n",
    "    return padding(starting_padding, original, end_padding)\n",
    "\n",
    "def recursive_padding(original, num1, num2):\n",
    "    starting_padding = original[-num1:]\n",
    "    end_padding = original[:num2]\n",
    "    return padding(starting_padding, original, end_padding)\n",
    "\n",
    "def random_padding(original, num1, num2):\n",
    "    max_value = np.max(original)\n",
    "    min_value = np.min(original)\n",
    "    starting_padding = [random.randint(min_value, max_value) for i in range(num1)]\n",
    "    end_padding = [random.randint(min_value, max_value) for i in range(num2)]\n",
    "    return padding(starting_padding, original, end_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4,5,6,7,8,9,10]\n",
    "recursive_padding(a, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======\n",
    "# OPTIONS\n",
    "# =======\n",
    "\n",
    "# ==================\n",
    "# analytical solution generator\n",
    "# ==================\n",
    "\n",
    "def gen_analytical(delta_x, delta_t, xmin, tmin, xmax, tmax, analytical_eq):\n",
    "    x = arange(xmin, xmax+delta_x, delta_x)\n",
    "    t = arange(tmin, tmax+delta_t, delta_t)\n",
    "    X,T = meshgrid(x, t) # grid of point\n",
    "    solu = analytical_eq(X, T) # evaluation of the function on the grid\n",
    "    return x, t, solu\n",
    "\n",
    "def gen_analytical_averaged(delta_x, delta_t, xmin, tmin, xmax, tmax, analytical_eq):\n",
    "    x = arange(xmin, xmax+delta_x, delta_x)\n",
    "    t = arange(tmin, tmax+delta_t, delta_t)\n",
    "    X,T = meshgrid(x, t) # grid of point\n",
    "    Z = analytical_eq(X, T) # evaluation of the function on the grid\n",
    "    solu = []\n",
    "    for zz in Z:\n",
    "        solu_t = []\n",
    "        for j in range(len(zz)-1):\n",
    "            value = (1/2) * (zz[j] + zz[j+1])\n",
    "            solu_t.append(value)\n",
    "        solu.append(solu_t)\n",
    "    return x, t, solu\n",
    "\n",
    "def gen_analytical_cell_averaged(delta_x, delta_t, xmin, tmin, xmax, tmax, analytical_eq):\n",
    "    x = arange(xmin, xmax+delta_x, delta_x)\n",
    "    t = arange(tmin, tmax+delta_t, delta_t)\n",
    "    solu = []\n",
    "    for ti in range(len(t)):\n",
    "        solu_t = []\n",
    "        for j in range(len(x)-1):\n",
    "            value = integrate.quad(lambda x: analytical_eq(x, t[ti]), x[j], x[j+1])\n",
    "            value = value[0] * (1/delta_x)\n",
    "            solu_t.append(value)\n",
    "        solu.append(solu_t)\n",
    "    return x, t, solu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======\n",
    "# OPTIONS\n",
    "# =======\n",
    "\n",
    "# ===========\n",
    "# training set\n",
    "# ===========\n",
    "\n",
    "def get_trainingset_random(solu, num1, num2, padding, size):\n",
    "    solu_padding = []\n",
    "    pairs = []\n",
    "    for item in solu:\n",
    "        p = padding(item, num1, num2)\n",
    "        solu_padding.append(p)\n",
    "    for iteration in range(size):\n",
    "        t_index = random.randint(0, len(solu_padding)-2)\n",
    "        x_index = random.randint(0, len(p)-num1-num2-1)\n",
    "        time = solu_padding[t_index]\n",
    "        time_next = solu_padding[t_index+1]\n",
    "        train = time[x_index: x_index+num1+num2+1]\n",
    "        target = time_next[x_index+num1]\n",
    "        pair = {'train': train, 'target': target}\n",
    "        pairs.append(pair)\n",
    "    return pairs\n",
    "    \n",
    "def get_trainingset_all(solu, num1, num2, padding):\n",
    "    solu_cutted = solu[:-1]\n",
    "    pairs = []\n",
    "    for index, item in enumerate(solu_cutted):\n",
    "        p = padding(item, num1, num2)\n",
    "        p_next = padding(solu[index+1], num1, num2)\n",
    "        for xi in range(len(p)-num1-num2):\n",
    "            train = p[xi: xi+num1+num2+1]\n",
    "            target = p_next[xi+num1]\n",
    "            pair = {'train': train, 'target': target}\n",
    "            pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "# ===========\n",
    "#  testing set\n",
    "# ===========\n",
    "\n",
    "def get_testingset_random(solu, num1, num2, padding, size):\n",
    "    return get_trainingset_random(solu, num1, num2, padding, size)\n",
    "\n",
    "def get_testingset_all(solu, num1, num2, padding):\n",
    "    solu_cutted = solu[:-1]\n",
    "    pairs = []\n",
    "    for index, item in enumerate(solu_cutted):\n",
    "        p = padding(item, num1, num2)\n",
    "        p_next = padding(solu[index+1], num1, num2)\n",
    "        pairs_t = []\n",
    "        for xi in range(len(p)-num1-num2):\n",
    "            train = p[xi:xi+num1+num2+1]\n",
    "            target = p_next[xi+num1]\n",
    "            pair = {'train': train, 'target': target}\n",
    "            pairs_t.append(pair)\n",
    "        pairs.append(pairs_t)\n",
    "    return pairs\n",
    "\n",
    "# x, t, solu = gen_analytical_cell_averaged(delta_x=1/10, delta_t=1/20, xmin=0, tmin=0, xmax=1, tmax=2, analytical_eq=heat_equ_analytical_solu)\n",
    "# pairs = get_testingset_all(solu, 3, 3, recursive_padding)\n",
    "# for i, p in enumerate(pairs[0]):\n",
    "#     print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15579194727527879, 0.45212584056020866, 0.7042025064251416, 0.8873469244938119, 0.9836316430834657, 0.9836316430834668, 0.8873469244938119, 0.7042025064251412, 0.45212584056020827, 0.155791947275279, -0.15579194727527892, -0.45212584056020916, -0.7042025064251403, -0.8873469244938128, -0.9836316430834647, -0.983631643083467, -0.8873469244938128, -0.7042025064251405, -0.45212584056020905, -0.15579194727527823]\n",
      "0 {'train': [-0.7042025064251405, -0.45212584056020905, -0.15579194727527823, 0.15579194727527879, 0.45212584056020866, 0.7042025064251416, 0.8873469244938119], 'target': 0.09511067616387091}\n",
      "1 {'train': [-0.45212584056020905, -0.15579194727527823, 0.15579194727527879, 0.45212584056020866, 0.7042025064251416, 0.8873469244938119, 0.9836316430834657], 'target': 0.27602193283364607}\n",
      "2 {'train': [-0.15579194727527823, 0.15579194727527879, 0.45212584056020866, 0.7042025064251416, 0.8873469244938119, 0.9836316430834657, 0.9836316430834668], 'target': 0.42991423955977376}\n",
      "3 {'train': [0.15579194727527879, 0.45212584056020866, 0.7042025064251416, 0.8873469244938119, 0.9836316430834657, 0.9836316430834668, 0.8873469244938119], 'target': 0.5417235451291507}\n",
      "4 {'train': [0.45212584056020866, 0.7042025064251416, 0.8873469244938119, 0.9836316430834657, 0.9836316430834668, 0.8873469244938119, 0.7042025064251412], 'target': 0.6005051756914073}\n",
      "5 {'train': [0.7042025064251416, 0.8873469244938119, 0.9836316430834657, 0.9836316430834668, 0.8873469244938119, 0.7042025064251412, 0.45212584056020827], 'target': 0.600505175691408}\n",
      "6 {'train': [0.8873469244938119, 0.9836316430834657, 0.9836316430834668, 0.8873469244938119, 0.7042025064251412, 0.45212584056020827, 0.155791947275279], 'target': 0.5417235451291506}\n",
      "7 {'train': [0.9836316430834657, 0.9836316430834668, 0.8873469244938119, 0.7042025064251412, 0.45212584056020827, 0.155791947275279, -0.15579194727527892], 'target': 0.42991423955977354}\n",
      "8 {'train': [0.9836316430834668, 0.8873469244938119, 0.7042025064251412, 0.45212584056020827, 0.155791947275279, -0.15579194727527892, -0.45212584056020916], 'target': 0.27602193283364584}\n",
      "9 {'train': [0.8873469244938119, 0.7042025064251412, 0.45212584056020827, 0.155791947275279, -0.15579194727527892, -0.45212584056020916, -0.7042025064251403], 'target': 0.09511067616387103}\n",
      "10 {'train': [0.7042025064251412, 0.45212584056020827, 0.155791947275279, -0.15579194727527892, -0.45212584056020916, -0.7042025064251403, -0.8873469244938128], 'target': -0.09511067616387099}\n",
      "11 {'train': [0.45212584056020827, 0.155791947275279, -0.15579194727527892, -0.45212584056020916, -0.7042025064251403, -0.8873469244938128, -0.9836316430834647], 'target': -0.2760219328336464}\n",
      "12 {'train': [0.155791947275279, -0.15579194727527892, -0.45212584056020916, -0.7042025064251403, -0.8873469244938128, -0.9836316430834647, -0.983631643083467], 'target': -0.42991423955977304}\n",
      "13 {'train': [-0.15579194727527892, -0.45212584056020916, -0.7042025064251403, -0.8873469244938128, -0.9836316430834647, -0.983631643083467, -0.8873469244938128], 'target': -0.5417235451291512}\n",
      "14 {'train': [-0.45212584056020916, -0.7042025064251403, -0.8873469244938128, -0.9836316430834647, -0.983631643083467, -0.8873469244938128, -0.7042025064251405], 'target': -0.6005051756914067}\n",
      "15 {'train': [-0.7042025064251403, -0.8873469244938128, -0.9836316430834647, -0.983631643083467, -0.8873469244938128, -0.7042025064251405, -0.45212584056020905], 'target': -0.600505175691408}\n",
      "16 {'train': [-0.8873469244938128, -0.9836316430834647, -0.983631643083467, -0.8873469244938128, -0.7042025064251405, -0.45212584056020905, -0.15579194727527823], 'target': -0.5417235451291511}\n",
      "17 {'train': [-0.9836316430834647, -0.983631643083467, -0.8873469244938128, -0.7042025064251405, -0.45212584056020905, -0.15579194727527823, 0.15579194727527879], 'target': -0.42991423955977304}\n",
      "18 {'train': [-0.983631643083467, -0.8873469244938128, -0.7042025064251405, -0.45212584056020905, -0.15579194727527823, 0.15579194727527879, 0.45212584056020866], 'target': -0.27602193283364623}\n",
      "19 {'train': [-0.8873469244938128, -0.7042025064251405, -0.45212584056020905, -0.15579194727527823, 0.15579194727527879, 0.45212584056020866, 0.7042025064251416], 'target': -0.09511067616387056}\n",
      "20 {'train': [-0.42991423955977304, -0.27602193283364623, -0.09511067616387056, 0.09511067616387091, 0.27602193283364607, 0.42991423955977376, 0.5417235451291507], 'target': 0.0580648799797379}\n",
      "21 {'train': [-0.27602193283364623, -0.09511067616387056, 0.09511067616387091, 0.27602193283364607, 0.42991423955977376, 0.5417235451291507, 0.6005051756914073], 'target': 0.16851084492498944}\n",
      "22 {'train': [-0.09511067616387056, 0.09511067616387091, 0.27602193283364607, 0.42991423955977376, 0.5417235451291507, 0.6005051756914073, 0.600505175691408], 'target': 0.26246179428488875}\n",
      "23 {'train': [0.09511067616387091, 0.27602193283364607, 0.42991423955977376, 0.5417235451291507, 0.6005051756914073, 0.600505175691408, 0.5417235451291506], 'target': 0.33072115454133344}\n",
      "24 {'train': [0.27602193283364607, 0.42991423955977376, 0.5417235451291507, 0.6005051756914073, 0.600505175691408, 0.5417235451291506, 0.42991423955977354], 'target': 0.3666072239214947}\n",
      "25 {'train': [0.42991423955977376, 0.5417235451291507, 0.6005051756914073, 0.600505175691408, 0.5417235451291506, 0.42991423955977354, 0.27602193283364584], 'target': 0.36660722392149514}\n",
      "26 {'train': [0.5417235451291507, 0.6005051756914073, 0.600505175691408, 0.5417235451291506, 0.42991423955977354, 0.27602193283364584, 0.09511067616387103], 'target': 0.33072115454133333}\n",
      "27 {'train': [0.6005051756914073, 0.600505175691408, 0.5417235451291506, 0.42991423955977354, 0.27602193283364584, 0.09511067616387103, -0.09511067616387099], 'target': 0.2624617942848886}\n",
      "28 {'train': [0.600505175691408, 0.5417235451291506, 0.42991423955977354, 0.27602193283364584, 0.09511067616387103, -0.09511067616387099, -0.2760219328336464], 'target': 0.1685108449249893}\n",
      "29 {'train': [0.5417235451291506, 0.42991423955977354, 0.27602193283364584, 0.09511067616387103, -0.09511067616387099, -0.2760219328336464, -0.42991423955977304], 'target': 0.05806487997973799}\n",
      "30 {'train': [0.42991423955977354, 0.27602193283364584, 0.09511067616387103, -0.09511067616387099, -0.2760219328336464, -0.42991423955977304, -0.5417235451291512], 'target': -0.058064879979737964}\n",
      "31 {'train': [0.27602193283364584, 0.09511067616387103, -0.09511067616387099, -0.2760219328336464, -0.42991423955977304, -0.5417235451291512, -0.6005051756914067], 'target': -0.16851084492498963}\n",
      "32 {'train': [0.09511067616387103, -0.09511067616387099, -0.2760219328336464, -0.42991423955977304, -0.5417235451291512, -0.6005051756914067, -0.600505175691408], 'target': -0.26246179428488825}\n",
      "33 {'train': [-0.09511067616387099, -0.2760219328336464, -0.42991423955977304, -0.5417235451291512, -0.6005051756914067, -0.600505175691408, -0.5417235451291511], 'target': -0.3307211545413338}\n",
      "34 {'train': [-0.2760219328336464, -0.42991423955977304, -0.5417235451291512, -0.6005051756914067, -0.600505175691408, -0.5417235451291511, -0.42991423955977304], 'target': -0.3666072239214943}\n",
      "35 {'train': [-0.42991423955977304, -0.5417235451291512, -0.6005051756914067, -0.600505175691408, -0.5417235451291511, -0.42991423955977304, -0.27602193283364623], 'target': -0.36660722392149514}\n",
      "36 {'train': [-0.5417235451291512, -0.6005051756914067, -0.600505175691408, -0.5417235451291511, -0.42991423955977304, -0.27602193283364623, -0.09511067616387056], 'target': -0.3307211545413338}\n",
      "37 {'train': [-0.6005051756914067, -0.600505175691408, -0.5417235451291511, -0.42991423955977304, -0.27602193283364623, -0.09511067616387056, 0.09511067616387091], 'target': -0.26246179428488836}\n",
      "38 {'train': [-0.600505175691408, -0.5417235451291511, -0.42991423955977304, -0.27602193283364623, -0.09511067616387056, 0.09511067616387091, 0.27602193283364607], 'target': -0.16851084492498952}\n",
      "39 {'train': [-0.5417235451291511, -0.42991423955977304, -0.27602193283364623, -0.09511067616387056, 0.09511067616387091, 0.27602193283364607, 0.42991423955977376], 'target': -0.058064879979737694}\n",
      "40 {'train': [-0.26246179428488836, -0.16851084492498952, -0.058064879979737694, 0.0580648799797379, 0.16851084492498944, 0.26246179428488875, 0.33072115454133344], 'target': 0.03544849456492551}\n",
      "41 {'train': [-0.16851084492498952, -0.058064879979737694, 0.0580648799797379, 0.16851084492498944, 0.26246179428488875, 0.33072115454133344, 0.3666072239214947], 'target': 0.10287553806257702}\n",
      "42 {'train': [-0.058064879979737694, 0.0580648799797379, 0.16851084492498944, 0.26246179428488875, 0.33072115454133344, 0.3666072239214947, 0.36660722392149514], 'target': 0.16023240711864242}\n",
      "43 {'train': [0.0580648799797379, 0.16851084492498944, 0.26246179428488875, 0.33072115454133344, 0.3666072239214947, 0.36660722392149514, 0.33072115454133333], 'target': 0.20190461176110852}\n",
      "44 {'train': [0.16851084492498944, 0.26246179428488875, 0.33072115454133344, 0.3666072239214947, 0.36660722392149514, 0.33072115454133333, 0.2624617942848886], 'target': 0.22381298625224844}\n",
      "45 {'train': [0.26246179428488875, 0.33072115454133344, 0.3666072239214947, 0.36660722392149514, 0.33072115454133333, 0.2624617942848886, 0.1685108449249893], 'target': 0.22381298625224869}\n",
      "46 {'train': [0.33072115454133344, 0.3666072239214947, 0.36660722392149514, 0.33072115454133333, 0.2624617942848886, 0.1685108449249893, 0.05806487997973799], 'target': 0.20190461176110852}\n",
      "47 {'train': [0.3666072239214947, 0.36660722392149514, 0.33072115454133333, 0.2624617942848886, 0.1685108449249893, 0.05806487997973799, -0.058064879979737964], 'target': 0.1602324071186423}\n",
      "48 {'train': [0.36660722392149514, 0.33072115454133333, 0.2624617942848886, 0.1685108449249893, 0.05806487997973799, -0.058064879979737964, -0.16851084492498963], 'target': 0.10287553806257692}\n",
      "49 {'train': [0.33072115454133333, 0.2624617942848886, 0.1685108449249893, 0.05806487997973799, -0.058064879979737964, -0.16851084492498963, -0.26246179428488825], 'target': 0.035448494564925555}\n",
      "50 {'train': [0.2624617942848886, 0.1685108449249893, 0.05806487997973799, -0.058064879979737964, -0.16851084492498963, -0.26246179428488825, -0.3307211545413338], 'target': -0.03544849456492554}\n",
      "51 {'train': [0.1685108449249893, 0.05806487997973799, -0.058064879979737964, -0.16851084492498963, -0.26246179428488825, -0.3307211545413338, -0.3666072239214943], 'target': -0.10287553806257711}\n",
      "52 {'train': [0.05806487997973799, -0.058064879979737964, -0.16851084492498963, -0.26246179428488825, -0.3307211545413338, -0.3666072239214943, -0.36660722392149514], 'target': -0.16023240711864215}\n",
      "53 {'train': [-0.058064879979737964, -0.16851084492498963, -0.26246179428488825, -0.3307211545413338, -0.3666072239214943, -0.36660722392149514, -0.3307211545413338], 'target': -0.20190461176110872}\n",
      "54 {'train': [-0.16851084492498963, -0.26246179428488825, -0.3307211545413338, -0.3666072239214943, -0.36660722392149514, -0.3307211545413338, -0.26246179428488836], 'target': -0.2238129862522482}\n",
      "55 {'train': [-0.26246179428488825, -0.3307211545413338, -0.3666072239214943, -0.36660722392149514, -0.3307211545413338, -0.26246179428488836, -0.16851084492498952], 'target': -0.22381298625224869}\n",
      "56 {'train': [-0.3307211545413338, -0.3666072239214943, -0.36660722392149514, -0.3307211545413338, -0.26246179428488836, -0.16851084492498952, -0.058064879979737694], 'target': -0.20190461176110872}\n",
      "57 {'train': [-0.3666072239214943, -0.36660722392149514, -0.3307211545413338, -0.26246179428488836, -0.16851084492498952, -0.058064879979737694, 0.0580648799797379], 'target': -0.16023240711864223}\n",
      "58 {'train': [-0.36660722392149514, -0.3307211545413338, -0.26246179428488836, -0.16851084492498952, -0.058064879979737694, 0.0580648799797379, 0.16851084492498944], 'target': -0.1028755380625771}\n",
      "59 {'train': [-0.3307211545413338, -0.26246179428488836, -0.16851084492498952, -0.058064879979737694, 0.0580648799797379, 0.16851084492498944, 0.26246179428488875], 'target': -0.035448494564925374}\n",
      "60 {'train': [-0.16023240711864223, -0.1028755380625771, -0.035448494564925374, 0.03544849456492551, 0.10287553806257702, 0.16023240711864242, 0.20190461176110852], 'target': 0.021641235930532368}\n",
      "61 {'train': [-0.1028755380625771, -0.035448494564925374, 0.03544849456492551, 0.10287553806257702, 0.16023240711864242, 0.20190461176110852, 0.22381298625224844], 'target': 0.06280531283535962}\n",
      "62 {'train': [-0.035448494564925374, 0.03544849456492551, 0.10287553806257702, 0.16023240711864242, 0.20190461176110852, 0.22381298625224844, 0.22381298625224869], 'target': 0.09782156812951649}\n",
      "63 {'train': [0.03544849456492551, 0.10287553806257702, 0.16023240711864242, 0.20190461176110852, 0.22381298625224844, 0.22381298625224869, 0.20190461176110852], 'target': 0.12326236677221424}\n",
      "64 {'train': [0.10287553806257702, 0.16023240711864242, 0.20190461176110852, 0.22381298625224844, 0.22381298625224869, 0.20190461176110852, 0.1602324071186423], 'target': 0.1366373861358387}\n",
      "65 {'train': [0.16023240711864242, 0.20190461176110852, 0.22381298625224844, 0.22381298625224869, 0.20190461176110852, 0.1602324071186423, 0.10287553806257692], 'target': 0.13663738613583884}\n",
      "66 {'train': [0.20190461176110852, 0.22381298625224844, 0.22381298625224869, 0.20190461176110852, 0.1602324071186423, 0.10287553806257692, 0.035448494564925555], 'target': 0.12326236677221421}\n",
      "67 {'train': [0.22381298625224844, 0.22381298625224869, 0.20190461176110852, 0.1602324071186423, 0.10287553806257692, 0.035448494564925555, -0.03544849456492554], 'target': 0.09782156812951645}\n",
      "68 {'train': [0.22381298625224869, 0.20190461176110852, 0.1602324071186423, 0.10287553806257692, 0.035448494564925555, -0.03544849456492554, -0.10287553806257711], 'target': 0.06280531283535958}\n",
      "69 {'train': [0.20190461176110852, 0.1602324071186423, 0.10287553806257692, 0.035448494564925555, -0.03544849456492554, -0.10287553806257711, -0.16023240711864215], 'target': 0.021641235930532403}\n",
      "70 {'train': [0.1602324071186423, 0.10287553806257692, 0.035448494564925555, -0.03544849456492554, -0.10287553806257711, -0.16023240711864215, -0.20190461176110872], 'target': -0.021641235930532392}\n",
      "71 {'train': [0.10287553806257692, 0.035448494564925555, -0.03544849456492554, -0.10287553806257711, -0.16023240711864215, -0.20190461176110872, -0.2238129862522482], 'target': -0.0628053128353597}\n",
      "72 {'train': [0.035448494564925555, -0.03544849456492554, -0.10287553806257711, -0.16023240711864215, -0.20190461176110872, -0.2238129862522482, -0.22381298625224869], 'target': -0.09782156812951631}\n",
      "73 {'train': [-0.03544849456492554, -0.10287553806257711, -0.16023240711864215, -0.20190461176110872, -0.2238129862522482, -0.22381298625224869, -0.20190461176110872], 'target': -0.12326236677221439}\n",
      "74 {'train': [-0.10287553806257711, -0.16023240711864215, -0.20190461176110872, -0.2238129862522482, -0.22381298625224869, -0.20190461176110872, -0.16023240711864223], 'target': -0.13663738613583856}\n",
      "75 {'train': [-0.16023240711864215, -0.20190461176110872, -0.2238129862522482, -0.22381298625224869, -0.20190461176110872, -0.16023240711864223, -0.1028755380625771], 'target': -0.13663738613583884}\n",
      "76 {'train': [-0.20190461176110872, -0.2238129862522482, -0.22381298625224869, -0.20190461176110872, -0.16023240711864223, -0.1028755380625771, -0.035448494564925374], 'target': -0.12326236677221436}\n",
      "77 {'train': [-0.2238129862522482, -0.22381298625224869, -0.20190461176110872, -0.16023240711864223, -0.1028755380625771, -0.035448494564925374, 0.03544849456492551], 'target': -0.09782156812951635}\n",
      "78 {'train': [-0.22381298625224869, -0.20190461176110872, -0.16023240711864223, -0.1028755380625771, -0.035448494564925374, 0.03544849456492551, 0.10287553806257702], 'target': -0.06280531283535967}\n",
      "79 {'train': [-0.20190461176110872, -0.16023240711864223, -0.1028755380625771, -0.035448494564925374, 0.03544849456492551, 0.10287553806257702, 0.16023240711864242], 'target': -0.02164123593053229}\n",
      "80 {'train': [-0.09782156812951635, -0.06280531283535967, -0.02164123593053229, 0.021641235930532368, 0.06280531283535962, 0.09782156812951649, 0.12326236677221424], 'target': 0.013211931799901233}\n",
      "81 {'train': [-0.06280531283535967, -0.02164123593053229, 0.021641235930532368, 0.06280531283535962, 0.09782156812951649, 0.12326236677221424, 0.1366373861358387], 'target': 0.038342519462187676}\n",
      "82 {'train': [-0.02164123593053229, 0.021641235930532368, 0.06280531283535962, 0.09782156812951649, 0.12326236677221424, 0.1366373861358387, 0.13663738613583884], 'target': 0.05971987417147347}\n",
      "83 {'train': [0.021641235930532368, 0.06280531283535962, 0.09782156812951649, 0.12326236677221424, 0.1366373861358387, 0.13663738613583884, 0.12326236677221421], 'target': 0.0752514315040252}\n",
      "84 {'train': [0.06280531283535962, 0.09782156812951649, 0.12326236677221424, 0.1366373861358387, 0.13663738613583884, 0.12326236677221421, 0.09782156812951645], 'target': 0.08341685441340974}\n",
      "85 {'train': [0.09782156812951649, 0.12326236677221424, 0.1366373861358387, 0.13663738613583884, 0.12326236677221421, 0.09782156812951645, 0.06280531283535958], 'target': 0.08341685441340982}\n",
      "86 {'train': [0.12326236677221424, 0.1366373861358387, 0.13663738613583884, 0.12326236677221421, 0.09782156812951645, 0.06280531283535958, 0.021641235930532403], 'target': 0.0752514315040252}\n",
      "87 {'train': [0.1366373861358387, 0.13663738613583884, 0.12326236677221421, 0.09782156812951645, 0.06280531283535958, 0.021641235930532403, -0.021641235930532392], 'target': 0.05971987417147344}\n",
      "88 {'train': [0.13663738613583884, 0.12326236677221421, 0.09782156812951645, 0.06280531283535958, 0.021641235930532403, -0.021641235930532392, -0.0628053128353597], 'target': 0.038342519462187655}\n",
      "89 {'train': [0.12326236677221421, 0.09782156812951645, 0.06280531283535958, 0.021641235930532403, -0.021641235930532392, -0.0628053128353597, -0.09782156812951631], 'target': 0.013211931799901249}\n",
      "90 {'train': [0.09782156812951645, 0.06280531283535958, 0.021641235930532403, -0.021641235930532392, -0.0628053128353597, -0.09782156812951631, -0.12326236677221439], 'target': -0.013211931799901242}\n",
      "91 {'train': [0.06280531283535958, 0.021641235930532403, -0.021641235930532392, -0.0628053128353597, -0.09782156812951631, -0.12326236677221439, -0.13663738613583856], 'target': -0.038342519462187724}\n",
      "92 {'train': [0.021641235930532403, -0.021641235930532392, -0.0628053128353597, -0.09782156812951631, -0.12326236677221439, -0.13663738613583856, -0.13663738613583884], 'target': -0.059719874171473356}\n",
      "93 {'train': [-0.021641235930532392, -0.0628053128353597, -0.09782156812951631, -0.12326236677221439, -0.13663738613583856, -0.13663738613583884, -0.12326236677221436], 'target': -0.07525143150402529}\n",
      "94 {'train': [-0.0628053128353597, -0.09782156812951631, -0.12326236677221439, -0.13663738613583856, -0.13663738613583884, -0.12326236677221436, -0.09782156812951635], 'target': -0.08341685441340965}\n",
      "95 {'train': [-0.09782156812951631, -0.12326236677221439, -0.13663738613583856, -0.13663738613583884, -0.12326236677221436, -0.09782156812951635, -0.06280531283535967], 'target': -0.08341685441340982}\n",
      "96 {'train': [-0.12326236677221439, -0.13663738613583856, -0.13663738613583884, -0.12326236677221436, -0.09782156812951635, -0.06280531283535967, -0.02164123593053229], 'target': -0.07525143150402529}\n",
      "97 {'train': [-0.13663738613583856, -0.13663738613583884, -0.12326236677221436, -0.09782156812951635, -0.06280531283535967, -0.02164123593053229, 0.021641235930532368], 'target': -0.05971987417147337}\n",
      "98 {'train': [-0.13663738613583884, -0.12326236677221436, -0.09782156812951635, -0.06280531283535967, -0.02164123593053229, 0.021641235930532368, 0.06280531283535962], 'target': -0.0383425194621877}\n",
      "99 {'train': [-0.12326236677221436, -0.09782156812951635, -0.06280531283535967, -0.02164123593053229, 0.021641235930532368, 0.06280531283535962, 0.09782156812951649], 'target': -0.013211931799901183}\n",
      "100 {'train': [-0.05971987417147337, -0.0383425194621877, -0.013211931799901183, 0.013211931799901233, 0.038342519462187676, 0.05971987417147347, 0.0752514315040252], 'target': 0.008065858273786086}\n",
      "101 {'train': [-0.0383425194621877, -0.013211931799901183, 0.013211931799901233, 0.038342519462187676, 0.05971987417147347, 0.0752514315040252, 0.08341685441340974], 'target': 0.023408032415380968}\n",
      "102 {'train': [-0.013211931799901183, 0.013211931799901233, 0.038342519462187676, 0.05971987417147347, 0.0752514315040252, 0.08341685441340974, 0.08341685441340982], 'target': 0.03645886525080641}\n",
      "103 {'train': [0.013211931799901233, 0.038342519462187676, 0.05971987417147347, 0.0752514315040252, 0.08341685441340974, 0.08341685441340982, 0.0752514315040252], 'target': 0.045940850331631776}\n",
      "104 {'train': [0.038342519462187676, 0.05971987417147347, 0.0752514315040252, 0.08341685441340974, 0.08341685441340982, 0.0752514315040252, 0.05971987417147344], 'target': 0.05092582489327112}\n",
      "105 {'train': [0.05971987417147347, 0.0752514315040252, 0.08341685441340974, 0.08341685441340982, 0.0752514315040252, 0.05971987417147344, 0.038342519462187655], 'target': 0.05092582489327118}\n",
      "106 {'train': [0.0752514315040252, 0.08341685441340974, 0.08341685441340982, 0.0752514315040252, 0.05971987417147344, 0.038342519462187655, 0.013211931799901249], 'target': 0.045940850331631755}\n",
      "107 {'train': [0.08341685441340974, 0.08341685441340982, 0.0752514315040252, 0.05971987417147344, 0.038342519462187655, 0.013211931799901249, -0.013211931799901242], 'target': 0.0364588652508064}\n",
      "108 {'train': [0.08341685441340982, 0.0752514315040252, 0.05971987417147344, 0.038342519462187655, 0.013211931799901249, -0.013211931799901242, -0.038342519462187724], 'target': 0.023408032415380944}\n",
      "109 {'train': [0.0752514315040252, 0.05971987417147344, 0.038342519462187655, 0.013211931799901249, -0.013211931799901242, -0.038342519462187724, -0.059719874171473356], 'target': 0.008065858273786098}\n",
      "110 {'train': [0.05971987417147344, 0.038342519462187655, 0.013211931799901249, -0.013211931799901242, -0.038342519462187724, -0.059719874171473356, -0.07525143150402529], 'target': -0.008065858273786093}\n",
      "111 {'train': [0.038342519462187655, 0.013211931799901249, -0.013211931799901242, -0.038342519462187724, -0.059719874171473356, -0.07525143150402529, -0.08341685441340965], 'target': -0.02340803241538099}\n",
      "112 {'train': [0.013211931799901249, -0.013211931799901242, -0.038342519462187724, -0.059719874171473356, -0.07525143150402529, -0.08341685441340965, -0.08341685441340982], 'target': -0.03645886525080635}\n",
      "113 {'train': [-0.013211931799901242, -0.038342519462187724, -0.059719874171473356, -0.07525143150402529, -0.08341685441340965, -0.08341685441340982, -0.07525143150402529], 'target': -0.045940850331631825}\n",
      "114 {'train': [-0.038342519462187724, -0.059719874171473356, -0.07525143150402529, -0.08341685441340965, -0.08341685441340982, -0.07525143150402529, -0.05971987417147337], 'target': -0.05092582489327108}\n",
      "115 {'train': [-0.059719874171473356, -0.07525143150402529, -0.08341685441340965, -0.08341685441340982, -0.07525143150402529, -0.05971987417147337, -0.0383425194621877], 'target': -0.05092582489327118}\n",
      "116 {'train': [-0.07525143150402529, -0.08341685441340965, -0.08341685441340982, -0.07525143150402529, -0.05971987417147337, -0.0383425194621877, -0.013211931799901183], 'target': -0.04594085033163181}\n",
      "117 {'train': [-0.08341685441340965, -0.08341685441340982, -0.07525143150402529, -0.05971987417147337, -0.0383425194621877, -0.013211931799901183, 0.013211931799901233], 'target': -0.03645886525080636}\n",
      "118 {'train': [-0.08341685441340982, -0.07525143150402529, -0.05971987417147337, -0.0383425194621877, -0.013211931799901183, 0.013211931799901233, 0.038342519462187676], 'target': -0.023408032415380982}\n",
      "119 {'train': [-0.07525143150402529, -0.05971987417147337, -0.0383425194621877, -0.013211931799901183, 0.013211931799901233, 0.038342519462187676, 0.05971987417147347], 'target': -0.008065858273786055}\n",
      "120 {'train': [-0.03645886525080636, -0.023408032415380982, -0.008065858273786055, 0.008065858273786086, 0.023408032415380968, 0.03645886525080641, 0.045940850331631776], 'target': 0.004924190548220198}\n",
      "121 {'train': [-0.023408032415380982, -0.008065858273786055, 0.008065858273786086, 0.023408032415380968, 0.03645886525080641, 0.045940850331631776, 0.05092582489327112], 'target': 0.014290557564947846}\n",
      "122 {'train': [-0.008065858273786055, 0.008065858273786086, 0.023408032415380968, 0.03645886525080641, 0.045940850331631776, 0.05092582489327112, 0.05092582489327118], 'target': 0.022258065239049107}\n",
      "123 {'train': [0.008065858273786086, 0.023408032415380968, 0.03645886525080641, 0.045940850331631776, 0.05092582489327112, 0.05092582489327118, 0.045940850331631755], 'target': 0.028046798406492747}\n",
      "124 {'train': [0.023408032415380968, 0.03645886525080641, 0.045940850331631776, 0.05092582489327112, 0.05092582489327118, 0.045940850331631755, 0.0364588652508064], 'target': 0.031090115532373796}\n",
      "125 {'train': [0.03645886525080641, 0.045940850331631776, 0.05092582489327112, 0.05092582489327118, 0.045940850331631755, 0.0364588652508064, 0.023408032415380944], 'target': 0.03109011553237383}\n",
      "126 {'train': [0.045940850331631776, 0.05092582489327112, 0.05092582489327118, 0.045940850331631755, 0.0364588652508064, 0.023408032415380944, 0.008065858273786098], 'target': 0.02804679840649273}\n",
      "127 {'train': [0.05092582489327112, 0.05092582489327118, 0.045940850331631755, 0.0364588652508064, 0.023408032415380944, 0.008065858273786098, -0.008065858273786093], 'target': 0.0222580652390491}\n",
      "128 {'train': [0.05092582489327118, 0.045940850331631755, 0.0364588652508064, 0.023408032415380944, 0.008065858273786098, -0.008065858273786093, -0.02340803241538099], 'target': 0.014290557564947836}\n",
      "129 {'train': [0.045940850331631755, 0.0364588652508064, 0.023408032415380944, 0.008065858273786098, -0.008065858273786093, -0.02340803241538099, -0.03645886525080635], 'target': 0.004924190548220204}\n",
      "130 {'train': [0.0364588652508064, 0.023408032415380944, 0.008065858273786098, -0.008065858273786093, -0.02340803241538099, -0.03645886525080635, -0.045940850331631825], 'target': -0.004924190548220201}\n",
      "131 {'train': [0.023408032415380944, 0.008065858273786098, -0.008065858273786093, -0.02340803241538099, -0.03645886525080635, -0.045940850331631825, -0.05092582489327108], 'target': -0.014290557564947863}\n",
      "132 {'train': [0.008065858273786098, -0.008065858273786093, -0.02340803241538099, -0.03645886525080635, -0.045940850331631825, -0.05092582489327108, -0.05092582489327118], 'target': -0.022258065239049073}\n",
      "133 {'train': [-0.008065858273786093, -0.02340803241538099, -0.03645886525080635, -0.045940850331631825, -0.05092582489327108, -0.05092582489327118, -0.04594085033163181], 'target': -0.028046798406492775}\n",
      "134 {'train': [-0.02340803241538099, -0.03645886525080635, -0.045940850331631825, -0.05092582489327108, -0.05092582489327118, -0.04594085033163181, -0.03645886525080636], 'target': -0.031090115532373765}\n",
      "135 {'train': [-0.03645886525080635, -0.045940850331631825, -0.05092582489327108, -0.05092582489327118, -0.04594085033163181, -0.03645886525080636, -0.023408032415380982], 'target': -0.031090115532373834}\n",
      "136 {'train': [-0.045940850331631825, -0.05092582489327108, -0.05092582489327118, -0.04594085033163181, -0.03645886525080636, -0.023408032415380982, -0.008065858273786055], 'target': -0.028046798406492764}\n",
      "137 {'train': [-0.05092582489327108, -0.05092582489327118, -0.04594085033163181, -0.03645886525080636, -0.023408032415380982, -0.008065858273786055, 0.008065858273786086], 'target': -0.02225806523904908}\n",
      "138 {'train': [-0.05092582489327118, -0.04594085033163181, -0.03645886525080636, -0.023408032415380982, -0.008065858273786055, 0.008065858273786086, 0.023408032415380968], 'target': -0.014290557564947856}\n",
      "139 {'train': [-0.04594085033163181, -0.03645886525080636, -0.023408032415380982, -0.008065858273786055, 0.008065858273786086, 0.023408032415380968, 0.03645886525080641], 'target': -0.00492419054822018}\n",
      "140 {'train': [-0.02225806523904908, -0.014290557564947856, -0.00492419054822018, 0.004924190548220198, 0.014290557564947846, 0.022258065239049107, 0.028046798406492747], 'target': 0.0030062086057209354}\n",
      "141 {'train': [-0.014290557564947856, -0.00492419054822018, 0.004924190548220198, 0.014290557564947846, 0.022258065239049107, 0.028046798406492747, 0.031090115532373796], 'target': 0.008724357173347862}\n",
      "142 {'train': [-0.00492419054822018, 0.004924190548220198, 0.014290557564947846, 0.022258065239049107, 0.028046798406492747, 0.031090115532373796, 0.03109011553237383], 'target': 0.01358850487467677}\n",
      "143 {'train': [0.004924190548220198, 0.014290557564947846, 0.022258065239049107, 0.028046798406492747, 0.031090115532373796, 0.03109011553237383, 0.02804679840649273], 'target': 0.017122515042191727}\n",
      "144 {'train': [0.014290557564947846, 0.022258065239049107, 0.028046798406492747, 0.031090115532373796, 0.03109011553237383, 0.02804679840649273, 0.0222580652390491], 'target': 0.0189804541377997}\n",
      "145 {'train': [0.022258065239049107, 0.028046798406492747, 0.031090115532373796, 0.03109011553237383, 0.02804679840649273, 0.0222580652390491, 0.014290557564947836], 'target': 0.01898045413779972}\n",
      "146 {'train': [0.028046798406492747, 0.031090115532373796, 0.03109011553237383, 0.02804679840649273, 0.0222580652390491, 0.014290557564947836, 0.004924190548220204], 'target': 0.017122515042191727}\n",
      "147 {'train': [0.031090115532373796, 0.03109011553237383, 0.02804679840649273, 0.0222580652390491, 0.014290557564947836, 0.004924190548220204, -0.004924190548220201], 'target': 0.013588504874676763}\n",
      "148 {'train': [0.03109011553237383, 0.02804679840649273, 0.0222580652390491, 0.014290557564947836, 0.004924190548220204, -0.004924190548220201, -0.014290557564947863], 'target': 0.008724357173347857}\n",
      "149 {'train': [0.02804679840649273, 0.0222580652390491, 0.014290557564947836, 0.004924190548220204, -0.004924190548220201, -0.014290557564947863, -0.022258065239049073], 'target': 0.0030062086057209398}\n",
      "150 {'train': [0.0222580652390491, 0.014290557564947836, 0.004924190548220204, -0.004924190548220201, -0.014290557564947863, -0.022258065239049073, -0.028046798406492775], 'target': -0.0030062086057209376}\n",
      "151 {'train': [0.014290557564947836, 0.004924190548220204, -0.004924190548220201, -0.014290557564947863, -0.022258065239049073, -0.028046798406492775, -0.031090115532373765], 'target': -0.008724357173347873}\n",
      "152 {'train': [0.004924190548220204, -0.004924190548220201, -0.014290557564947863, -0.022258065239049073, -0.028046798406492775, -0.031090115532373765, -0.031090115532373834], 'target': -0.013588504874676747}\n",
      "153 {'train': [-0.004924190548220201, -0.014290557564947863, -0.022258065239049073, -0.028046798406492775, -0.031090115532373765, -0.031090115532373834, -0.028046798406492764], 'target': -0.017122515042191744}\n",
      "154 {'train': [-0.014290557564947863, -0.022258065239049073, -0.028046798406492775, -0.031090115532373765, -0.031090115532373834, -0.028046798406492764, -0.02225806523904908], 'target': -0.018980454137799682}\n",
      "155 {'train': [-0.022258065239049073, -0.028046798406492775, -0.031090115532373765, -0.031090115532373834, -0.028046798406492764, -0.02225806523904908, -0.014290557564947856], 'target': -0.01898045413779972}\n",
      "156 {'train': [-0.028046798406492775, -0.031090115532373765, -0.031090115532373834, -0.028046798406492764, -0.02225806523904908, -0.014290557564947856, -0.00492419054822018], 'target': -0.017122515042191744}\n",
      "157 {'train': [-0.031090115532373765, -0.031090115532373834, -0.028046798406492764, -0.02225806523904908, -0.014290557564947856, -0.00492419054822018, 0.004924190548220198], 'target': -0.013588504874676754}\n",
      "158 {'train': [-0.031090115532373834, -0.028046798406492764, -0.02225806523904908, -0.014290557564947856, -0.00492419054822018, 0.004924190548220198, 0.014290557564947846], 'target': -0.00872435717334787}\n",
      "159 {'train': [-0.028046798406492764, -0.02225806523904908, -0.014290557564947856, -0.00492419054822018, 0.004924190548220198, 0.014290557564947846, 0.022258065239049107], 'target': -0.0030062086057209237}\n",
      "160 {'train': [-0.013588504874676754, -0.00872435717334787, -0.0030062086057209237, 0.0030062086057209354, 0.008724357173347862, 0.01358850487467677, 0.017122515042191727], 'target': 0.0018352844173296766}\n",
      "161 {'train': [-0.00872435717334787, -0.0030062086057209237, 0.0030062086057209354, 0.008724357173347862, 0.01358850487467677, 0.017122515042191727, 0.0189804541377997], 'target': 0.005326202826042362}\n",
      "162 {'train': [-0.0030062086057209237, 0.0030062086057209354, 0.008724357173347862, 0.01358850487467677, 0.017122515042191727, 0.0189804541377997, 0.01898045413779972], 'target': 0.00829575539230483}\n",
      "163 {'train': [0.0030062086057209354, 0.008724357173347862, 0.01358850487467677, 0.017122515042191727, 0.0189804541377997, 0.01898045413779972, 0.017122515042191727], 'target': 0.010453261620841961}\n",
      "164 {'train': [0.008724357173347862, 0.01358850487467677, 0.017122515042191727, 0.0189804541377997, 0.01898045413779972, 0.017122515042191727, 0.013588504874676763], 'target': 0.011587529769774745}\n",
      "165 {'train': [0.01358850487467677, 0.017122515042191727, 0.0189804541377997, 0.01898045413779972, 0.017122515042191727, 0.013588504874676763, 0.008724357173347857], 'target': 0.011587529769774757}\n",
      "166 {'train': [0.017122515042191727, 0.0189804541377997, 0.01898045413779972, 0.017122515042191727, 0.013588504874676763, 0.008724357173347857, 0.0030062086057209398], 'target': 0.010453261620841958}\n",
      "167 {'train': [0.0189804541377997, 0.01898045413779972, 0.017122515042191727, 0.013588504874676763, 0.008724357173347857, 0.0030062086057209398, -0.0030062086057209376], 'target': 0.008295755392304824}\n",
      "168 {'train': [0.01898045413779972, 0.017122515042191727, 0.013588504874676763, 0.008724357173347857, 0.0030062086057209398, -0.0030062086057209376, -0.008724357173347873], 'target': 0.005326202826042358}\n",
      "169 {'train': [0.017122515042191727, 0.013588504874676763, 0.008724357173347857, 0.0030062086057209398, -0.0030062086057209376, -0.008724357173347873, -0.013588504874676747], 'target': 0.0018352844173296788}\n",
      "170 {'train': [0.013588504874676763, 0.008724357173347857, 0.0030062086057209398, -0.0030062086057209376, -0.008724357173347873, -0.013588504874676747, -0.017122515042191744], 'target': -0.001835284417329678}\n",
      "171 {'train': [0.008724357173347857, 0.0030062086057209398, -0.0030062086057209376, -0.008724357173347873, -0.013588504874676747, -0.017122515042191744, -0.018980454137799682], 'target': -0.0053262028260423686}\n",
      "172 {'train': [0.0030062086057209398, -0.0030062086057209376, -0.008724357173347873, -0.013588504874676747, -0.017122515042191744, -0.018980454137799682, -0.01898045413779972], 'target': -0.008295755392304812}\n",
      "173 {'train': [-0.0030062086057209376, -0.008724357173347873, -0.013588504874676747, -0.017122515042191744, -0.018980454137799682, -0.01898045413779972, -0.017122515042191744], 'target': -0.010453261620841973}\n",
      "174 {'train': [-0.008724357173347873, -0.013588504874676747, -0.017122515042191744, -0.018980454137799682, -0.01898045413779972, -0.017122515042191744, -0.013588504874676754], 'target': -0.011587529769774733}\n",
      "175 {'train': [-0.013588504874676747, -0.017122515042191744, -0.018980454137799682, -0.01898045413779972, -0.017122515042191744, -0.013588504874676754, -0.00872435717334787], 'target': -0.011587529769774757}\n",
      "176 {'train': [-0.017122515042191744, -0.018980454137799682, -0.01898045413779972, -0.017122515042191744, -0.013588504874676754, -0.00872435717334787, -0.0030062086057209237], 'target': -0.01045326162084197}\n",
      "177 {'train': [-0.018980454137799682, -0.01898045413779972, -0.017122515042191744, -0.013588504874676754, -0.00872435717334787, -0.0030062086057209237, 0.0030062086057209354], 'target': -0.008295755392304817}\n",
      "178 {'train': [-0.01898045413779972, -0.017122515042191744, -0.013588504874676754, -0.00872435717334787, -0.0030062086057209237, 0.0030062086057209354, 0.008724357173347862], 'target': -0.005326202826042366}\n",
      "179 {'train': [-0.017122515042191744, -0.013588504874676754, -0.00872435717334787, -0.0030062086057209237, 0.0030062086057209354, 0.008724357173347862, 0.01358850487467677], 'target': -0.00183528441732967}\n",
      "180 {'train': [-0.008295755392304817, -0.005326202826042366, -0.00183528441732967, 0.0018352844173296766, 0.005326202826042362, 0.00829575539230483, 0.010453261620841961], 'target': 0.0011204375125808568}\n",
      "181 {'train': [-0.005326202826042366, -0.00183528441732967, 0.0018352844173296766, 0.005326202826042362, 0.00829575539230483, 0.010453261620841961, 0.011587529769774745], 'target': 0.0032516363074639705}\n",
      "182 {'train': [-0.00183528441732967, 0.0018352844173296766, 0.005326202826042362, 0.00829575539230483, 0.010453261620841961, 0.011587529769774745, 0.011587529769774757], 'target': 0.005064542285090186}\n",
      "183 {'train': [0.0018352844173296766, 0.005326202826042362, 0.00829575539230483, 0.010453261620841961, 0.011587529769774745, 0.011587529769774757, 0.010453261620841958], 'target': 0.0063816955771107626}\n",
      "184 {'train': [0.005326202826042362, 0.00829575539230483, 0.010453261620841961, 0.011587529769774745, 0.011587529769774757, 0.010453261620841958, 0.008295755392304824], 'target': 0.007074164042156121}\n",
      "185 {'train': [0.00829575539230483, 0.010453261620841961, 0.011587529769774745, 0.011587529769774757, 0.010453261620841958, 0.008295755392304824, 0.005326202826042358], 'target': 0.007074164042156128}\n",
      "186 {'train': [0.010453261620841961, 0.011587529769774745, 0.011587529769774757, 0.010453261620841958, 0.008295755392304824, 0.005326202826042358, 0.0018352844173296788], 'target': 0.006381695577110761}\n",
      "187 {'train': [0.011587529769774745, 0.011587529769774757, 0.010453261620841958, 0.008295755392304824, 0.005326202826042358, 0.0018352844173296788, -0.001835284417329678], 'target': 0.005064542285090182}\n",
      "188 {'train': [0.011587529769774757, 0.010453261620841958, 0.008295755392304824, 0.005326202826042358, 0.0018352844173296788, -0.001835284417329678, -0.0053262028260423686], 'target': 0.003251636307463968}\n",
      "189 {'train': [0.010453261620841958, 0.008295755392304824, 0.005326202826042358, 0.0018352844173296788, -0.001835284417329678, -0.0053262028260423686, -0.008295755392304812], 'target': 0.0011204375125808584}\n",
      "190 {'train': [0.008295755392304824, 0.005326202826042358, 0.0018352844173296788, -0.001835284417329678, -0.0053262028260423686, -0.008295755392304812, -0.010453261620841973], 'target': -0.0011204375125808577}\n",
      "191 {'train': [0.005326202826042358, 0.0018352844173296788, -0.001835284417329678, -0.0053262028260423686, -0.008295755392304812, -0.010453261620841973, -0.011587529769774733], 'target': -0.0032516363074639744}\n",
      "192 {'train': [0.0018352844173296788, -0.001835284417329678, -0.0053262028260423686, -0.008295755392304812, -0.010453261620841973, -0.011587529769774733, -0.011587529769774757], 'target': -0.005064542285090176}\n",
      "193 {'train': [-0.001835284417329678, -0.0053262028260423686, -0.008295755392304812, -0.010453261620841973, -0.011587529769774733, -0.011587529769774757, -0.01045326162084197], 'target': -0.0063816955771107695}\n",
      "194 {'train': [-0.0053262028260423686, -0.008295755392304812, -0.010453261620841973, -0.011587529769774733, -0.011587529769774757, -0.01045326162084197, -0.008295755392304817], 'target': -0.007074164042156114}\n",
      "195 {'train': [-0.008295755392304812, -0.010453261620841973, -0.011587529769774733, -0.011587529769774757, -0.01045326162084197, -0.008295755392304817, -0.005326202826042366], 'target': -0.007074164042156129}\n",
      "196 {'train': [-0.010453261620841973, -0.011587529769774733, -0.011587529769774757, -0.01045326162084197, -0.008295755392304817, -0.005326202826042366, -0.00183528441732967], 'target': -0.0063816955771107695}\n",
      "197 {'train': [-0.011587529769774733, -0.011587529769774757, -0.01045326162084197, -0.008295755392304817, -0.005326202826042366, -0.00183528441732967, 0.0018352844173296766], 'target': -0.005064542285090179}\n",
      "198 {'train': [-0.011587529769774757, -0.01045326162084197, -0.008295755392304817, -0.005326202826042366, -0.00183528441732967, 0.0018352844173296766, 0.005326202826042362], 'target': -0.003251636307463973}\n",
      "199 {'train': [-0.01045326162084197, -0.008295755392304817, -0.005326202826042366, -0.00183528441732967, 0.0018352844173296766, 0.005326202826042362, 0.00829575539230483], 'target': -0.0011204375125808525}\n",
      "200 {'train': [-0.005064542285090179, -0.003251636307463973, -0.0011204375125808525, 0.0011204375125808568, 0.0032516363074639705, 0.005064542285090186, 0.0063816955771107626], 'target': 0.0006840248888643348}\n",
      "201 {'train': [-0.003251636307463973, -0.0011204375125808525, 0.0011204375125808568, 0.0032516363074639705, 0.005064542285090186, 0.0063816955771107626, 0.007074164042156121], 'target': 0.001985117544589322}\n",
      "202 {'train': [-0.0011204375125808525, 0.0011204375125808568, 0.0032516363074639705, 0.005064542285090186, 0.0063816955771107626, 0.007074164042156121, 0.007074164042156128], 'target': 0.003091893063922686}\n",
      "203 {'train': [0.0011204375125808568, 0.0032516363074639705, 0.005064542285090186, 0.0063816955771107626, 0.007074164042156121, 0.007074164042156128, 0.006381695577110761], 'target': 0.003896012547673593}\n",
      "204 {'train': [0.0032516363074639705, 0.005064542285090186, 0.0063816955771107626, 0.007074164042156121, 0.007074164042156128, 0.006381695577110761, 0.005064542285090182], 'target': 0.004318763178142621}\n",
      "205 {'train': [0.005064542285090186, 0.0063816955771107626, 0.007074164042156121, 0.007074164042156128, 0.006381695577110761, 0.005064542285090182, 0.003251636307463968], 'target': 0.004318763178142625}\n",
      "206 {'train': [0.0063816955771107626, 0.007074164042156121, 0.007074164042156128, 0.006381695577110761, 0.005064542285090182, 0.003251636307463968, 0.0011204375125808584], 'target': 0.0038960125476735913}\n",
      "207 {'train': [0.007074164042156121, 0.007074164042156128, 0.006381695577110761, 0.005064542285090182, 0.003251636307463968, 0.0011204375125808584, -0.0011204375125808577], 'target': 0.003091893063922684}\n",
      "208 {'train': [0.007074164042156128, 0.006381695577110761, 0.005064542285090182, 0.003251636307463968, 0.0011204375125808584, -0.0011204375125808577, -0.0032516363074639744], 'target': 0.001985117544589321}\n",
      "209 {'train': [0.006381695577110761, 0.005064542285090182, 0.003251636307463968, 0.0011204375125808584, -0.0011204375125808577, -0.0032516363074639744, -0.005064542285090176], 'target': 0.0006840248888643357}\n",
      "210 {'train': [0.005064542285090182, 0.003251636307463968, 0.0011204375125808584, -0.0011204375125808577, -0.0032516363074639744, -0.005064542285090176, -0.0063816955771107695], 'target': -0.0006840248888643352}\n",
      "211 {'train': [0.003251636307463968, 0.0011204375125808584, -0.0011204375125808577, -0.0032516363074639744, -0.005064542285090176, -0.0063816955771107695, -0.007074164042156114], 'target': -0.001985117544589325}\n",
      "212 {'train': [0.0011204375125808584, -0.0011204375125808577, -0.0032516363074639744, -0.005064542285090176, -0.0063816955771107695, -0.007074164042156114, -0.007074164042156129], 'target': -0.0030918930639226806}\n",
      "213 {'train': [-0.0011204375125808577, -0.0032516363074639744, -0.005064542285090176, -0.0063816955771107695, -0.007074164042156114, -0.007074164042156129, -0.0063816955771107695], 'target': -0.0038960125476735965}\n",
      "214 {'train': [-0.0032516363074639744, -0.005064542285090176, -0.0063816955771107695, -0.007074164042156114, -0.007074164042156129, -0.0063816955771107695, -0.005064542285090179], 'target': -0.004318763178142616}\n",
      "215 {'train': [-0.005064542285090176, -0.0063816955771107695, -0.007074164042156114, -0.007074164042156129, -0.0063816955771107695, -0.005064542285090179, -0.003251636307463973], 'target': -0.004318763178142625}\n",
      "216 {'train': [-0.0063816955771107695, -0.007074164042156114, -0.007074164042156129, -0.0063816955771107695, -0.005064542285090179, -0.003251636307463973, -0.0011204375125808525], 'target': -0.0038960125476735965}\n",
      "217 {'train': [-0.007074164042156114, -0.007074164042156129, -0.0063816955771107695, -0.005064542285090179, -0.003251636307463973, -0.0011204375125808525, 0.0011204375125808568], 'target': -0.003091893063922682}\n",
      "218 {'train': [-0.007074164042156129, -0.0063816955771107695, -0.005064542285090179, -0.003251636307463973, -0.0011204375125808525, 0.0011204375125808568, 0.0032516363074639705], 'target': -0.001985117544589324}\n",
      "219 {'train': [-0.0063816955771107695, -0.005064542285090179, -0.003251636307463973, -0.0011204375125808525, 0.0011204375125808568, 0.0032516363074639705, 0.005064542285090186], 'target': -0.0006840248888643324}\n",
      "220 {'train': [-0.003091893063922682, -0.001985117544589324, -0.0006840248888643324, 0.0006840248888643348, 0.001985117544589322, 0.003091893063922686, 0.003896012547673593], 'target': 0.0004175958438843323}\n",
      "221 {'train': [-0.001985117544589324, -0.0006840248888643324, 0.0006840248888643348, 0.001985117544589322, 0.003091893063922686, 0.003896012547673593, 0.004318763178142621], 'target': 0.0012119103408922685}\n",
      "222 {'train': [-0.0006840248888643324, 0.0006840248888643348, 0.001985117544589322, 0.003091893063922686, 0.003896012547673593, 0.004318763178142621, 0.004318763178142625], 'target': 0.0018875946098578138}\n",
      "223 {'train': [0.0006840248888643348, 0.001985117544589322, 0.003091893063922686, 0.003896012547673593, 0.004318763178142621, 0.004318763178142625, 0.0038960125476735913], 'target': 0.0023785079667654934}\n",
      "224 {'train': [0.001985117544589322, 0.003091893063922686, 0.003896012547673593, 0.004318763178142621, 0.004318763178142625, 0.0038960125476735913, 0.003091893063922684], 'target': 0.002636596391846706}\n",
      "225 {'train': [0.003091893063922686, 0.003896012547673593, 0.004318763178142621, 0.004318763178142625, 0.0038960125476735913, 0.003091893063922684, 0.001985117544589321], 'target': 0.0026365963918467093}\n",
      "226 {'train': [0.003896012547673593, 0.004318763178142621, 0.004318763178142625, 0.0038960125476735913, 0.003091893063922684, 0.001985117544589321, 0.0006840248888643357], 'target': 0.002378507966765493}\n",
      "227 {'train': [0.004318763178142621, 0.004318763178142625, 0.0038960125476735913, 0.003091893063922684, 0.001985117544589321, 0.0006840248888643357, -0.0006840248888643352], 'target': 0.0018875946098578127}\n",
      "228 {'train': [0.004318763178142625, 0.0038960125476735913, 0.003091893063922684, 0.001985117544589321, 0.0006840248888643357, -0.0006840248888643352, -0.001985117544589325], 'target': 0.0012119103408922678}\n",
      "229 {'train': [0.0038960125476735913, 0.003091893063922684, 0.001985117544589321, 0.0006840248888643357, -0.0006840248888643352, -0.001985117544589325, -0.0030918930639226806], 'target': 0.00041759584388433295}\n",
      "230 {'train': [0.003091893063922684, 0.001985117544589321, 0.0006840248888643357, -0.0006840248888643352, -0.001985117544589325, -0.0030918930639226806, -0.0038960125476735965], 'target': -0.0004175958438843328}\n",
      "231 {'train': [0.001985117544589321, 0.0006840248888643357, -0.0006840248888643352, -0.001985117544589325, -0.0030918930639226806, -0.0038960125476735965, -0.004318763178142616], 'target': -0.00121191034089227}\n",
      "232 {'train': [0.0006840248888643357, -0.0006840248888643352, -0.001985117544589325, -0.0030918930639226806, -0.0038960125476735965, -0.004318763178142616, -0.004318763178142625], 'target': -0.0018875946098578106}\n",
      "233 {'train': [-0.0006840248888643352, -0.001985117544589325, -0.0030918930639226806, -0.0038960125476735965, -0.004318763178142616, -0.004318763178142625, -0.0038960125476735965], 'target': -0.0023785079667654955}\n",
      "234 {'train': [-0.001985117544589325, -0.0030918930639226806, -0.0038960125476735965, -0.004318763178142616, -0.004318763178142625, -0.0038960125476735965, -0.003091893063922682], 'target': -0.0026365963918467033}\n",
      "235 {'train': [-0.0030918930639226806, -0.0038960125476735965, -0.004318763178142616, -0.004318763178142625, -0.0038960125476735965, -0.003091893063922682, -0.001985117544589324], 'target': -0.0026365963918467093}\n",
      "236 {'train': [-0.0038960125476735965, -0.004318763178142616, -0.004318763178142625, -0.0038960125476735965, -0.003091893063922682, -0.001985117544589324, -0.0006840248888643324], 'target': -0.0023785079667654955}\n",
      "237 {'train': [-0.004318763178142616, -0.004318763178142625, -0.0038960125476735965, -0.003091893063922682, -0.001985117544589324, -0.0006840248888643324, 0.0006840248888643348], 'target': -0.0018875946098578106}\n",
      "238 {'train': [-0.004318763178142625, -0.0038960125476735965, -0.003091893063922682, -0.001985117544589324, -0.0006840248888643324, 0.0006840248888643348, 0.001985117544589322], 'target': -0.0012119103408922693}\n",
      "239 {'train': [-0.0038960125476735965, -0.003091893063922682, -0.001985117544589324, -0.0006840248888643324, 0.0006840248888643348, 0.001985117544589322, 0.003091893063922686], 'target': -0.00041759584388433084}\n",
      "240 {'train': [-0.0018875946098578106, -0.0012119103408922693, -0.00041759584388433084, 0.0004175958438843323, 0.0012119103408922685, 0.0018875946098578138, 0.0023785079667654934], 'target': 0.0002549414380505893}\n",
      "241 {'train': [-0.0012119103408922693, -0.00041759584388433084, 0.0004175958438843323, 0.0012119103408922685, 0.0018875946098578138, 0.0023785079667654934, 0.002636596391846706], 'target': 0.0007398688699139296}\n",
      "242 {'train': [-0.00041759584388433084, 0.0004175958438843323, 0.0012119103408922685, 0.0018875946098578138, 0.0023785079667654934, 0.002636596391846706, 0.0026365963918467093], 'target': 0.0011523727818205593}\n",
      "243 {'train': [0.0004175958438843323, 0.0012119103408922685, 0.0018875946098578138, 0.0023785079667654934, 0.002636596391846706, 0.0026365963918467093, 0.002378507966765493], 'target': 0.0014520744167893015}\n",
      "244 {'train': [0.0012119103408922685, 0.0018875946098578138, 0.0023785079667654934, 0.002636596391846706, 0.0026365963918467093, 0.002378507966765493, 0.0018875946098578127], 'target': 0.0016096368906453411}\n",
      "245 {'train': [0.0018875946098578138, 0.0023785079667654934, 0.002636596391846706, 0.0026365963918467093, 0.002378507966765493, 0.0018875946098578127, 0.0012119103408922678], 'target': 0.0016096368906453429}\n",
      "246 {'train': [0.0023785079667654934, 0.002636596391846706, 0.0026365963918467093, 0.002378507966765493, 0.0018875946098578127, 0.0012119103408922678, 0.00041759584388433295], 'target': 0.0014520744167893015}\n",
      "247 {'train': [0.002636596391846706, 0.0026365963918467093, 0.002378507966765493, 0.0018875946098578127, 0.0012119103408922678, 0.00041759584388433295, -0.0004175958438843328], 'target': 0.0011523727818205586}\n",
      "248 {'train': [0.0026365963918467093, 0.002378507966765493, 0.0018875946098578127, 0.0012119103408922678, 0.00041759584388433295, -0.0004175958438843328, -0.00121191034089227], 'target': 0.000739868869913929}\n",
      "249 {'train': [0.002378507966765493, 0.0018875946098578127, 0.0012119103408922678, 0.00041759584388433295, -0.0004175958438843328, -0.00121191034089227, -0.0018875946098578106], 'target': 0.00025494143805058963}\n",
      "250 {'train': [0.0018875946098578127, 0.0012119103408922678, 0.00041759584388433295, -0.0004175958438843328, -0.00121191034089227, -0.0018875946098578106, -0.0023785079667654955], 'target': -0.00025494143805058947}\n",
      "251 {'train': [0.0012119103408922678, 0.00041759584388433295, -0.0004175958438843328, -0.00121191034089227, -0.0018875946098578106, -0.0023785079667654955, -0.0026365963918467033], 'target': -0.0007398688699139306}\n",
      "252 {'train': [0.00041759584388433295, -0.0004175958438843328, -0.00121191034089227, -0.0018875946098578106, -0.0023785079667654955, -0.0026365963918467033, -0.0026365963918467093], 'target': -0.001152372781820557}\n",
      "253 {'train': [-0.0004175958438843328, -0.00121191034089227, -0.0018875946098578106, -0.0023785079667654955, -0.0026365963918467033, -0.0026365963918467093, -0.0023785079667654955], 'target': -0.001452074416789303}\n",
      "254 {'train': [-0.00121191034089227, -0.0018875946098578106, -0.0023785079667654955, -0.0026365963918467033, -0.0026365963918467093, -0.0023785079667654955, -0.0018875946098578106], 'target': -0.0016096368906453398}\n",
      "255 {'train': [-0.0018875946098578106, -0.0023785079667654955, -0.0026365963918467033, -0.0026365963918467093, -0.0023785079667654955, -0.0018875946098578106, -0.0012119103408922693], 'target': -0.0016096368906453429}\n",
      "256 {'train': [-0.0023785079667654955, -0.0026365963918467033, -0.0026365963918467093, -0.0023785079667654955, -0.0018875946098578106, -0.0012119103408922693, -0.00041759584388433084], 'target': -0.001452074416789303}\n",
      "257 {'train': [-0.0026365963918467033, -0.0026365963918467093, -0.0023785079667654955, -0.0018875946098578106, -0.0012119103408922693, -0.00041759584388433084, 0.0004175958438843323], 'target': -0.0011523727818205573}\n",
      "258 {'train': [-0.0026365963918467093, -0.0023785079667654955, -0.0018875946098578106, -0.0012119103408922693, -0.00041759584388433084, 0.0004175958438843323, 0.0012119103408922685], 'target': -0.0007398688699139302}\n",
      "259 {'train': [-0.0023785079667654955, -0.0018875946098578106, -0.0012119103408922693, -0.00041759584388433084, 0.0004175958438843323, 0.0012119103408922685, 0.0018875946098578138], 'target': -0.0002549414380505883}\n",
      "260 {'train': [-0.0011523727818205573, -0.0007398688699139302, -0.0002549414380505883, 0.0002549414380505893, 0.0007398688699139296, 0.0011523727818205593, 0.0014520744167893015], 'target': 0.00015564124448830716}\n",
      "261 {'train': [-0.0007398688699139302, -0.0002549414380505883, 0.0002549414380505893, 0.0007398688699139296, 0.0011523727818205593, 0.0014520744167893015, 0.0016096368906453411], 'target': 0.00045168848403809064}\n",
      "262 {'train': [-0.0002549414380505883, 0.0002549414380505893, 0.0007398688699139296, 0.0011523727818205593, 0.0014520744167893015, 0.0016096368906453411, 0.0016096368906453429], 'target': 0.0007035213076715043}\n",
      "263 {'train': [0.0002549414380505893, 0.0007398688699139296, 0.0011523727818205593, 0.0014520744167893015, 0.0016096368906453411, 0.0016096368906453429, 0.0014520744167893015], 'target': 0.0008864885639888519}\n",
      "264 {'train': [0.0007398688699139296, 0.0011523727818205593, 0.0014520744167893015, 0.0016096368906453411, 0.0016096368906453429, 0.0014520744167893015, 0.0011523727818205586], 'target': 0.000982680143133958}\n",
      "265 {'train': [0.0011523727818205593, 0.0014520744167893015, 0.0016096368906453411, 0.0016096368906453429, 0.0014520744167893015, 0.0011523727818205586, 0.000739868869913929], 'target': 0.000982680143133959}\n",
      "266 {'train': [0.0014520744167893015, 0.0016096368906453411, 0.0016096368906453429, 0.0014520744167893015, 0.0011523727818205586, 0.000739868869913929, 0.00025494143805058963], 'target': 0.0008864885639888519}\n",
      "267 {'train': [0.0016096368906453411, 0.0016096368906453429, 0.0014520744167893015, 0.0011523727818205586, 0.000739868869913929, 0.00025494143805058963, -0.00025494143805058947], 'target': 0.0007035213076715039}\n",
      "268 {'train': [0.0016096368906453429, 0.0014520744167893015, 0.0011523727818205586, 0.000739868869913929, 0.00025494143805058963, -0.00025494143805058947, -0.0007398688699139306], 'target': 0.0004516884840380903}\n",
      "269 {'train': [0.0014520744167893015, 0.0011523727818205586, 0.000739868869913929, 0.00025494143805058963, -0.00025494143805058947, -0.0007398688699139306, -0.001152372781820557], 'target': 0.00015564124448830735}\n",
      "270 {'train': [0.0011523727818205586, 0.000739868869913929, 0.00025494143805058963, -0.00025494143805058947, -0.0007398688699139306, -0.001152372781820557, -0.001452074416789303], 'target': -0.00015564124448830732}\n",
      "271 {'train': [0.000739868869913929, 0.00025494143805058963, -0.00025494143805058947, -0.0007398688699139306, -0.001152372781820557, -0.001452074416789303, -0.0016096368906453398], 'target': -0.0004516884840380912}\n",
      "272 {'train': [0.00025494143805058963, -0.00025494143805058947, -0.0007398688699139306, -0.001152372781820557, -0.001452074416789303, -0.0016096368906453398, -0.0016096368906453429], 'target': -0.0007035213076715028}\n",
      "273 {'train': [-0.00025494143805058947, -0.0007398688699139306, -0.001152372781820557, -0.001452074416789303, -0.0016096368906453398, -0.0016096368906453429, -0.001452074416789303], 'target': -0.0008864885639888529}\n",
      "274 {'train': [-0.0007398688699139306, -0.001152372781820557, -0.001452074416789303, -0.0016096368906453398, -0.0016096368906453429, -0.001452074416789303, -0.0011523727818205573], 'target': -0.0009826801431339568}\n",
      "275 {'train': [-0.001152372781820557, -0.001452074416789303, -0.0016096368906453398, -0.0016096368906453429, -0.001452074416789303, -0.0011523727818205573, -0.0007398688699139302], 'target': -0.000982680143133959}\n",
      "276 {'train': [-0.001452074416789303, -0.0016096368906453398, -0.0016096368906453429, -0.001452074416789303, -0.0011523727818205573, -0.0007398688699139302, -0.0002549414380505883], 'target': -0.0008864885639888529}\n",
      "277 {'train': [-0.0016096368906453398, -0.0016096368906453429, -0.001452074416789303, -0.0011523727818205573, -0.0007398688699139302, -0.0002549414380505883, 0.0002549414380505893], 'target': -0.0007035213076715032}\n",
      "278 {'train': [-0.0016096368906453429, -0.001452074416789303, -0.0011523727818205573, -0.0007398688699139302, -0.0002549414380505883, 0.0002549414380505893, 0.0007398688699139296], 'target': -0.0004516884840380909}\n",
      "279 {'train': [-0.001452074416789303, -0.0011523727818205573, -0.0007398688699139302, -0.0002549414380505883, 0.0002549414380505893, 0.0007398688699139296, 0.0011523727818205593], 'target': -0.00015564124448830662}\n",
      "280 {'train': [-0.0007035213076715032, -0.0004516884840380909, -0.00015564124448830662, 0.00015564124448830716, 0.00045168848403809064, 0.0007035213076715043, 0.0008864885639888519], 'target': 9.50186724100228e-05}\n",
      "281 {'train': [-0.0004516884840380909, -0.00015564124448830662, 0.00015564124448830716, 0.00045168848403809064, 0.0007035213076715043, 0.0008864885639888519, 0.000982680143133958], 'target': 0.0002757549275405561}\n",
      "282 {'train': [-0.00015564124448830662, 0.00015564124448830716, 0.00045168848403809064, 0.0007035213076715043, 0.0008864885639888519, 0.000982680143133958, 0.000982680143133959], 'target': 0.00042949836906586495}\n",
      "283 {'train': [0.00015564124448830716, 0.00045168848403809064, 0.0007035213076715043, 0.0008864885639888519, 0.000982680143133958, 0.000982680143133959, 0.0008864885639888519], 'target': 0.0005411995177359069}\n",
      "284 {'train': [0.00045168848403809064, 0.0007035213076715043, 0.0008864885639888519, 0.000982680143133958, 0.000982680143133959, 0.0008864885639888519, 0.0007035213076715039], 'target': 0.0005999242868511928}\n",
      "285 {'train': [0.0007035213076715043, 0.0008864885639888519, 0.000982680143133958, 0.000982680143133959, 0.0008864885639888519, 0.0007035213076715039, 0.0004516884840380903], 'target': 0.0005999242868511935}\n",
      "286 {'train': [0.0008864885639888519, 0.000982680143133958, 0.000982680143133959, 0.0008864885639888519, 0.0007035213076715039, 0.0004516884840380903, 0.00015564124448830735], 'target': 0.0005411995177359068}\n",
      "287 {'train': [0.000982680143133958, 0.000982680143133959, 0.0008864885639888519, 0.0007035213076715039, 0.0004516884840380903, 0.00015564124448830735, -0.00015564124448830732], 'target': 0.0004294983690658648}\n",
      "288 {'train': [0.000982680143133959, 0.0008864885639888519, 0.0007035213076715039, 0.0004516884840380903, 0.00015564124448830735, -0.00015564124448830732, -0.0004516884840380912], 'target': 0.00027575492754055593}\n",
      "289 {'train': [0.0008864885639888519, 0.0007035213076715039, 0.0004516884840380903, 0.00015564124448830735, -0.00015564124448830732, -0.0004516884840380912, -0.0007035213076715028], 'target': 9.501867241002288e-05}\n",
      "290 {'train': [0.0007035213076715039, 0.0004516884840380903, 0.00015564124448830735, -0.00015564124448830732, -0.0004516884840380912, -0.0007035213076715028, -0.0008864885639888529], 'target': -9.501867241002283e-05}\n",
      "291 {'train': [0.0004516884840380903, 0.00015564124448830735, -0.00015564124448830732, -0.0004516884840380912, -0.0007035213076715028, -0.0008864885639888529, -0.0009826801431339568], 'target': -0.0002757549275405564}\n",
      "292 {'train': [0.00015564124448830735, -0.00015564124448830732, -0.0004516884840380912, -0.0007035213076715028, -0.0008864885639888529, -0.0009826801431339568, -0.000982680143133959], 'target': -0.0004294983690658643}\n",
      "293 {'train': [-0.00015564124448830732, -0.0004516884840380912, -0.0007035213076715028, -0.0008864885639888529, -0.0009826801431339568, -0.000982680143133959, -0.0008864885639888529], 'target': -0.0005411995177359074}\n",
      "294 {'train': [-0.0004516884840380912, -0.0007035213076715028, -0.0008864885639888529, -0.0009826801431339568, -0.000982680143133959, -0.0008864885639888529, -0.0007035213076715032], 'target': -0.0005999242868511922}\n",
      "295 {'train': [-0.0007035213076715028, -0.0008864885639888529, -0.0009826801431339568, -0.000982680143133959, -0.0008864885639888529, -0.0007035213076715032, -0.0004516884840380909], 'target': -0.0005999242868511935}\n",
      "296 {'train': [-0.0008864885639888529, -0.0009826801431339568, -0.000982680143133959, -0.0008864885639888529, -0.0007035213076715032, -0.0004516884840380909, -0.00015564124448830662], 'target': -0.0005411995177359073}\n",
      "297 {'train': [-0.0009826801431339568, -0.000982680143133959, -0.0008864885639888529, -0.0007035213076715032, -0.0004516884840380909, -0.00015564124448830662, 0.00015564124448830716], 'target': -0.0004294983690658643}\n",
      "298 {'train': [-0.000982680143133959, -0.0008864885639888529, -0.0007035213076715032, -0.0004516884840380909, -0.00015564124448830662, 0.00015564124448830716, 0.00045168848403809064], 'target': -0.0002757549275405564}\n",
      "299 {'train': [-0.0008864885639888529, -0.0007035213076715032, -0.0004516884840380909, -0.00015564124448830662, 0.00015564124448830716, 0.00045168848403809064, 0.0007035213076715043], 'target': -9.50186724100224e-05}\n",
      "300 {'train': [-0.0004294983690658643, -0.0002757549275405564, -9.50186724100224e-05, 9.50186724100228e-05, 0.0002757549275405561, 0.00042949836906586495, 0.0005411995177359069], 'target': 5.80087118696966e-05}\n",
      "301 {'train': [-0.0002757549275405564, -9.50186724100224e-05, 9.50186724100228e-05, 0.0002757549275405561, 0.00042949836906586495, 0.0005411995177359069, 0.0005999242868511928], 'target': 0.00016834783872082254}\n",
      "302 {'train': [-9.50186724100224e-05, 9.50186724100228e-05, 0.0002757549275405561, 0.00042949836906586495, 0.0005411995177359069, 0.0005999242868511928, 0.0005999242868511935], 'target': 0.00026220790616959106}\n",
      "303 {'train': [9.50186724100228e-05, 0.0002757549275405561, 0.00042949836906586495, 0.0005411995177359069, 0.0005999242868511928, 0.0005999242868511935, 0.0005411995177359068], 'target': 0.00033040123685257295}\n",
      "304 {'train': [0.0002757549275405561, 0.00042949836906586495, 0.0005411995177359069, 0.0005999242868511928, 0.0005999242868511935, 0.0005411995177359068, 0.0004294983690658648], 'target': 0.0003662525924316449}\n",
      "305 {'train': [0.00042949836906586495, 0.0005411995177359069, 0.0005999242868511928, 0.0005999242868511935, 0.0005411995177359068, 0.0004294983690658648, 0.00027575492754055593], 'target': 0.00036625259243164526}\n",
      "306 {'train': [0.0005411995177359069, 0.0005999242868511928, 0.0005999242868511935, 0.0005411995177359068, 0.0004294983690658648, 0.00027575492754055593, 9.501867241002288e-05], 'target': 0.0003304012368525729}\n",
      "307 {'train': [0.0005999242868511928, 0.0005999242868511935, 0.0005411995177359068, 0.0004294983690658648, 0.00027575492754055593, 9.501867241002288e-05, -9.501867241002283e-05], 'target': 0.000262207906169591}\n",
      "308 {'train': [0.0005999242868511935, 0.0005411995177359068, 0.0004294983690658648, 0.00027575492754055593, 9.501867241002288e-05, -9.501867241002283e-05, -0.0002757549275405564], 'target': 0.00016834783872082243}\n",
      "309 {'train': [0.0005411995177359068, 0.0004294983690658648, 0.00027575492754055593, 9.501867241002288e-05, -9.501867241002283e-05, -0.0002757549275405564, -0.0004294983690658643], 'target': 5.800871186969667e-05}\n",
      "310 {'train': [0.0004294983690658648, 0.00027575492754055593, 9.501867241002288e-05, -9.501867241002283e-05, -0.0002757549275405564, -0.0004294983690658643, -0.0005411995177359074], 'target': -5.800871186969663e-05}\n",
      "311 {'train': [0.00027575492754055593, 9.501867241002288e-05, -9.501867241002283e-05, -0.0002757549275405564, -0.0004294983690658643, -0.0005411995177359074, -0.0005999242868511922], 'target': -0.0001683478387208227}\n",
      "312 {'train': [9.501867241002288e-05, -9.501867241002283e-05, -0.0002757549275405564, -0.0004294983690658643, -0.0005411995177359074, -0.0005999242868511922, -0.0005999242868511935], 'target': -0.0002622079061695906}\n",
      "313 {'train': [-9.501867241002283e-05, -0.0002757549275405564, -0.0004294983690658643, -0.0005411995177359074, -0.0005999242868511922, -0.0005999242868511935, -0.0005411995177359073], 'target': -0.0003304012368525733}\n",
      "314 {'train': [-0.0002757549275405564, -0.0004294983690658643, -0.0005411995177359074, -0.0005999242868511922, -0.0005999242868511935, -0.0005411995177359073, -0.0004294983690658643], 'target': -0.0003662525924316445}\n",
      "315 {'train': [-0.0004294983690658643, -0.0005411995177359074, -0.0005999242868511922, -0.0005999242868511935, -0.0005411995177359073, -0.0004294983690658643, -0.0002757549275405564], 'target': -0.00036625259243164526}\n",
      "316 {'train': [-0.0005411995177359074, -0.0005999242868511922, -0.0005999242868511935, -0.0005411995177359073, -0.0004294983690658643, -0.0002757549275405564, -9.50186724100224e-05], 'target': -0.0003304012368525732}\n",
      "317 {'train': [-0.0005999242868511922, -0.0005999242868511935, -0.0005411995177359073, -0.0004294983690658643, -0.0002757549275405564, -9.50186724100224e-05, 9.50186724100228e-05], 'target': -0.0002622079061695908}\n",
      "318 {'train': [-0.0005999242868511935, -0.0005411995177359073, -0.0004294983690658643, -0.0002757549275405564, -9.50186724100224e-05, 9.50186724100228e-05, 0.0002757549275405561], 'target': -0.00016834783872082267}\n",
      "319 {'train': [-0.0005411995177359073, -0.0004294983690658643, -0.0002757549275405564, -9.50186724100224e-05, 9.50186724100228e-05, 0.0002757549275405561, 0.00042949836906586495], 'target': -5.8008711869696373e-05}\n",
      "320 {'train': [-0.0002622079061695908, -0.00016834783872082267, -5.8008711869696373e-05, 5.80087118696966e-05, 0.00016834783872082254, 0.00026220790616959106, 0.00033040123685257295], 'target': 3.541420404466235e-05}\n",
      "321 {'train': [-0.00016834783872082267, -5.8008711869696373e-05, 5.80087118696966e-05, 0.00016834783872082254, 0.00026220790616959106, 0.00033040123685257295, 0.0003662525924316449], 'target': 0.00010277602309682698}\n",
      "322 {'train': [-5.8008711869696373e-05, 5.80087118696966e-05, 0.00016834783872082254, 0.00026220790616959106, 0.00033040123685257295, 0.0003662525924316449, 0.00036625259243164526], 'target': 0.00016007740892561468}\n",
      "323 {'train': [5.80087118696966e-05, 0.00016834783872082254, 0.00026220790616959106, 0.00033040123685257295, 0.0003662525924316449, 0.00036625259243164526, 0.0003304012368525729], 'target': 0.00020170930264387253}\n",
      "324 {'train': [0.00016834783872082254, 0.00026220790616959106, 0.00033040123685257295, 0.0003662525924316449, 0.00036625259243164526, 0.0003304012368525729, 0.000262207906169591], 'target': 0.00022359648442799786}\n",
      "325 {'train': [0.00026220790616959106, 0.00033040123685257295, 0.0003662525924316449, 0.00036625259243164526, 0.0003304012368525729, 0.000262207906169591, 0.00016834783872082243], 'target': 0.0002235964844279981}\n",
      "326 {'train': [0.00033040123685257295, 0.0003662525924316449, 0.00036625259243164526, 0.0003304012368525729, 0.000262207906169591, 0.00016834783872082243, 5.800871186969667e-05], 'target': 0.00020170930264387248}\n",
      "327 {'train': [0.0003662525924316449, 0.00036625259243164526, 0.0003304012368525729, 0.000262207906169591, 0.00016834783872082243, 5.800871186969667e-05, -5.800871186969663e-05], 'target': 0.00016007740892561457}\n",
      "328 {'train': [0.00036625259243164526, 0.0003304012368525729, 0.000262207906169591, 0.00016834783872082243, 5.800871186969667e-05, -5.800871186969663e-05, -0.0001683478387208227], 'target': 0.00010277602309682688}\n",
      "329 {'train': [0.0003304012368525729, 0.000262207906169591, 0.00016834783872082243, 5.800871186969667e-05, -5.800871186969663e-05, -0.0001683478387208227, -0.0002622079061695906], 'target': 3.5414204044662395e-05}\n",
      "330 {'train': [0.000262207906169591, 0.00016834783872082243, 5.800871186969667e-05, -5.800871186969663e-05, -0.0001683478387208227, -0.0002622079061695906, -0.0003304012368525733], 'target': -3.5414204044662375e-05}\n",
      "331 {'train': [0.00016834783872082243, 5.800871186969667e-05, -5.800871186969663e-05, -0.0001683478387208227, -0.0002622079061695906, -0.0003304012368525733, -0.0003662525924316445], 'target': -0.0001027760230968271}\n",
      "332 {'train': [5.800871186969667e-05, -5.800871186969663e-05, -0.0001683478387208227, -0.0002622079061695906, -0.0003304012368525733, -0.0003662525924316445, -0.00036625259243164526], 'target': -0.0001600774089256144}\n",
      "333 {'train': [-5.800871186969663e-05, -0.0001683478387208227, -0.0002622079061695906, -0.0003304012368525733, -0.0003662525924316445, -0.00036625259243164526, -0.0003304012368525732], 'target': -0.00020170930264387275}\n",
      "334 {'train': [-0.0001683478387208227, -0.0002622079061695906, -0.0003304012368525733, -0.0003662525924316445, -0.00036625259243164526, -0.0003304012368525732, -0.0002622079061695908], 'target': -0.0002235964844279976}\n",
      "335 {'train': [-0.0002622079061695906, -0.0003304012368525733, -0.0003662525924316445, -0.00036625259243164526, -0.0003304012368525732, -0.0002622079061695908, -0.00016834783872082267], 'target': -0.0002235964844279981}\n",
      "336 {'train': [-0.0003304012368525733, -0.0003662525924316445, -0.00036625259243164526, -0.0003304012368525732, -0.0002622079061695908, -0.00016834783872082267, -5.8008711869696373e-05], 'target': -0.0002017093026438727}\n",
      "337 {'train': [-0.0003662525924316445, -0.00036625259243164526, -0.0003304012368525732, -0.0002622079061695908, -0.00016834783872082267, -5.8008711869696373e-05, 5.80087118696966e-05], 'target': -0.00016007740892561446}\n",
      "338 {'train': [-0.00036625259243164526, -0.0003304012368525732, -0.0002622079061695908, -0.00016834783872082267, -5.8008711869696373e-05, 5.80087118696966e-05, 0.00016834783872082254], 'target': -0.00010277602309682704}\n",
      "339 {'train': [-0.0003304012368525732, -0.0002622079061695908, -0.00016834783872082267, -5.8008711869696373e-05, 5.80087118696966e-05, 0.00016834783872082254, 0.00026220790616959106], 'target': -3.541420404466221e-05}\n",
      "340 {'train': [-0.00016007740892561446, -0.00010277602309682704, -3.541420404466221e-05, 3.541420404466235e-05, 0.00010277602309682698, 0.00016007740892561468, 0.00020170930264387253], 'target': 2.1620301635626388e-05}\n",
      "341 {'train': [-0.00010277602309682704, -3.541420404466221e-05, 3.541420404466235e-05, 0.00010277602309682698, 0.00016007740892561468, 0.00020170930264387253, 0.00022359648442799786], 'target': 6.274455914528486e-05}\n",
      "342 {'train': [-3.541420404466221e-05, 3.541420404466235e-05, 0.00010277602309682698, 0.00016007740892561468, 0.00020170930264387253, 0.00022359648442799786, 0.0002235964844279981], 'target': 9.772694203875333e-05}\n",
      "343 {'train': [3.541420404466235e-05, 0.00010277602309682698, 0.00016007740892561468, 0.00020170930264387253, 0.00022359648442799786, 0.0002235964844279981, 0.00020170930264387248], 'target': 0.00012314313094182532}\n",
      "344 {'train': [0.00010277602309682698, 0.00016007740892561468, 0.00020170930264387253, 0.00022359648442799786, 0.0002235964844279981, 0.00020170930264387248, 0.00016007740892561457], 'target': 0.0001365052121996674}\n",
      "345 {'train': [0.00016007740892561468, 0.00020170930264387253, 0.00022359648442799786, 0.0002235964844279981, 0.00020170930264387248, 0.00016007740892561457, 0.00010277602309682688], 'target': 0.00013650521219966754}\n",
      "346 {'train': [0.00020170930264387253, 0.00022359648442799786, 0.0002235964844279981, 0.00020170930264387248, 0.00016007740892561457, 0.00010277602309682688, 3.5414204044662395e-05], 'target': 0.00012314313094182532}\n",
      "347 {'train': [0.00022359648442799786, 0.0002235964844279981, 0.00020170930264387248, 0.00016007740892561457, 0.00010277602309682688, 3.5414204044662395e-05, -3.5414204044662375e-05], 'target': 9.772694203875327e-05}\n",
      "348 {'train': [0.0002235964844279981, 0.00020170930264387248, 0.00016007740892561457, 0.00010277602309682688, 3.5414204044662395e-05, -3.5414204044662375e-05, -0.0001027760230968271], 'target': 6.274455914528482e-05}\n",
      "349 {'train': [0.00020170930264387248, 0.00016007740892561457, 0.00010277602309682688, 3.5414204044662395e-05, -3.5414204044662375e-05, -0.0001027760230968271, -0.0001600774089256144], 'target': 2.1620301635626415e-05}\n",
      "350 {'train': [0.00016007740892561457, 0.00010277602309682688, 3.5414204044662395e-05, -3.5414204044662375e-05, -0.0001027760230968271, -0.0001600774089256144, -0.00020170930264387275], 'target': -2.162030163562641e-05}\n",
      "351 {'train': [0.00010277602309682688, 3.5414204044662395e-05, -3.5414204044662375e-05, -0.0001027760230968271, -0.0001600774089256144, -0.00020170930264387275, -0.0002235964844279976], 'target': -6.274455914528496e-05}\n",
      "352 {'train': [3.5414204044662395e-05, -3.5414204044662375e-05, -0.0001027760230968271, -0.0001600774089256144, -0.00020170930264387275, -0.0002235964844279976, -0.0002235964844279981], 'target': -9.772694203875315e-05}\n",
      "353 {'train': [-3.5414204044662375e-05, -0.0001027760230968271, -0.0001600774089256144, -0.00020170930264387275, -0.0002235964844279976, -0.0002235964844279981, -0.0002017093026438727], 'target': -0.00012314313094182548}\n",
      "354 {'train': [-0.0001027760230968271, -0.0001600774089256144, -0.00020170930264387275, -0.0002235964844279976, -0.0002235964844279981, -0.0002017093026438727, -0.00016007740892561446], 'target': -0.00013650521219966724}\n",
      "355 {'train': [-0.0001600774089256144, -0.00020170930264387275, -0.0002235964844279976, -0.0002235964844279981, -0.0002017093026438727, -0.00016007740892561446, -0.00010277602309682704], 'target': -0.00013650521219966754}\n",
      "356 {'train': [-0.00020170930264387275, -0.0002235964844279976, -0.0002235964844279981, -0.0002017093026438727, -0.00016007740892561446, -0.00010277602309682704, -3.541420404466221e-05], 'target': -0.00012314313094182545}\n",
      "357 {'train': [-0.0002235964844279976, -0.0002235964844279981, -0.0002017093026438727, -0.00016007740892561446, -0.00010277602309682704, -3.541420404466221e-05, 3.541420404466235e-05], 'target': -9.772694203875319e-05}\n",
      "358 {'train': [-0.0002235964844279981, -0.0002017093026438727, -0.00016007740892561446, -0.00010277602309682704, -3.541420404466221e-05, 3.541420404466235e-05, 0.00010277602309682698], 'target': -6.274455914528492e-05}\n",
      "359 {'train': [-0.0002017093026438727, -0.00016007740892561446, -0.00010277602309682704, -3.541420404466221e-05, 3.541420404466235e-05, 0.00010277602309682698, 0.00016007740892561468], 'target': -2.1620301635626307e-05}\n",
      "360 {'train': [-9.772694203875319e-05, -6.274455914528492e-05, -2.1620301635626307e-05, 2.1620301635626388e-05, 6.274455914528486e-05, 9.772694203875333e-05, 0.00012314313094182532], 'target': 1.3199151454200782e-05}\n",
      "361 {'train': [-6.274455914528492e-05, -2.1620301635626307e-05, 2.1620301635626388e-05, 6.274455914528486e-05, 9.772694203875333e-05, 0.00012314313094182532, 0.0001365052121996674], 'target': 3.83054294543694e-05}\n",
      "362 {'train': [-2.1620301635626307e-05, 2.1620301635626388e-05, 6.274455914528486e-05, 9.772694203875333e-05, 0.00012314313094182532, 0.0001365052121996674, 0.00013650521219966754], 'target': 5.966210512992389e-05}\n",
      "363 {'train': [2.1620301635626388e-05, 6.274455914528486e-05, 9.772694203875333e-05, 0.00012314313094182532, 0.0001365052121996674, 0.00013650521219966754, 0.00012314313094182532], 'target': 7.517863826503179e-05}\n",
      "364 {'train': [6.274455914528486e-05, 9.772694203875333e-05, 0.00012314313094182532, 0.0001365052121996674, 0.00013650521219966754, 0.00012314313094182532, 9.772694203875327e-05], 'target': 8.333616248638549e-05}\n",
      "365 {'train': [9.772694203875333e-05, 0.00012314313094182532, 0.0001365052121996674, 0.00013650521219966754, 0.00012314313094182532, 9.772694203875327e-05, 6.274455914528482e-05], 'target': 8.333616248638558e-05}\n",
      "366 {'train': [0.00012314313094182532, 0.0001365052121996674, 0.00013650521219966754, 0.00012314313094182532, 9.772694203875327e-05, 6.274455914528482e-05, 2.1620301635626415e-05], 'target': 7.517863826503179e-05}\n",
      "367 {'train': [0.0001365052121996674, 0.00013650521219966754, 0.00012314313094182532, 9.772694203875327e-05, 6.274455914528482e-05, 2.1620301635626415e-05, -2.162030163562641e-05], 'target': 5.966210512992384e-05}\n",
      "368 {'train': [0.00013650521219966754, 0.00012314313094182532, 9.772694203875327e-05, 6.274455914528482e-05, 2.1620301635626415e-05, -2.162030163562641e-05, -6.274455914528496e-05], 'target': 3.830542945436937e-05}\n",
      "369 {'train': [0.00012314313094182532, 9.772694203875327e-05, 6.274455914528482e-05, 2.1620301635626415e-05, -2.162030163562641e-05, -6.274455914528496e-05, -9.772694203875315e-05], 'target': 1.31991514542008e-05}\n",
      "370 {'train': [9.772694203875327e-05, 6.274455914528482e-05, 2.1620301635626415e-05, -2.162030163562641e-05, -6.274455914528496e-05, -9.772694203875315e-05, -0.00012314313094182548], 'target': -1.3199151454200794e-05}\n",
      "371 {'train': [6.274455914528482e-05, 2.1620301635626415e-05, -2.162030163562641e-05, -6.274455914528496e-05, -9.772694203875315e-05, -0.00012314313094182548, -0.00013650521219966724], 'target': -3.830542945436944e-05}\n",
      "372 {'train': [2.1620301635626415e-05, -2.162030163562641e-05, -6.274455914528496e-05, -9.772694203875315e-05, -0.00012314313094182548, -0.00013650521219966724, -0.00013650521219966754], 'target': -5.9662105129923774e-05}\n",
      "373 {'train': [-2.162030163562641e-05, -6.274455914528496e-05, -9.772694203875315e-05, -0.00012314313094182548, -0.00013650521219966724, -0.00013650521219966754, -0.00012314313094182545], 'target': -7.517863826503187e-05}\n",
      "374 {'train': [-6.274455914528496e-05, -9.772694203875315e-05, -0.00012314313094182548, -0.00013650521219966724, -0.00013650521219966754, -0.00012314313094182545, -9.772694203875319e-05], 'target': -8.333616248638539e-05}\n",
      "375 {'train': [-9.772694203875315e-05, -0.00012314313094182548, -0.00013650521219966724, -0.00013650521219966754, -0.00012314313094182545, -9.772694203875319e-05, -6.274455914528492e-05], 'target': -8.333616248638558e-05}\n",
      "376 {'train': [-0.00012314313094182548, -0.00013650521219966724, -0.00013650521219966754, -0.00012314313094182545, -9.772694203875319e-05, -6.274455914528492e-05, -2.1620301635626307e-05], 'target': -7.517863826503187e-05}\n",
      "377 {'train': [-0.00013650521219966724, -0.00013650521219966754, -0.00012314313094182545, -9.772694203875319e-05, -6.274455914528492e-05, -2.1620301635626307e-05, 2.1620301635626388e-05], 'target': -5.966210512992378e-05}\n",
      "378 {'train': [-0.00013650521219966754, -0.00012314313094182545, -9.772694203875319e-05, -6.274455914528492e-05, -2.1620301635626307e-05, 2.1620301635626388e-05, 6.274455914528486e-05], 'target': -3.830542945436943e-05}\n",
      "379 {'train': [-0.00012314313094182545, -9.772694203875319e-05, -6.274455914528492e-05, -2.1620301635626307e-05, 2.1620301635626388e-05, 6.274455914528486e-05, 9.772694203875333e-05], 'target': -1.3199151454200735e-05}\n",
      "380 {'train': [-5.966210512992378e-05, -3.830542945436943e-05, -1.3199151454200735e-05, 1.3199151454200782e-05, 3.83054294543694e-05, 5.966210512992389e-05, 7.517863826503179e-05], 'target': 8.05805589797376e-06}\n",
      "381 {'train': [-3.830542945436943e-05, -1.3199151454200735e-05, 1.3199151454200782e-05, 3.83054294543694e-05, 5.966210512992389e-05, 7.517863826503179e-05, 8.333616248638549e-05], 'target': 2.338538903885084e-05}\n",
      "382 {'train': [-1.3199151454200735e-05, 1.3199151454200782e-05, 3.83054294543694e-05, 5.966210512992389e-05, 7.517863826503179e-05, 8.333616248638549e-05, 8.333616248638558e-05], 'target': 3.642359736501894e-05}\n",
      "383 {'train': [1.3199151454200782e-05, 3.83054294543694e-05, 5.966210512992389e-05, 7.517863826503179e-05, 8.333616248638549e-05, 8.333616248638558e-05, 7.517863826503179e-05], 'target': 4.589641020297365e-05}\n",
      "384 {'train': [3.83054294543694e-05, 5.966210512992389e-05, 7.517863826503179e-05, 8.333616248638549e-05, 8.333616248638558e-05, 7.517863826503179e-05, 5.966210512992384e-05], 'target': 5.0876562631167966e-05}\n",
      "385 {'train': [5.966210512992389e-05, 7.517863826503179e-05, 8.333616248638549e-05, 8.333616248638558e-05, 7.517863826503179e-05, 5.966210512992384e-05, 3.830542945436937e-05], 'target': 5.087656263116802e-05}\n",
      "386 {'train': [7.517863826503179e-05, 8.333616248638549e-05, 8.333616248638558e-05, 7.517863826503179e-05, 5.966210512992384e-05, 3.830542945436937e-05, 1.31991514542008e-05], 'target': 4.589641020297363e-05}\n",
      "387 {'train': [8.333616248638549e-05, 8.333616248638558e-05, 7.517863826503179e-05, 5.966210512992384e-05, 3.830542945436937e-05, 1.31991514542008e-05, -1.3199151454200794e-05], 'target': 3.6423597365018935e-05}\n",
      "388 {'train': [8.333616248638558e-05, 7.517863826503179e-05, 5.966210512992384e-05, 3.830542945436937e-05, 1.31991514542008e-05, -1.3199151454200794e-05, -3.830542945436944e-05], 'target': 2.3385389038850824e-05}\n",
      "389 {'train': [7.517863826503179e-05, 5.966210512992384e-05, 3.830542945436937e-05, 1.31991514542008e-05, -1.3199151454200794e-05, -3.830542945436944e-05, -5.9662105129923774e-05], 'target': 8.058055897973772e-06}\n",
      "390 {'train': [5.966210512992384e-05, 3.830542945436937e-05, 1.31991514542008e-05, -1.3199151454200794e-05, -3.830542945436944e-05, -5.9662105129923774e-05, -7.517863826503187e-05], 'target': -8.058055897973766e-06}\n",
      "391 {'train': [3.830542945436937e-05, 1.31991514542008e-05, -1.3199151454200794e-05, -3.830542945436944e-05, -5.9662105129923774e-05, -7.517863826503187e-05, -8.333616248638539e-05], 'target': -2.3385389038850865e-05}\n",
      "392 {'train': [1.31991514542008e-05, -1.3199151454200794e-05, -3.830542945436944e-05, -5.9662105129923774e-05, -7.517863826503187e-05, -8.333616248638539e-05, -8.333616248638558e-05], 'target': -3.642359736501888e-05}\n",
      "393 {'train': [-1.3199151454200794e-05, -3.830542945436944e-05, -5.9662105129923774e-05, -7.517863826503187e-05, -8.333616248638539e-05, -8.333616248638558e-05, -7.517863826503187e-05], 'target': -4.5896410202973696e-05}\n",
      "394 {'train': [-3.830542945436944e-05, -5.9662105129923774e-05, -7.517863826503187e-05, -8.333616248638539e-05, -8.333616248638558e-05, -7.517863826503187e-05, -5.966210512992378e-05], 'target': -5.0876562631167925e-05}\n",
      "395 {'train': [-5.9662105129923774e-05, -7.517863826503187e-05, -8.333616248638539e-05, -8.333616248638558e-05, -7.517863826503187e-05, -5.966210512992378e-05, -3.830542945436943e-05], 'target': -5.087656263116802e-05}\n",
      "396 {'train': [-7.517863826503187e-05, -8.333616248638539e-05, -8.333616248638558e-05, -7.517863826503187e-05, -5.966210512992378e-05, -3.830542945436943e-05, -1.3199151454200735e-05], 'target': -4.589641020297369e-05}\n",
      "397 {'train': [-8.333616248638539e-05, -8.333616248638558e-05, -7.517863826503187e-05, -5.966210512992378e-05, -3.830542945436943e-05, -1.3199151454200735e-05, 1.3199151454200782e-05], 'target': -3.6423597365018894e-05}\n",
      "398 {'train': [-8.333616248638558e-05, -7.517863826503187e-05, -5.966210512992378e-05, -3.830542945436943e-05, -1.3199151454200735e-05, 1.3199151454200782e-05, 3.83054294543694e-05], 'target': -2.3385389038850858e-05}\n",
      "399 {'train': [-7.517863826503187e-05, -5.966210512992378e-05, -3.830542945436943e-05, -1.3199151454200735e-05, 1.3199151454200782e-05, 3.83054294543694e-05, 5.966210512992389e-05], 'target': -8.05805589797373e-06}\n"
     ]
    }
   ],
   "source": [
    "x, t, solu = gen_analytical_cell_averaged(delta_x=1/10, delta_t=1/20, xmin=0, tmin=0, xmax=2, tmax=1, analytical_eq=heat_equ_analytical_solu)\n",
    "print(solu[0])\n",
    "pairs = get_trainingset_all(solu, 3, 3, recursive_padding)\n",
    "for i, p in enumerate(pairs):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# FullconnectedResNet\n",
    "# ==============\n",
    "\n",
    "class FullconnectedResNet(nn.Module):\n",
    "    def __init__(self, i, o, layer_data, hasDropout, p, num, weight=1, active=nn.Tanh()):\n",
    "        super(FullconnectedResNet, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module(\"linear_1\", nn.Linear(i, layer_data[0]))\n",
    "        if hasDropout:\n",
    "            self.layers.add_module(\"dropout_1\", nn.Dropout(p=p))\n",
    "        self.layers.add_module(\"relu_1\", active)\n",
    "        for index in range(len(layer_data)-1):\n",
    "            self.layers.add_module(\"linear_\"+str(index+2), nn.Linear(layer_data[index], layer_data[index+1]))\n",
    "            if hasDropout:\n",
    "                self.layers.add_module(\"dropout_2\", nn.Dropout(p=p))\n",
    "            self.layers.add_module(\"relu_\"+str(index+2), active)\n",
    "        self.layers.add_module(\"linear_3\"+str(len(layer_data)+1), nn.Linear(layer_data[len(layer_data)-1], o))\n",
    "        if hasDropout:\n",
    "            self.layers.add_module(\"dropout_3\", nn.Dropout(p=p))\n",
    "        self.layers.add_module(\"relu_\"+str(len(layer_data)+1), active)\n",
    "        self.num = num\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        return output + self.weight * x[self.num], x[self.num], output\n",
    "\n",
    "    def load_model(self, save_path):\n",
    "        self.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.state_dict(), save_path)\n",
    "        \n",
    "# ==========\n",
    "# BidirectionRNN\n",
    "# ==========\n",
    "\n",
    "# class BidirectionRNN(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer_of_nn(counter, train, target, loss, output, res, pure, TorE):\n",
    "    print(\"=\"*60)\n",
    "    print(\"This is\", counter+1, \"times of iteration\")\n",
    "    if TorE:\n",
    "        print(\"Training...\")\n",
    "    else:\n",
    "        print(\"Evaluating...\")\n",
    "    print(\"The input is:\", train)\n",
    "    print(\"The output is:\", output)\n",
    "    print(\"The correct solution is:\", target)\n",
    "    print(\"The pure output is:\", pure)\n",
    "    print(\"The res input is:\", res)\n",
    "    if TorE:\n",
    "        print(\"The training loss is:\", loss)\n",
    "    else:\n",
    "        print(\"The evaluation loss is:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_config_generator(\n",
    "    delta_x, delta_t, xmin, tmin, xmax, tmax, analytical_eq, gen_analytical_method, allTheTime,\n",
    "    num1, num2, padding, train_takeAll, eval_takeAll, size1, size2,\n",
    "    layer_data, nn_model, optim, learning_rate, iteration, hasDropout, p, weight, active,\n",
    "    loading, load_path,\n",
    "    x_file, t_file, actual_solu_file, config_file, train_loss_file, model_file, eval_loss_file, prediction_file\n",
    "):\n",
    "    data_setting = {'delta_x': delta_x,'delta_t': delta_t,'xmin': xmin, 'tmin': tmin, 'xmax': xmax, 'tmax': tmax, 'PDE': str(analytical_eq), 'method': str(gen_analytical_method), 'allTheTime': allTheTime}\n",
    "    pairs_setting = {'left': num1,'right': num2, 'dim': num1+num2+1, 'padding': str(padding), 'train_takeAll': train_takeAll, 'eval_takeAll': eval_takeAll, 'size_train': size1, 'size_eval': size2}\n",
    "    nn_setting = {'model': str(nn_model), 'layer_data': layer_data, 'input': num1+num2+1, 'output': 1, 'hasDropout': hasDropout, 'dropout_rate': p, 'res_weight': weight, 'active': str(active)}\n",
    "    optim_setting = {'optimizer': str(optim), 'learning_rate': learning_rate}\n",
    "    model_setting = {'nn_model': nn_setting, 'optim': optim_setting, 'iteration': iteration, 'is_loading': loading, 'loading_path': load_path}\n",
    "    x_file_setting = {'path': x_file, 'explain': 'x'}\n",
    "    t_file_setting = {'path': t_file, 'explain': 't'}\n",
    "    actual_solu_file_setting = {'path': actual_solu_file, 'explain': 'the actual/correct/analytical solutions'}\n",
    "    config_file_setting = {'path': config_file, 'explain': 'the current file, store all the configurations of each experiment'}\n",
    "    train_loss_file_setting = {'path': train_loss_file, 'explain': 'the training loss'}\n",
    "    model_file_setting = {'path': model_file, 'explain': 'the saved model, can be loaded for further training'}\n",
    "    eval_loss_file_setting = {'path': eval_loss_file, 'explain': 'the evaluation loss'}\n",
    "    prediction_file_setting = {'path': prediction_file, 'explain': 'final predictions'}\n",
    "    files = {\n",
    "        'x_file_setting': x_file_setting,\n",
    "        't_file_setting': t_file_setting,\n",
    "        'actual_solu_file_setting': actual_solu_file_setting,\n",
    "        'config_file_setting': config_file_setting,\n",
    "        'train_loss_file_setting': train_loss_file_setting,\n",
    "        'model_file_setting': model_file_setting,\n",
    "        'eval_loss_file_setting': eval_loss_file_setting,\n",
    "        'prediction_file_setting': prediction_file_setting\n",
    "    }\n",
    "    json_data = {\n",
    "        'data_setting': data_setting,\n",
    "        'pairs_setting': pairs_setting,\n",
    "        'model_setting': model_setting,\n",
    "        'files_setting': files\n",
    "    }\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_the_model(\n",
    "    folder_name,\n",
    "    delta_x=1/20, delta_t=1/10, xmin=0, tmin=0, xmax=1, tmax=2, analytical_eq=heat_equ_analytical_solu, gen_analytical_method=gen_analytical_cell_averaged, allTheTime=False,\n",
    "    num1=3, num2=3, padding=recursive_padding, train_takeAll=True, eval_takeAll=True, size1=0, size2=0,\n",
    "    layer_data=[6, 6], nn_model=FullconnectedResNet, optim=optim.Adam, learning_rate=0.001, iteration=100, hasDropout=False, p=0.2, weight=1, active=nn.Tanh,\n",
    "    loading=False, load_path=\"\",\n",
    "    config_file=\"config.json\", actual_solu_file='actual solution.csv', x_file='x.csv', t_file='t.csv',\n",
    "    train_loss_file='training loss.txt', model_file='model',\n",
    "    eval_loss_file='evaluation loss.txt', prediction_file='prediction.csv',\n",
    "    doEval=True, printTraining=False, printEval=False\n",
    "):\n",
    "    # ====================\n",
    "    # Configuration and parameters\n",
    "    # ====================\n",
    "    json_data = json_config_generator(\n",
    "    delta_x, delta_t, xmin, tmin, xmax, tmax, analytical_eq, gen_analytical_method, allTheTime,\n",
    "    num1, num2, padding, train_takeAll, eval_takeAll, size1, size2,\n",
    "    layer_data, nn_model, optim, learning_rate, iteration, hasDropout, p, weight, active,\n",
    "    loading, load_path,\n",
    "    x_file, t_file, actual_solu_file, config_file, train_loss_file, model_file, eval_loss_file, prediction_file)\n",
    "    # ==================\n",
    "    # Creating pathes and config\n",
    "    # ==================\n",
    "    x_file = folder_name+\"/\"+x_file\n",
    "    t_file = folder_name+\"/\"+t_file\n",
    "    actual_solu_file = folder_name+\"/\"+actual_solu_file\n",
    "    config_file = folder_name+\"/\"+config_file\n",
    "    train_loss_file = folder_name+\"/\"+train_loss_file\n",
    "    model_file = folder_name+\"/\"+model_file\n",
    "    eval_loss_file = folder_name+\"/\"+eval_loss_file\n",
    "    prediction_file = folder_name+\"/\"+prediction_file\n",
    "    # ==========\n",
    "    # Creating folder\n",
    "    # ==========\n",
    "    mkdir(folder_name)\n",
    "    # ===========\n",
    "    # Prepare the data\n",
    "    # ===========\n",
    "    x, t, solu = gen_analytical_method(delta_x=delta_x, delta_t=delta_t, xmin=xmin, tmin=tmin, xmax=xmax, tmax=tmax, analytical_eq=analytical_eq)\n",
    "    actual_solu = solu\n",
    "    if not allTheTime:\n",
    "        solu = solu[:2]\n",
    "    # ===========\n",
    "    # Prepare the pairs\n",
    "    # ===========\n",
    "    if train_takeAll:\n",
    "        pairs = get_trainingset_all(solu, num1, num2, padding)\n",
    "    else:\n",
    "        pairs = get_trainingset_random(solu, num1, num2, padding, size)\n",
    "    # =================\n",
    "    # Set up model & optimizer\n",
    "    # =================\n",
    "    model = nn_model(i=num1+num2+1, o=1, layer_data=layer_data, hasDropout=hasDropout, p=p, num=num1, weight=weight, active=active)\n",
    "    if loading:\n",
    "        model.load_model(load_path)\n",
    "    optimizer = optim(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    # ===========\n",
    "    # Train the model\n",
    "    # ===========\n",
    "    model.train()\n",
    "    list_of_losses_t = []\n",
    "    list_of_outputs = []\n",
    "    counter = 0\n",
    "    for itera in range(iteration):\n",
    "        for pair in pairs:\n",
    "            train = torch.FloatTensor(pair[\"train\"])\n",
    "            target = torch.FloatTensor([pair[\"target\"]])\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            output, res, pure = model(train)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            list_of_losses_t.append(loss.item())\n",
    "            list_of_outputs.append(output)\n",
    "        if printTraining:\n",
    "            printer_of_nn(counter=counter, train=train, target=target, loss=loss, output=output, res=res, pure=pure, TorE=True)\n",
    "        counter += 1\n",
    "    # for parameter in model.parameters():\n",
    "    #     print(parameter)\n",
    "    # =====\n",
    "    # Saving\n",
    "    # =====\n",
    "    save_csv(actual_solu_file, actual_solu)\n",
    "    save_csv(x_file, [x])\n",
    "    save_csv(t_file, [t])\n",
    "    save_json(config_file, json_data)\n",
    "    save_list(train_loss_file, list_of_losses_t)\n",
    "    model.save_model(model_file)\n",
    "    # ==========\n",
    "    # Do we do eval?\n",
    "    # ==========\n",
    "    if not doEval:\n",
    "        return 0\n",
    "    # ===========\n",
    "    # Prepare the pairs\n",
    "    # ===========\n",
    "    if eval_takeAll:\n",
    "        eval_pairs = get_testingset_all(actual_solu, num1, num2, padding)\n",
    "    else:\n",
    "        eval_pairs = get_testingset_random(actual_solu, num1, num2, padding, size)\n",
    "    # =============\n",
    "    # Evaluate the model\n",
    "    # =============\n",
    "    model.eval()\n",
    "    list_of_losses_e = []\n",
    "    prediction = [solu[0]]\n",
    "    counter = 0\n",
    "    for j in range(len(eval_pairs)):\n",
    "        pairs_t = eval_pairs[j]\n",
    "        prediction_t = []\n",
    "        for pair in pairs_t:\n",
    "            train = torch.FloatTensor(pair[\"train\"])\n",
    "            target = torch.FloatTensor([pair[\"target\"]])\n",
    "            output, res, pure = model(train)\n",
    "            loss = criterion(output, target)\n",
    "            list_of_losses_e.append(loss.item())\n",
    "            prediction_t.append(output.item())\n",
    "            if printTraining:\n",
    "                printer_of_nn(counter=counter, train=train, target=target, loss=loss, output=output, res=res, pure=pure, TorE=False)\n",
    "        counter += 1\n",
    "        prediction.append(prediction_t)\n",
    "    # =====\n",
    "    # Saving\n",
    "    # =====\n",
    "    save_list(eval_loss_file, list_of_losses_e)\n",
    "    save_csv(prediction_file, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1186], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2744], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0457, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1184], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2742], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0456, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1182], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2740], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0455, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1180], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2738], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0454, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1178], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2736], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0453, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1176], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2734], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0452, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1174], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2732], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1172], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2730], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1170], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2728], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0450, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1168], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2726], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0449, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1166], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2724], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1164], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2722], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0447, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1162], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2720], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1160], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2718], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1158], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2716], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0445, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1156], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2714], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0444, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1154], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2712], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0443, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1152], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2710], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0442, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1150], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2708], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0441, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1148], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2706], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0441, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 21 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1146], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2704], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0440, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 22 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1144], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2702], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0439, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 23 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1142], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2700], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0438, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 24 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1140], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2698], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0437, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 25 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1138], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2696], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 26 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1136], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2694], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 27 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1134], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2692], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 28 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1132], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2690], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0434, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 29 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1130], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2688], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0433, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 30 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1128], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2686], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0432, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 31 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1126], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2684], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0431, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 32 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1124], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2682], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0430, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 33 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1122], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2680], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0430, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 34 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1120], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2678], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0429, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 35 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1118], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2676], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0428, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 36 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2674], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0427, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 37 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1114], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2672], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 38 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1112], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2670], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0425, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 39 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1110], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2668], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0425, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 40 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1108], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2665], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0424, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 41 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1106], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2663], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0423, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 42 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1104], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2661], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0422, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 43 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1102], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2659], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0421, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 44 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1100], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2657], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 45 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1097], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2655], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 46 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1095], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2653], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0419, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 47 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1093], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2651], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0418, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 48 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1091], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2649], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0417, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 49 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1089], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2647], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0416, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 50 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1087], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2645], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0416, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 51 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1085], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2643], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0415, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 52 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2641], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0414, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 53 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1081], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2639], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0413, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 54 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1079], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2637], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0412, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 55 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1077], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2635], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0411, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 56 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1075], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2633], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0411, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 57 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1073], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2631], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0410, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 58 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2629], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0409, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 59 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1069], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2627], grad_fn=<HardtanhBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0408, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 60 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1067], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2625], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0407, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 61 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1065], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2623], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0406, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 62 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1063], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2621], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0406, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 63 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1061], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2619], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 64 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1059], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2617], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0404, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 65 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1057], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2615], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0403, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 66 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1055], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2613], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0402, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 67 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0402, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 68 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0401, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 69 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1049], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0400, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 70 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1047], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2605], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0399, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 71 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1045], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2603], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0398, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 72 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1043], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2600], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 73 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1041], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2598], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 74 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1038], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2596], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0396, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 75 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1036], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2594], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0395, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 76 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1034], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2592], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 77 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1032], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2590], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0393, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 78 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2588], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0393, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 79 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1028], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2586], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0392, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 80 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2584], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 81 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1024], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2582], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0390, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 82 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1022], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2580], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 83 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2578], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 84 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1018], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2576], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0388, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 85 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2574], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0387, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 86 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1014], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2572], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0386, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 87 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2570], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0385, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 88 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2568], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 89 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1008], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2565], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 90 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1006], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2563], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0383, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 91 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2561], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 92 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.1001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2559], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 93 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0999], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2557], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 94 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0997], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2555], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 95 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0995], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2553], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0379, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 96 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0993], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2551], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0378, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 97 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0991], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2549], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0377, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 98 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0989], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2547], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0376, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 99 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0987], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2545], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0376, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 100 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0985], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2543], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0375, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 101 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0983], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2541], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0374, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 102 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0981], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2538], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0373, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 103 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0978], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2536], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0372, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 104 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0976], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2534], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0372, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 105 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0974], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0371, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 106 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0972], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2530], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 107 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0970], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2528], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0369, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 108 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0968], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2526], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 109 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0966], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2524], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 110 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0964], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2522], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0367, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 111 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0962], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2520], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0366, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 112 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0960], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2518], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0365, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 113 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0958], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2515], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0364, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 114 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0955], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2513], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0363, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 115 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0953], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2511], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0363, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 116 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2509], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0362, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 117 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2507], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0361, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 118 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2505], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0360, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 119 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0945], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2503], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0359, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 120 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0943], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2501], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0359, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 121 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0941], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2499], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0358, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 122 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0939], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2496], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0357, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 123 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0936], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2494], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0356, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 124 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0934], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2492], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0355, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 125 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0932], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2490], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0355, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 126 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0930], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2488], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0354, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 127 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0928], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2486], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0353, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 128 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0926], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2484], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0352, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 129 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0924], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2482], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0351, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 130 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0921], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2479], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0351, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 131 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0919], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2477], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0350, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 132 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0917], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2475], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0349, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 133 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0915], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2473], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0348, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 134 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0913], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2471], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0347, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 135 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0911], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2468], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0347, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 136 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0908], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2466], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0346, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 137 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0906], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2464], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0345, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 138 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0904], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2462], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0344, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 139 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0902], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2460], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0343, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 140 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0900], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2457], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0342, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 141 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0897], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2455], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0342, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 142 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0895], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2453], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0341, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 143 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0893], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2451], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0340, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 144 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0891], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2449], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 145 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0888], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2446], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 146 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0886], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2444], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 147 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0884], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2442], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 148 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0882], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2439], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 149 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0879], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2437], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0335, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 150 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0877], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2435], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0334, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 151 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0875], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2433], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0333, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 152 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0872], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2430], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0333, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 153 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0870], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2428], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0332, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 154 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0868], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2426], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0331, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 155 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0866], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2423], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0330, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 156 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0863], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2421], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0329, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 157 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0861], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2419], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0328, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 158 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0859], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2417], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0328, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 159 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0856], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2414], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 160 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0854], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2412], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0326, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 161 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0852], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2410], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0325, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 162 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0850], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2408], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0324, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 163 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0847], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2405], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 164 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0845], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2403], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 165 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0843], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2401], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0322, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 166 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0840], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2398], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0321, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 167 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0838], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2396], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0320, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 168 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0836], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2394], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 169 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2392], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 170 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0831], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2389], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0318, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 171 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0829], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2387], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0317, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 172 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0827], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2385], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0316, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 173 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0824], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2382], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 174 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0822], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2380], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 175 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0820], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2378], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 176 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0818], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2375], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0313, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 177 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0815], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2373], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0312, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 178 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0813], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2371], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0311, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 179 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0811], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2369], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 180 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0808], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2366], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 181 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0806], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2364], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0309, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 182 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0804], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2362], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0308, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 183 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0801], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2359], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0307, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 184 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0799], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2357], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 185 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0797], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2355], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 186 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0795], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2352], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0305, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 187 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0792], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2350], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0304, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 188 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0790], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2348], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0303, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 189 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0788], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2346], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 190 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0785], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2343], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 191 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0783], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2341], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0301, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 192 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0781], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2339], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0300, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 193 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0778], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2336], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0299, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 194 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0776], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2334], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0298, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 195 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0774], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2332], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0298, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 196 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0771], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2329], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 197 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0769], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2327], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0296, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 198 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0767], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2325], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 199 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0765], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2322], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 200 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0762], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2320], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 201 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2318], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0293, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 202 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0758], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2315], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 203 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0755], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2313], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 204 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2311], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0290, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 205 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0751], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2309], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0290, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 206 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0748], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2306], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0289, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 207 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0746], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2304], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0288, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 208 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0744], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2302], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0287, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 209 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0741], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2299], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 210 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0739], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2297], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 211 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0737], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2295], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0285, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 212 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0734], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2292], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 213 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0732], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2290], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0283, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 214 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0730], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2288], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 215 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0727], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2285], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 216 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0725], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2283], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0281, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 217 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0723], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2280], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0280, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 218 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0720], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2278], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0279, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 219 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0718], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2276], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0279, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 220 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0716], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2273], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0278, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 221 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0713], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2271], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 222 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0711], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2269], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 223 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0708], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2266], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0275, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 224 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0706], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2264], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0275, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 225 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0704], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2262], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 226 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0701], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2259], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 227 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0699], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2257], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 228 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0697], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2255], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 229 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0694], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2252], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 230 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0692], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2250], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0270, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 231 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0690], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2248], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 232 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0687], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 233 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0685], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2243], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 234 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0683], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2240], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 235 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0680], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2238], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 236 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0678], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2236], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 237 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0675], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 238 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0673], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2231], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 239 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0671], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2229], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0263, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 240 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0668], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 241 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2224], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 242 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0664], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2221], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 243 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0661], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2219], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 244 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0659], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2217], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 245 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0656], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2214], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 246 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0654], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2212], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 247 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0652], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2209], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0257, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 248 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0649], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2207], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 249 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0647], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2205], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 250 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0644], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2202], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0255, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 251 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0642], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2200], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 252 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0640], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0253, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 253 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0637], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2195], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 254 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0635], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2193], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 255 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0632], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2190], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 256 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0630], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2188], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 257 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2185], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 258 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2183], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 259 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0623], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2181], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 260 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0620], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2178], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0247, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 261 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0618], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2176], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 262 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0615], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2173], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 263 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0613], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2171], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 264 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0611], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2169], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 265 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0608], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2166], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 266 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0606], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2164], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 267 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0603], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2161], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 268 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0601], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2159], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0241, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 269 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0599], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2156], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 270 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0596], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2154], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0239, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 271 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0594], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2152], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 272 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0591], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2149], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0238, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 273 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0589], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2147], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 274 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0586], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2144], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0236, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 275 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0584], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0236, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 276 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0581], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2139], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0235, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 277 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0579], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2137], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 278 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0577], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2134], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 279 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0574], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2132], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 280 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0572], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2130], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 281 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0569], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2127], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 282 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0567], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2125], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 283 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0564], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2122], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 284 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0562], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2120], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0229, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 285 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0559], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2117], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0228, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 286 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0557], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2115], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 287 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0554], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2112], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 288 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0552], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2110], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 289 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0549], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2107], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 290 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0547], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2105], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 291 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0545], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2102], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0224, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 292 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0542], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2100], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 293 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0540], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2097], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 294 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0537], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2095], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 295 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0535], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2093], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 296 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0532], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2090], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 297 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0530], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2088], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0219, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 298 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0527], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2085], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0219, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 299 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0525], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2083], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 300 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0522], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2080], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 301 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0520], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2078], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 302 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0517], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2075], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 303 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0515], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2073], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 304 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0512], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2070], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 305 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0510], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2068], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 306 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0507], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2065], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 307 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0505], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2063], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 308 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0502], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2060], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 309 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0500], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2058], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 310 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0497], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2055], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 311 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0495], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2053], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 312 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0492], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2050], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0208, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 313 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0490], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2047], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 314 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0487], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 315 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0484], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2042], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 316 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0482], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2040], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 317 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0479], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2037], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 318 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0477], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2035], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 319 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0474], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2032], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 320 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0472], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2030], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 321 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0469], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2027], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 322 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0467], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2025], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 323 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0464], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2022], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 324 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0462], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2020], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 325 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0459], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2017], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 326 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0457], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2014], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 327 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0454], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 328 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0451], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2009], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 329 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0449], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 330 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0446], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 331 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0444], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.2002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 332 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0441], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1999], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 333 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0439], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1997], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 334 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0436], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1994], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 335 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0434], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1991], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 336 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0431], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1989], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 337 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0428], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1986], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 338 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0426], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1984], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 339 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0423], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1981], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 340 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0421], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1979], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0188, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 341 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0418], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1976], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 342 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0416], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1973], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 343 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0413], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1971], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 344 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0410], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1968], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 345 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0408], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1966], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 346 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0405], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1963], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 347 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0403], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1960], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0183, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 348 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0400], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1958], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0183, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 349 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0397], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1955], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 350 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0395], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1953], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0181, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 351 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0392], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1950], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 352 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0390], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1947], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 353 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0387], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1945], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 354 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0384], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1942], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 355 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0382], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1940], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 356 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0379], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1937], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 357 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0376], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1934], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 358 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0374], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1932], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 359 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0371], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1929], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0175, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 360 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0369], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1927], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0174, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 361 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1924], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 362 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0363], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1921], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 363 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0361], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1919], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 364 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0358], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1916], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 365 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0355], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1913], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 366 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0353], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1911], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 367 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0350], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1908], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 368 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0348], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1905], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 369 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0345], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1903], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 370 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0342], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1900], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0167, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 371 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0340], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1897], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0167, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 372 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0337], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1895], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 373 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0334], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1892], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 374 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0332], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1890], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 375 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0329], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1887], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 376 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0326], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1884], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 377 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0324], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1882], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 378 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0321], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1879], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 379 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0318], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1876], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0161, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 380 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0316], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1874], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 381 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0313], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1871], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0160, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 382 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0310], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1868], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 383 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0308], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1866], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 384 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0305], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1863], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 385 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0302], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1860], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0157, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 386 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0300], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1857], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 387 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0297], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1855], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 388 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0294], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1852], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 389 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0291], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1849], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 390 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0289], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1847], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 391 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0286], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1844], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 392 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0283], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1841], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 393 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0281], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1839], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 394 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0278], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1836], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 395 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0275], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1833], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 396 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0273], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1830], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 397 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0270], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1828], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 398 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0267], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1825], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 399 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0264], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1822], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0148, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 400 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0262], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1820], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 401 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0259], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1817], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 402 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0256], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1814], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 403 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0254], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1811], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 404 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0251], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1809], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 405 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0248], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1806], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 406 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0245], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1803], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 407 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0243], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1801], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 408 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0240], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1798], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 409 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0237], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1795], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 410 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0234], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1792], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 411 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0232], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1790], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 412 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0229], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1787], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 413 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0226], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1784], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 414 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1781], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 415 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0221], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1779], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 416 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0218], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1776], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 417 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0215], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1773], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 418 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0212], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure output is: tensor([0.1770], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 419 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0210], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1768], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 420 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0207], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1765], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 421 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0204], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1762], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 422 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0201], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1759], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 423 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0199], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1756], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 424 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0196], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1754], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 425 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0193], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1751], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 426 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0190], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1748], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 427 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0187], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1745], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 428 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0185], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 429 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0182], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1740], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 430 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0179], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1737], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 431 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0176], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1734], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 432 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0173], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1731], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 433 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1729], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 434 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0168], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1726], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0125, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 435 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0165], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1723], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0125, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 436 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0162], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1720], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0124, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 437 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0159], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1717], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 438 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0157], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1715], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 439 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0154], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1712], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 440 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0151], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1709], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0121, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 441 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0148], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1706], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 442 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0145], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1703], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 443 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1700], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 444 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0140], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1698], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 445 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0137], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1695], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0118, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 446 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0134], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1692], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0118, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 447 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0131], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1689], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 448 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0128], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1686], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 449 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0126], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1683], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 450 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0123], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1681], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0115, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 451 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0120], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1678], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0115, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 452 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0117], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1675], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 453 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0114], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1672], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 454 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0111], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1669], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 455 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0109], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1666], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 456 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0106], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1664], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 457 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0103], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1661], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 458 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0100], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1658], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 459 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0097], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1655], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0110, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 460 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0094], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1652], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 461 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0091], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1649], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 462 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0088], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1646], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0108, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 463 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0086], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1644], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 464 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1641], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 465 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0080], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1638], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 466 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0077], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1635], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 467 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0074], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1632], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 468 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1629], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 469 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0068], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1626], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 470 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0065], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1623], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 471 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0063], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1621], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 472 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0060], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1618], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 473 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0057], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1615], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 474 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0054], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1612], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 475 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 476 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0048], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1606], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 477 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0045], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1603], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 478 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0042], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1600], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 479 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0039], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1597], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 480 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0036], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1594], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 481 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0033], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1591], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 482 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1588], grad_fn=<HardtanhBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 483 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0027], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1585], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 484 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0025], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1582], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 485 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0022], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1580], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 486 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1577], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 487 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1574], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 488 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0013], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1571], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 489 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1568], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 490 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1565], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 491 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1562], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 492 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([9.4488e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1559], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 493 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1556], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 494 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1553], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 495 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0008], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1550], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 496 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0011], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1547], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 497 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0014], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1544], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 498 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0017], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1541], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 499 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1538], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 500 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0023], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1535], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 501 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 502 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0029], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1529], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 503 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0032], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1526], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 504 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0035], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1523], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 505 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0038], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1520], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 506 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0041], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1517], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 507 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0044], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1514], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 508 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0047], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1511], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 509 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0050], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1508], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 510 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1505], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 511 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0056], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1502], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 512 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0059], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1499], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 513 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0062], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1496], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 514 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0065], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1493], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 515 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0068], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1490], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 516 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1487], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 517 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0074], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1484], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 518 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0077], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1481], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 519 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0080], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1478], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 520 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1475], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 521 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0086], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1472], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 522 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0089], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1469], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 523 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0092], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1466], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss is: tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 524 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0095], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1463], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 525 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0098], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1460], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 526 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0101], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1457], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 527 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0104], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1454], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 528 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0107], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1451], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 529 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0110], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1448], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 530 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0113], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1445], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 531 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1442], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 532 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0119], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1439], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 533 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0122], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1436], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 534 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0125], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1433], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 535 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0128], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1430], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 536 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0131], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1427], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 537 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0134], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1424], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 538 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0137], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1421], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 539 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0140], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1418], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 540 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1415], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 541 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0146], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1412], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 542 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0149], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1409], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 543 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0152], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1406], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 544 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0155], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1403], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 545 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0158], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1400], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0063, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 546 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0161], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1396], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 547 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0165], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1393], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 548 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0168], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1390], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 549 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1387], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 550 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0174], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1384], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 551 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0177], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1381], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 552 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0180], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1378], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 553 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0183], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1375], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 554 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0186], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1372], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 555 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0189], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1369], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 556 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0192], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1366], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 557 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0195], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1363], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 558 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0198], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1360], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 559 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0201], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1357], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 560 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0204], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1354], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 561 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0207], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1350], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 562 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0211], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1347], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 563 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0214], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1344], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0054, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 564 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0217], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1341], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 565 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0220], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1338], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 566 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1335], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 567 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0226], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1332], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 568 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0229], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1329], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 569 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0232], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1326], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 570 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0235], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1323], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 571 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0238], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1320], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 572 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0241], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1316], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 573 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0245], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1313], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 574 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0248], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1310], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 575 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0251], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1307], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 576 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0254], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1304], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 577 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0257], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1301], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 578 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0260], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1298], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 579 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0263], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1295], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 580 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0266], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1292], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 581 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0269], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1289], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 582 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0272], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1285], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 583 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0276], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1282], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 584 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0279], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1279], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0045, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 585 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0282], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1276], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 586 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0285], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1273], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 587 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0288], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1270], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 588 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0291], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1267], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 589 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0294], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1264], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 590 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0297], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1261], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 591 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0300], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1257], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 592 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0304], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1254], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 593 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0307], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1251], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 594 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0310], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1248], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 595 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0313], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 596 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0316], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1242], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 597 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0319], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1239], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 598 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0322], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1236], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 599 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0325], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 600 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0329], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1229], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 601 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0332], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 602 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0335], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1223], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 603 times of iteration\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0338], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1220], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 604 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0341], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1217], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 605 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0344], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1214], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 606 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0347], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1211], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 607 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0350], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1208], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 608 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0354], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1204], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 609 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0357], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1201], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 610 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0360], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 611 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0363], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1195], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 612 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1192], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 613 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0369], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1189], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 614 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0372], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1186], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 615 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0375], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1182], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 616 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0379], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1179], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 617 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0382], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1176], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 618 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0385], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1173], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 619 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0388], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1170], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 620 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0391], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1167], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 621 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0394], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1164], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 622 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0397], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1161], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 623 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0400], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1157], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0030, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 624 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0404], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1154], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 625 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0407], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1151], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 626 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0410], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1148], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 627 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0413], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1145], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 628 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0416], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 629 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0419], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1139], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 630 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0422], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1136], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 631 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0425], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1132], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 632 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0429], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1129], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 633 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0432], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1126], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 634 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0435], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1123], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 635 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0438], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1120], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 636 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0441], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1117], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 637 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0444], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1114], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 638 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0447], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1111], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 639 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0450], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1107], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 640 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0454], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1104], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 641 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0457], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1101], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 642 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0460], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1098], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 643 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0463], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1095], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 644 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0466], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1092], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 645 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0469], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1089], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 646 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0472], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1086], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 647 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0475], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1083], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 648 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0478], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1079], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 649 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0482], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1076], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 650 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0485], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1073], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 651 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0488], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1070], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 652 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0491], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1067], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 653 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0494], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1064], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 654 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0497], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1061], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 655 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0500], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1058], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 656 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0503], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1055], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 657 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0506], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1052], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 658 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0509], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1048], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 659 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0513], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 660 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0516], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1042], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 661 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0519], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1039], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 662 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0522], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1036], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 663 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0525], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1033], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 664 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0528], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1030], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 665 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0531], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1027], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 666 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0534], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1024], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 667 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0537], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1021], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 668 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0540], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1018], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 669 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0543], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1015], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss is: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 670 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0546], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 671 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0549], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1008], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 672 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0553], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1005], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 673 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0556], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.1002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 674 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0559], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0999], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 675 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0562], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0996], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 676 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0565], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0993], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 677 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0568], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0990], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 678 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0571], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0987], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 679 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0574], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0984], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 680 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0577], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0981], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 681 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0580], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0978], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 682 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0583], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0975], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 683 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0586], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0972], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 684 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0589], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0969], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 685 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0592], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0966], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 686 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0595], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0963], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 687 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0598], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0960], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 688 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0601], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0957], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 689 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0604], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0954], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0012, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 690 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0607], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0951], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 691 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0610], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0948], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 692 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0613], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0945], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 693 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0616], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0942], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 694 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0619], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0939], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 695 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0622], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0936], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 696 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0933], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 697 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0930], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 698 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0631], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0927], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 699 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0634], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0924], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 700 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0637], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0921], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 701 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0640], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0918], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 702 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0643], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0915], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 703 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0645], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0912], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 704 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0648], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0910], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 705 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0651], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0907], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 706 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0654], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0904], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 707 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0657], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0901], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 708 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0660], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0898], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 709 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0663], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0895], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 710 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0892], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 711 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0669], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0889], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 712 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0671], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0887], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 713 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0674], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0884], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 714 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0677], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0881], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 715 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0680], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0878], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 716 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0683], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0875], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 717 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0686], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0872], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 718 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0688], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0870], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 719 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0691], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0867], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 720 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0694], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0864], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 721 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0697], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0861], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 722 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0700], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0858], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 723 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0702], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0856], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 724 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0705], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0853], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 725 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0708], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0850], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 726 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0711], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0847], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 727 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0713], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0845], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 728 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0716], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0842], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 729 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0719], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0839], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 730 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0721], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0837], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 731 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0724], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0834], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 732 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0727], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0831], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 733 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0729], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0829], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 734 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0732], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0826], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 735 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0735], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0823], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 736 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0737], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0821], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 737 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0740], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0818], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 738 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0742], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0815], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 739 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0745], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0813], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 740 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0748], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0810], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 741 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0750], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0808], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 742 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0805], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 743 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0755], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0803], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 744 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0758], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0800], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 745 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0798], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 746 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0763], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0795], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 747 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0765], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0793], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 748 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0768], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0790], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 749 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0770], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0788], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 750 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0773], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0785], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 751 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0775], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0783], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 752 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0778], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0780], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 753 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0780], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0778], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 754 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0783], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0775], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 755 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: tensor([-0.0785], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0773], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 756 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0787], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0771], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 757 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0790], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0768], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 758 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0792], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0766], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 759 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0794], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0764], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 760 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0797], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0761], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 761 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0799], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0759], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 762 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0801], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0757], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 763 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0804], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0754], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 764 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0806], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0752], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 765 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0808], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0750], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 766 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0810], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0748], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 767 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0812], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0745], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 768 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0815], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 769 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0817], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0741], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 770 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0819], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0739], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 771 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0821], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0737], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 772 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0823], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0735], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 773 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0825], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0733], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 774 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0827], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0730], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 775 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0830], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0728], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 776 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0832], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0726], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 777 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0724], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 778 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0836], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0722], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 779 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0838], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0720], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 780 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0840], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0718], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 781 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0842], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0716], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 782 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0844], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0714], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 783 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0846], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0712], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 784 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0847], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0710], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 785 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0849], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0709], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 786 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0851], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0707], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.9734e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 787 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0853], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0705], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.6043e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 788 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0855], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0703], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.2457e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 789 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0857], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0701], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.8973e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 790 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0859], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0699], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.5591e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 791 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0860], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0698], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.2308e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 792 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0862], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0696], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.9125e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 793 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0864], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0694], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.6036e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 794 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0866], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0692], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.3042e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 795 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0867], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0691], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.0141e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 796 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0869], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0689], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.7329e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 797 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0871], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0687], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.4605e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 798 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0872], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0686], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.1967e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 799 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0874], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0684], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.9415e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 800 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0876], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0682], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.6946e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 801 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0877], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0681], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.4558e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 802 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0879], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0679], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.2250e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 803 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0880], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0678], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.0019e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 804 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0882], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0676], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.7865e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 805 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0883], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0674], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.5784e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 806 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0885], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0673], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.3776e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 807 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0886], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0671], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.1838e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 808 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0888], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0670], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.9969e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 809 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0889], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0669], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.8168e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 810 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0891], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0667], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.6431e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 811 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0892], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0666], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.4759e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 812 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0894], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0664], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.3150e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 813 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0895], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0663], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.1600e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 814 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0896], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0662], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.0111e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 815 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0898], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0660], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8677e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 816 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0899], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0659], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.7299e-05, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 817 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0900], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0658], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.5977e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 818 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0901], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0657], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.4705e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 819 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0903], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0655], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.3485e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 820 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0904], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0654], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.2316e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 821 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0905], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0653], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.1193e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 822 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0906], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0652], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.0118e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 823 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0907], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0651], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.9087e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 824 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0909], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0649], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.8101e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 825 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0910], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0648], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.7157e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 826 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0911], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0647], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.6253e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 827 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0912], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0646], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.5390e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 828 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0913], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0645], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4565e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 829 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0914], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0644], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3776e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 830 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0915], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0643], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3024e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 831 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0916], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0642], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2306e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 832 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0917], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0641], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.1621e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 833 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0918], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0640], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0968e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 834 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0919], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0639], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0346e-05, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 835 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0920], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0638], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.7546e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 836 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0921], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0637], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.1914e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 837 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0922], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0636], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.6557e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 838 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0923], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0635], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.1464e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 839 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0923], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0634], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.6630e-06, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 840 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0924], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0634], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.2036e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 841 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0925], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0633], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.7679e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 842 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0926], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0632], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.3548e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 843 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0927], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0631], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.9634e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 844 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0927], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0630], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.5929e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 845 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0928], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0630], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.2419e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 846 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0929], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0629], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.9098e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 847 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0930], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0628], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.5959e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 848 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0930], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0628], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.2996e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 849 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0931], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0627], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.0193e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 850 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0932], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0626], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.7553e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 851 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0932], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0626], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.5061e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 852 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0933], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0625], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.2713e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 853 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0934], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.0501e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 854 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0934], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8420e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 855 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0935], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0623], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.6462e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 856 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0935], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0623], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.4624e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 857 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0936], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0622], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.2895e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 858 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0937], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0621], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.1273e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 859 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0937], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0621], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.9753e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 860 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0938], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0620], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.8328e-06, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 861 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0938], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0620], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.6993e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 862 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0939], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0619], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.5744e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 863 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0939], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0619], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4574e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 864 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0939], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0618], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3481e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 865 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0940], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0618], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2461e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 866 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0940], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0618], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.1508e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 867 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0941], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0617], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0620e-06, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 868 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0941], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0617], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.7943e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 869 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0942], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0616], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.0250e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 870 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0942], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0616], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.3096e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 871 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0942], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0616], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.6448e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 872 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0943], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0615], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.0261e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 873 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0943], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0615], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.4533e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 874 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0943], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0615], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.9225e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 875 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0944], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0614], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.4303e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 876 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0944], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0614], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.9747e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 877 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0944], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0614], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.5528e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 878 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0945], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0613], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.1639e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 879 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0945], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0613], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.8044e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 880 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0945], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0613], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.4726e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 881 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0945], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0612], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.1675e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 882 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0946], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure output is: tensor([0.0612], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8859e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 883 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0946], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0612], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.6268e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 884 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0946], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0612], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.3894e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 885 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0946], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.1712e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 886 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.9707e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 887 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.7874e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 888 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.6198e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 889 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0611], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4663e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 890 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0947], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3254e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 891 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.1972e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 892 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0806e-07, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 893 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.7423e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 894 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.7729e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 895 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0610], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.8935e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 896 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0948], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.0931e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 897 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.3655e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 898 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.7071e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 899 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.1096e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 900 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.5695e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 901 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.0852e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 902 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.6468e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 903 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.2515e-08, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 904 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0949], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0609], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8956e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 905 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.5772e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 906 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.2914e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 907 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.0332e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 908 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.8024e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 909 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.5952e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 910 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4112e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 911 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2467e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 912 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0997e-08, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 913 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.6825e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 914 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.5148e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 915 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.4812e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 916 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.5699e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 917 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.7539e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 918 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0608], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.0373e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 919 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.4059e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 920 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0950], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.8454e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 921 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.3531e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 922 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.9130e-09, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 923 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.5262e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 924 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.1949e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 925 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.9043e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 926 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.6482e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 927 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4241e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 928 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2252e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 929 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0548e-09, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 930 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.0334e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 931 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.7605e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 932 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.6456e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 933 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.6772e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 934 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.8702e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 935 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.1858e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 936 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.6011e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 937 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.1049e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 938 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.6819e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 939 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.3170e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 940 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.0209e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 941 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.7707e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 942 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.5574e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 943 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3753e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 944 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2094e-10, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 945 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0710e-10, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 946 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.4537e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 947 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.3030e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 948 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.3925e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 949 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.5711e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 950 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.8663e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 951 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.2230e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 952 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.6781e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 953 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.2210e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 954 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.7874e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 955 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.4120e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 956 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.1059e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 957 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8141e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 958 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.5518e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 959 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.3453e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 960 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.1132e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 961 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.9127e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 962 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.7721e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 963 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.5889e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 964 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.4382e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 965 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.3274e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 966 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.2210e-11, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "This is 967 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0993e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 968 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(1.0264e-11, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 969 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(9.2406e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 970 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(8.5301e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 971 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.8897e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 972 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(7.3955e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 973 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.9172e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 974 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.4928e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 975 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(6.0819e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 976 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.7199e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 977 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.5431e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 978 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(5.3346e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 979 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.9960e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 980 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.9960e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 981 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.6685e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 982 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.6043e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 983 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.4145e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 984 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.3521e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 985 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(4.1676e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 986 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.9277e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 987 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.9277e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 988 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.7526e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 989 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.6380e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 990 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.5252e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 991 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.5252e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 992 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.3049e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 993 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.3049e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 994 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(3.1444e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 995 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.9878e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 996 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.9365e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 997 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.8857e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 998 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.7358e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 999 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.6867e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1000 times of iteration\n",
      "Training...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The training loss is: tensor(2.4949e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042,  0.8873])\n",
      "The output is: tensor([0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0951])\n",
      "The pure output is: tensor([-0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1558)\n",
      "The evaluation loss is: tensor(2.9878e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.4521, -0.1558,  0.1558,  0.4521,  0.7042,  0.8873,  0.9836])\n",
      "The output is: tensor([0.2760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2760])\n",
      "The pure output is: tensor([-0.1761], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.4521)\n",
      "The evaluation loss is: tensor(2.9878e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1558,  0.1558,  0.4521,  0.7042,  0.8873,  0.9836,  0.9836])\n",
      "The output is: tensor([0.4299], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.4299])\n",
      "The pure output is: tensor([-0.2743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.7042)\n",
      "The evaluation loss is: tensor(2.6867e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.1558, 0.4521, 0.7042, 0.8873, 0.9836, 0.9836, 0.8873])\n",
      "The output is: tensor([0.5417], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.5417])\n",
      "The pure output is: tensor([-0.3456], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.8873)\n",
      "The evaluation loss is: tensor(1.8794e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.4521, 0.7042, 0.8873, 0.9836, 0.9836, 0.8873, 0.7042])\n",
      "The output is: tensor([0.6005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.6005])\n",
      "The pure output is: tensor([-0.3831], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.9836)\n",
      "The evaluation loss is: tensor(1.1511e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.7042, 0.8873, 0.9836, 0.9836, 0.8873, 0.7042, 0.4521])\n",
      "The output is: tensor([0.6005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.6005])\n",
      "The pure output is: tensor([-0.3831], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.9836)\n",
      "The evaluation loss is: tensor(6.0041e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.8873, 0.9836, 0.9836, 0.8873, 0.7042, 0.4521, 0.1558])\n",
      "The output is: tensor([0.5417], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.5417])\n",
      "The pure output is: tensor([-0.3456], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.8873)\n",
      "The evaluation loss is: tensor(8.8818e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.9836,  0.9836,  0.8873,  0.7042,  0.4521,  0.1558, -0.1558])\n",
      "The output is: tensor([0.4299], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.4299])\n",
      "The pure output is: tensor([-0.2743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.7042)\n",
      "The evaluation loss is: tensor(8.8818e-16, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.9836,  0.8873,  0.7042,  0.4521,  0.1558, -0.1558, -0.4521])\n",
      "The output is: tensor([0.2760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2760])\n",
      "The pure output is: tensor([-0.1761], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.4521)\n",
      "The evaluation loss is: tensor(8.8818e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.8873,  0.7042,  0.4521,  0.1558, -0.1558, -0.4521, -0.7042])\n",
      "The output is: tensor([0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0951])\n",
      "The pure output is: tensor([-0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1558)\n",
      "The evaluation loss is: tensor(2.6429e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.7042,  0.4521,  0.1558, -0.1558, -0.4521, -0.7042, -0.8873])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The evaluation loss is: tensor(4.2988e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.4521,  0.1558, -0.1558, -0.4521, -0.7042, -0.8873, -0.9836])\n",
      "The output is: tensor([-0.2760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2760])\n",
      "The pure output is: tensor([0.1761], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.4521)\n",
      "The evaluation loss is: tensor(3.9169e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1558, -0.1558, -0.4521, -0.7042, -0.8873, -0.9836, -0.9836])\n",
      "The output is: tensor([-0.4299], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.4299])\n",
      "The pure output is: tensor([0.2743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.7042)\n",
      "The evaluation loss is: tensor(3.2063e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1558, -0.4521, -0.7042, -0.8873, -0.9836, -0.9836, -0.8873])\n",
      "The output is: tensor([-0.5417], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.5417])\n",
      "The pure output is: tensor([0.3456], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.8873)\n",
      "The evaluation loss is: tensor(8.8818e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.4521, -0.7042, -0.8873, -0.9836, -0.9836, -0.8873, -0.7042])\n",
      "The output is: tensor([-0.6005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.6005])\n",
      "The pure output is: tensor([0.3831], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.9836)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation loss is: tensor(3.5527e-15, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.7042, -0.8873, -0.9836, -0.9836, -0.8873, -0.7042, -0.4521])\n",
      "The output is: tensor([-0.6005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.6005])\n",
      "The pure output is: tensor([0.3831], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.9836)\n",
      "The evaluation loss is: tensor(1.2790e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.8873, -0.9836, -0.9836, -0.8873, -0.7042, -0.4521, -0.1558])\n",
      "The output is: tensor([-0.5417], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.5417])\n",
      "The pure output is: tensor([0.3456], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.8873)\n",
      "The evaluation loss is: tensor(6.0041e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.9836, -0.9836, -0.8873, -0.7042, -0.4521, -0.1558,  0.1558])\n",
      "The output is: tensor([-0.4299], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.4299])\n",
      "The pure output is: tensor([0.2743], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.7042)\n",
      "The evaluation loss is: tensor(1.0880e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.9836, -0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521])\n",
      "The output is: tensor([-0.2760], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2760])\n",
      "The pure output is: tensor([0.1761], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.4521)\n",
      "The evaluation loss is: tensor(1.8794e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 1 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.8873, -0.7042, -0.4521, -0.1558,  0.1558,  0.4521,  0.7042])\n",
      "The output is: tensor([-0.0951], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0951])\n",
      "The pure output is: tensor([0.0607], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1558)\n",
      "The evaluation loss is: tensor(2.4949e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.4299, -0.2760, -0.0951,  0.0951,  0.2760,  0.4299,  0.5417])\n",
      "The output is: tensor([0.0581], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0581])\n",
      "The pure output is: tensor([-0.0370], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0951)\n",
      "The evaluation loss is: tensor(1.5667e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2760, -0.0951,  0.0951,  0.2760,  0.4299,  0.5417,  0.6005])\n",
      "The output is: tensor([0.1685], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1685])\n",
      "The pure output is: tensor([-0.1075], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2760)\n",
      "The evaluation loss is: tensor(1.6043e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0951,  0.0951,  0.2760,  0.4299,  0.5417,  0.6005,  0.6005])\n",
      "The output is: tensor([0.2625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2625])\n",
      "The pure output is: tensor([-0.1675], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.4299)\n",
      "The evaluation loss is: tensor(1.4211e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0951, 0.2760, 0.4299, 0.5417, 0.6005, 0.6005, 0.5417])\n",
      "The output is: tensor([0.3307], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.3307])\n",
      "The pure output is: tensor([-0.2110], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.5417)\n",
      "The evaluation loss is: tensor(1.1511e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.2760, 0.4299, 0.5417, 0.6005, 0.6005, 0.5417, 0.4299])\n",
      "The output is: tensor([0.3666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.3666])\n",
      "The pure output is: tensor([-0.2339], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.6005)\n",
      "The evaluation loss is: tensor(6.9633e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.4299, 0.5417, 0.6005, 0.6005, 0.5417, 0.4299, 0.2760])\n",
      "The output is: tensor([0.3666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.3666])\n",
      "The pure output is: tensor([-0.2339], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.6005)\n",
      "The evaluation loss is: tensor(4.2988e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.5417, 0.6005, 0.6005, 0.5417, 0.4299, 0.2760, 0.0951])\n",
      "The output is: tensor([0.3307], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.3307])\n",
      "The pure output is: tensor([-0.2110], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.5417)\n",
      "The evaluation loss is: tensor(1.9984e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.6005,  0.6005,  0.5417,  0.4299,  0.2760,  0.0951, -0.0951])\n",
      "The output is: tensor([0.2625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2625])\n",
      "The pure output is: tensor([-0.1675], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.4299)\n",
      "The evaluation loss is: tensor(4.3521e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.6005,  0.5417,  0.4299,  0.2760,  0.0951, -0.0951, -0.2760])\n",
      "The output is: tensor([0.1685], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1685])\n",
      "The pure output is: tensor([-0.1075], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2760)\n",
      "The evaluation loss is: tensor(2.2204e-16, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.5417,  0.4299,  0.2760,  0.0951, -0.0951, -0.2760, -0.4299])\n",
      "The output is: tensor([0.0581], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0581])\n",
      "The pure output is: tensor([-0.0370], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0951)\n",
      "The evaluation loss is: tensor(1.3337e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.4299,  0.2760,  0.0951, -0.0951, -0.2760, -0.4299, -0.5417])\n",
      "The output is: tensor([-0.0581], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0581])\n",
      "The pure output is: tensor([0.0370], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0951)\n",
      "The evaluation loss is: tensor(2.8103e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.2760,  0.0951, -0.0951, -0.2760, -0.4299, -0.5417, -0.6005])\n",
      "The output is: tensor([-0.1685], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1685])\n",
      "The pure output is: tensor([0.1075], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2760)\n",
      "The evaluation loss is: tensor(2.6867e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0951, -0.0951, -0.2760, -0.4299, -0.5417, -0.6005, -0.6005])\n",
      "The output is: tensor([-0.2625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2625])\n",
      "The pure output is: tensor([0.1675], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.4299)\n",
      "The evaluation loss is: tensor(7.9936e-15, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0951, -0.2760, -0.4299, -0.5417, -0.6005, -0.6005, -0.5417])\n",
      "The output is: tensor([-0.3307], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.3307])\n",
      "The pure output is: tensor([0.2110], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.5417)\n",
      "The evaluation loss is: tensor(0., grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.2760, -0.4299, -0.5417, -0.6005, -0.6005, -0.5417, -0.4299])\n",
      "The output is: tensor([-0.3666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.3666])\n",
      "The pure output is: tensor([0.2339], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.6005)\n",
      "The evaluation loss is: tensor(5.6843e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.4299, -0.5417, -0.6005, -0.6005, -0.5417, -0.4299, -0.2760])\n",
      "The output is: tensor([-0.3666], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.3666])\n",
      "The pure output is: tensor([0.2339], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.6005)\n",
      "The evaluation loss is: tensor(1.9984e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.5417, -0.6005, -0.6005, -0.5417, -0.4299, -0.2760, -0.0951])\n",
      "The output is: tensor([-0.3307], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.3307])\n",
      "The pure output is: tensor([0.2110], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.5417)\n",
      "The evaluation loss is: tensor(4.2988e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.6005, -0.6005, -0.5417, -0.4299, -0.2760, -0.0951,  0.0951])\n",
      "The output is: tensor([-0.2625], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2625])\n",
      "The pure output is: tensor([0.1675], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.4299)\n",
      "The evaluation loss is: tensor(7.4696e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.6005, -0.5417, -0.4299, -0.2760, -0.0951,  0.0951,  0.2760])\n",
      "The output is: tensor([-0.1685], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1685])\n",
      "The pure output is: tensor([0.1075], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2760)\n",
      "The evaluation loss is: tensor(1.1193e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 2 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.5417, -0.4299, -0.2760, -0.0951,  0.0951,  0.2760,  0.4299])\n",
      "The output is: tensor([-0.0581], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0581])\n",
      "The pure output is: tensor([0.0370], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0951)\n",
      "The evaluation loss is: tensor(1.4479e-12, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2625, -0.1685, -0.0581,  0.0581,  0.1685,  0.2625,  0.3307])\n",
      "The output is: tensor([0.0354], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0354])\n",
      "The pure output is: tensor([-0.0226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0581)\n",
      "The evaluation loss is: tensor(9.6723e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1685, -0.0581,  0.0581,  0.1685,  0.2625,  0.3307,  0.3666])\n",
      "The output is: tensor([0.1029], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1029])\n",
      "The pure output is: tensor([-0.0656], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1685)\n",
      "The evaluation loss is: tensor(9.5263e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0581,  0.0581,  0.1685,  0.2625,  0.3307,  0.3666,  0.3666])\n",
      "The output is: tensor([0.1602], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1602])\n",
      "The pure output is: tensor([-0.1022], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2625)\n",
      "The evaluation loss is: tensor(8.2623e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0581, 0.1685, 0.2625, 0.3307, 0.3666, 0.3666, 0.3307])\n",
      "The output is: tensor([0.2019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2019])\n",
      "The pure output is: tensor([-0.1288], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.3307)\n",
      "The evaluation loss is: tensor(7.2142e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.1685, 0.2625, 0.3307, 0.3666, 0.3666, 0.3307, 0.2625])\n",
      "The output is: tensor([0.2238], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2238])\n",
      "The pure output is: tensor([-0.1428], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.3666)\n",
      "The evaluation loss is: tensor(5.5511e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.2625, 0.3307, 0.3666, 0.3666, 0.3307, 0.2625, 0.1685])\n",
      "The output is: tensor([0.2238], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2238])\n",
      "The pure output is: tensor([-0.1428], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.3666)\n",
      "The evaluation loss is: tensor(3.7326e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.3307, 0.3666, 0.3666, 0.3307, 0.2625, 0.1685, 0.0581])\n",
      "The output is: tensor([0.2019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.2019])\n",
      "The pure output is: tensor([-0.1288], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.3307)\n",
      "The evaluation loss is: tensor(1.9984e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.3666,  0.3666,  0.3307,  0.2625,  0.1685,  0.0581, -0.0581])\n",
      "The output is: tensor([0.1602], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1602])\n",
      "The pure output is: tensor([-0.1022], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2625)\n",
      "The evaluation loss is: tensor(1.0747e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.3666,  0.3307,  0.2625,  0.1685,  0.0581, -0.0581, -0.1685])\n",
      "The output is: tensor([0.1029], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1029])\n",
      "The pure output is: tensor([-0.0656], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1685)\n",
      "The evaluation loss is: tensor(4.6685e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.3307,  0.2625,  0.1685,  0.0581, -0.0581, -0.1685, -0.2625])\n",
      "The output is: tensor([0.0354], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0354])\n",
      "The pure output is: tensor([-0.0226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0581)\n",
      "The evaluation loss is: tensor(2.1108e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.2625,  0.1685,  0.0581, -0.0581, -0.1685, -0.2625, -0.3307])\n",
      "The output is: tensor([-0.0354], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0354])\n",
      "The pure output is: tensor([0.0226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0581)\n",
      "The evaluation loss is: tensor(1.0880e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1685,  0.0581, -0.0581, -0.1685, -0.2625, -0.3307, -0.3666])\n",
      "The output is: tensor([-0.1029], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1029])\n",
      "The pure output is: tensor([0.0656], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1685)\n",
      "The evaluation loss is: tensor(1.0880e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0581, -0.0581, -0.1685, -0.2625, -0.3307, -0.3666, -0.3666])\n",
      "The output is: tensor([-0.1602], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1602])\n",
      "The pure output is: tensor([0.1022], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2625)\n",
      "The evaluation loss is: tensor(2.6867e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0581, -0.1685, -0.2625, -0.3307, -0.3666, -0.3666, -0.3307])\n",
      "The output is: tensor([-0.2019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2019])\n",
      "The pure output is: tensor([0.1288], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.3307)\n",
      "The evaluation loss is: tensor(4.9960e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1685, -0.2625, -0.3307, -0.3666, -0.3666, -0.3307, -0.2625])\n",
      "The output is: tensor([-0.2238], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2238])\n",
      "The pure output is: tensor([0.1428], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.3666)\n",
      "The evaluation loss is: tensor(9.7922e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2625, -0.3307, -0.3666, -0.3666, -0.3307, -0.2625, -0.1685])\n",
      "The output is: tensor([-0.2238], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2238])\n",
      "The pure output is: tensor([0.1428], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.3666)\n",
      "The evaluation loss is: tensor(2.1338e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.3307, -0.3666, -0.3666, -0.3307, -0.2625, -0.1685, -0.0581])\n",
      "The output is: tensor([-0.2019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.2019])\n",
      "The pure output is: tensor([0.1288], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.3307)\n",
      "The evaluation loss is: tensor(3.7326e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([-0.3666, -0.3666, -0.3307, -0.2625, -0.1685, -0.0581,  0.0581])\n",
      "The output is: tensor([-0.1602], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1602])\n",
      "The pure output is: tensor([0.1022], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2625)\n",
      "The evaluation loss is: tensor(5.7754e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.3666, -0.3307, -0.2625, -0.1685, -0.0581,  0.0581,  0.1685])\n",
      "The output is: tensor([-0.1029], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1029])\n",
      "The pure output is: tensor([0.0656], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1685)\n",
      "The evaluation loss is: tensor(7.2142e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 3 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.3307, -0.2625, -0.1685, -0.0581,  0.0581,  0.1685,  0.2625])\n",
      "The output is: tensor([-0.0354], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0354])\n",
      "The pure output is: tensor([0.0226], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0581)\n",
      "The evaluation loss is: tensor(8.5354e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1602, -0.1029, -0.0354,  0.0354,  0.1029,  0.1602,  0.2019])\n",
      "The output is: tensor([0.0216], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0216])\n",
      "The pure output is: tensor([-0.0138], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0354)\n",
      "The evaluation loss is: tensor(6.4150e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1029, -0.0354,  0.0354,  0.1029,  0.1602,  0.2019,  0.2238])\n",
      "The output is: tensor([0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0628])\n",
      "The pure output is: tensor([-0.0401], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1029)\n",
      "The evaluation loss is: tensor(6.4748e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0354,  0.0354,  0.1029,  0.1602,  0.2019,  0.2238,  0.2238])\n",
      "The output is: tensor([0.0978], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0978])\n",
      "The pure output is: tensor([-0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1602)\n",
      "The evaluation loss is: tensor(6.0041e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0354, 0.1029, 0.1602, 0.2019, 0.2238, 0.2238, 0.2019])\n",
      "The output is: tensor([0.1233], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1233])\n",
      "The pure output is: tensor([-0.0786], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2019)\n",
      "The evaluation loss is: tensor(5.2230e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.1029, 0.1602, 0.2019, 0.2238, 0.2238, 0.2019, 0.1602])\n",
      "The output is: tensor([0.1366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1366])\n",
      "The pure output is: tensor([-0.0872], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2238)\n",
      "The evaluation loss is: tensor(4.1056e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.1602, 0.2019, 0.2238, 0.2238, 0.2019, 0.1602, 0.1029])\n",
      "The output is: tensor([0.1366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1366])\n",
      "The pure output is: tensor([-0.0872], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2238)\n",
      "The evaluation loss is: tensor(3.2063e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.2019, 0.2238, 0.2238, 0.2019, 0.1602, 0.1029, 0.0354])\n",
      "The output is: tensor([0.1233], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.1233])\n",
      "The pure output is: tensor([-0.0786], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.2019)\n",
      "The evaluation loss is: tensor(2.4181e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.2238,  0.2238,  0.2019,  0.1602,  0.1029,  0.0354, -0.0354])\n",
      "The output is: tensor([0.0978], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0978])\n",
      "The pure output is: tensor([-0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1602)\n",
      "The evaluation loss is: tensor(1.6792e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.2238,  0.2019,  0.1602,  0.1029,  0.0354, -0.0354, -0.1029])\n",
      "The output is: tensor([0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0628])\n",
      "The pure output is: tensor([-0.0401], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1029)\n",
      "The evaluation loss is: tensor(1.2262e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.2019,  0.1602,  0.1029,  0.0354, -0.0354, -0.1029, -0.1602])\n",
      "The output is: tensor([0.0216], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0216])\n",
      "The pure output is: tensor([-0.0138], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0354)\n",
      "The evaluation loss is: tensor(8.4432e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1602,  0.1029,  0.0354, -0.0354, -0.1029, -0.1602, -0.2019])\n",
      "The output is: tensor([-0.0216], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0216])\n",
      "The pure output is: tensor([0.0138], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0354)\n",
      "The evaluation loss is: tensor(7.5995e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1029,  0.0354, -0.0354, -0.1029, -0.1602, -0.2019, -0.2238])\n",
      "The output is: tensor([-0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0628])\n",
      "The pure output is: tensor([0.0401], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1029)\n",
      "The evaluation loss is: tensor(7.5995e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0354, -0.0354, -0.1029, -0.1602, -0.2019, -0.2238, -0.2238])\n",
      "The output is: tensor([-0.0978], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0978])\n",
      "The pure output is: tensor([0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1602)\n",
      "The evaluation loss is: tensor(9.7922e-14, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0354, -0.1029, -0.1602, -0.2019, -0.2238, -0.2238, -0.2019])\n",
      "The output is: tensor([-0.1233], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1233])\n",
      "The pure output is: tensor([0.0786], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2019)\n",
      "The evaluation loss is: tensor(1.2790e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1029, -0.1602, -0.2019, -0.2238, -0.2238, -0.2019, -0.1602])\n",
      "The output is: tensor([-0.1366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1366])\n",
      "The pure output is: tensor([0.0872], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2238)\n",
      "The evaluation loss is: tensor(1.7408e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1602, -0.2019, -0.2238, -0.2238, -0.2019, -0.1602, -0.1029])\n",
      "The output is: tensor([-0.1366], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1366])\n",
      "The pure output is: tensor([0.0872], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2238)\n",
      "The evaluation loss is: tensor(2.5668e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2019, -0.2238, -0.2238, -0.2019, -0.1602, -0.1029, -0.0354])\n",
      "The output is: tensor([-0.1233], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.1233])\n",
      "The pure output is: tensor([0.0786], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.2019)\n",
      "The evaluation loss is: tensor(3.5527e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2238, -0.2238, -0.2019, -0.1602, -0.1029, -0.0354,  0.0354])\n",
      "The output is: tensor([-0.0978], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0978])\n",
      "The pure output is: tensor([0.0624], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1602)\n",
      "The evaluation loss is: tensor(4.6985e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2238, -0.2019, -0.1602, -0.1029, -0.0354,  0.0354,  0.1029])\n",
      "The output is: tensor([-0.0628], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0628])\n",
      "The pure output is: tensor([0.0401], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1029)\n",
      "The evaluation loss is: tensor(5.1159e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 4 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.2019, -0.1602, -0.1029, -0.0354,  0.0354,  0.1029,  0.1602])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: tensor([-0.0216], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0216])\n",
      "The pure output is: tensor([0.0138], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0354)\n",
      "The evaluation loss is: tensor(6.0041e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0978, -0.0628, -0.0216,  0.0216,  0.0628,  0.0978,  0.1233])\n",
      "The output is: tensor([0.0132], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0132])\n",
      "The pure output is: tensor([-0.0084], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0216)\n",
      "The evaluation loss is: tensor(5.0099e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0628, -0.0216,  0.0216,  0.0628,  0.0978,  0.1233,  0.1366])\n",
      "The output is: tensor([0.0383], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0383])\n",
      "The pure output is: tensor([-0.0245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0628)\n",
      "The evaluation loss is: tensor(4.8012e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0216,  0.0216,  0.0628,  0.0978,  0.1233,  0.1366,  0.1366])\n",
      "The output is: tensor([0.0597], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0597])\n",
      "The pure output is: tensor([-0.0381], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0978)\n",
      "The evaluation loss is: tensor(4.5969e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0216, 0.0628, 0.0978, 0.1233, 0.1366, 0.1366, 0.1233])\n",
      "The output is: tensor([0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0753])\n",
      "The pure output is: tensor([-0.0480], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1233)\n",
      "The evaluation loss is: tensor(4.2988e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0628, 0.0978, 0.1233, 0.1366, 0.1366, 0.1233, 0.0978])\n",
      "The output is: tensor([0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0834])\n",
      "The pure output is: tensor([-0.0532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1366)\n",
      "The evaluation loss is: tensor(3.7326e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0978, 0.1233, 0.1366, 0.1366, 0.1233, 0.0978, 0.0628])\n",
      "The output is: tensor([0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0834])\n",
      "The pure output is: tensor([-0.0532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1366)\n",
      "The evaluation loss is: tensor(3.1225e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.1233, 0.1366, 0.1366, 0.1233, 0.0978, 0.0628, 0.0216])\n",
      "The output is: tensor([0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0753])\n",
      "The pure output is: tensor([-0.0480], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.1233)\n",
      "The evaluation loss is: tensor(2.6429e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1366,  0.1366,  0.1233,  0.0978,  0.0628,  0.0216, -0.0216])\n",
      "The output is: tensor([0.0597], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0597])\n",
      "The pure output is: tensor([-0.0381], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0978)\n",
      "The evaluation loss is: tensor(2.0656e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1366,  0.1233,  0.0978,  0.0628,  0.0216, -0.0216, -0.0628])\n",
      "The output is: tensor([0.0383], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0383])\n",
      "The pure output is: tensor([-0.0245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0628)\n",
      "The evaluation loss is: tensor(1.6792e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.1233,  0.0978,  0.0628,  0.0216, -0.0216, -0.0628, -0.0978])\n",
      "The output is: tensor([0.0132], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0132])\n",
      "The pure output is: tensor([-0.0084], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0216)\n",
      "The evaluation loss is: tensor(1.5010e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0978,  0.0628,  0.0216, -0.0216, -0.0628, -0.0978, -0.1233])\n",
      "The output is: tensor([-0.0132], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0132])\n",
      "The pure output is: tensor([0.0084], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0216)\n",
      "The evaluation loss is: tensor(1.3878e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0628,  0.0216, -0.0216, -0.0628, -0.0978, -0.1233, -0.1366])\n",
      "The output is: tensor([-0.0383], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0383])\n",
      "The pure output is: tensor([0.0245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0628)\n",
      "The evaluation loss is: tensor(1.5010e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0216, -0.0216, -0.0628, -0.0978, -0.1233, -0.1366, -0.1366])\n",
      "The output is: tensor([-0.0597], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0597])\n",
      "The pure output is: tensor([0.0381], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0978)\n",
      "The evaluation loss is: tensor(1.6187e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0216, -0.0628, -0.0978, -0.1233, -0.1366, -0.1366, -0.1233])\n",
      "The output is: tensor([-0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0753])\n",
      "The pure output is: tensor([0.0480], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1233)\n",
      "The evaluation loss is: tensor(1.6792e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0628, -0.0978, -0.1233, -0.1366, -0.1366, -0.1233, -0.0978])\n",
      "The output is: tensor([-0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0834])\n",
      "The pure output is: tensor([0.0532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1366)\n",
      "The evaluation loss is: tensor(2.2737e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0978, -0.1233, -0.1366, -0.1366, -0.1233, -0.0978, -0.0628])\n",
      "The output is: tensor([-0.0834], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0834])\n",
      "The pure output is: tensor([0.0532], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1366)\n",
      "The evaluation loss is: tensor(2.4181e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1233, -0.1366, -0.1366, -0.1233, -0.0978, -0.0628, -0.0216])\n",
      "The output is: tensor([-0.0753], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0753])\n",
      "The pure output is: tensor([0.0480], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.1233)\n",
      "The evaluation loss is: tensor(3.2913e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1366, -0.1366, -0.1233, -0.0978, -0.0628, -0.0216,  0.0216])\n",
      "The output is: tensor([-0.0597], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0597])\n",
      "The pure output is: tensor([0.0381], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0978)\n",
      "The evaluation loss is: tensor(3.9169e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1366, -0.1233, -0.0978, -0.0628, -0.0216,  0.0216,  0.0628])\n",
      "The output is: tensor([-0.0383], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0383])\n",
      "The pure output is: tensor([0.0245], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0628)\n",
      "The evaluation loss is: tensor(4.3970e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 5 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.1233, -0.0978, -0.0628, -0.0216,  0.0216,  0.0628,  0.0978])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: tensor([-0.0132], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0132])\n",
      "The pure output is: tensor([0.0084], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0216)\n",
      "The evaluation loss is: tensor(4.8012e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0597, -0.0383, -0.0132,  0.0132,  0.0383,  0.0597,  0.0753])\n",
      "The output is: tensor([0.0081], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0081])\n",
      "The pure output is: tensor([-0.0051], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0132)\n",
      "The evaluation loss is: tensor(4.1415e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0383, -0.0132,  0.0132,  0.0383,  0.0597,  0.0753,  0.0834])\n",
      "The output is: tensor([0.0234], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0234])\n",
      "The pure output is: tensor([-0.0149], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0383)\n",
      "The evaluation loss is: tensor(4.2016e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0132,  0.0132,  0.0383,  0.0597,  0.0753,  0.0834,  0.0834])\n",
      "The output is: tensor([0.0365], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0365])\n",
      "The pure output is: tensor([-0.0233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0597)\n",
      "The evaluation loss is: tensor(3.9169e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0132, 0.0383, 0.0597, 0.0753, 0.0834, 0.0834, 0.0753])\n",
      "The output is: tensor([0.0459], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0459])\n",
      "The pure output is: tensor([-0.0293], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0753)\n",
      "The evaluation loss is: tensor(3.7782e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0383, 0.0597, 0.0753, 0.0834, 0.0834, 0.0753, 0.0597])\n",
      "The output is: tensor([0.0509], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0509])\n",
      "The pure output is: tensor([-0.0325], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0834)\n",
      "The evaluation loss is: tensor(3.5084e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0597, 0.0753, 0.0834, 0.0834, 0.0753, 0.0597, 0.0383])\n",
      "The output is: tensor([0.0509], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0509])\n",
      "The pure output is: tensor([-0.0325], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0834)\n",
      "The evaluation loss is: tensor(3.1225e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0753, 0.0834, 0.0834, 0.0753, 0.0597, 0.0383, 0.0132])\n",
      "The output is: tensor([0.0459], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0459])\n",
      "The pure output is: tensor([-0.0293], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0753)\n",
      "The evaluation loss is: tensor(2.6813e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0834,  0.0834,  0.0753,  0.0597,  0.0383,  0.0132, -0.0132])\n",
      "The output is: tensor([0.0365], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0365])\n",
      "The pure output is: tensor([-0.0233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0597)\n",
      "The evaluation loss is: tensor(2.4919e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0834,  0.0753,  0.0597,  0.0383,  0.0132, -0.0132, -0.0383])\n",
      "The output is: tensor([0.0234], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0234])\n",
      "The pure output is: tensor([-0.0149], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0383)\n",
      "The evaluation loss is: tensor(2.1338e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0753,  0.0597,  0.0383,  0.0132, -0.0132, -0.0383, -0.0597])\n",
      "The output is: tensor([0.0081], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0081])\n",
      "The pure output is: tensor([-0.0051], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0132)\n",
      "The evaluation loss is: tensor(1.9570e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0597,  0.0383,  0.0132, -0.0132, -0.0383, -0.0597, -0.0753])\n",
      "The output is: tensor([-0.0081], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0081])\n",
      "The pure output is: tensor([0.0051], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0132)\n",
      "The evaluation loss is: tensor(1.9079e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0383,  0.0132, -0.0132, -0.0383, -0.0597, -0.0753, -0.0834])\n",
      "The output is: tensor([-0.0234], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0234])\n",
      "The pure output is: tensor([0.0149], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0383)\n",
      "The evaluation loss is: tensor(1.8674e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0132, -0.0132, -0.0383, -0.0597, -0.0753, -0.0834, -0.0834])\n",
      "The output is: tensor([-0.0365], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0365])\n",
      "The pure output is: tensor([0.0233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0597)\n",
      "The evaluation loss is: tensor(1.9323e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0132, -0.0383, -0.0597, -0.0753, -0.0834, -0.0834, -0.0753])\n",
      "The output is: tensor([-0.0459], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0459])\n",
      "The pure output is: tensor([0.0293], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0753)\n",
      "The evaluation loss is: tensor(2.0996e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0383, -0.0597, -0.0753, -0.0834, -0.0834, -0.0753, -0.0597])\n",
      "The output is: tensor([-0.0509], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0509])\n",
      "The pure output is: tensor([0.0325], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0834)\n",
      "The evaluation loss is: tensor(2.3816e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0597, -0.0753, -0.0834, -0.0834, -0.0753, -0.0597, -0.0383])\n",
      "The output is: tensor([-0.0509], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0509])\n",
      "The pure output is: tensor([0.0325], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0834)\n",
      "The evaluation loss is: tensor(2.7590e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0753, -0.0834, -0.0834, -0.0753, -0.0597, -0.0383, -0.0132])\n",
      "The output is: tensor([-0.0459], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0459])\n",
      "The pure output is: tensor([0.0293], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0753)\n",
      "The evaluation loss is: tensor(2.9989e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0834, -0.0834, -0.0753, -0.0597, -0.0383, -0.0132,  0.0132])\n",
      "The output is: tensor([-0.0365], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0365])\n",
      "The pure output is: tensor([0.0233], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0597)\n",
      "The evaluation loss is: tensor(3.3773e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0834, -0.0753, -0.0597, -0.0383, -0.0132,  0.0132,  0.0383])\n",
      "The output is: tensor([-0.0234], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0234])\n",
      "The pure output is: tensor([0.0149], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0383)\n",
      "The evaluation loss is: tensor(3.7326e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 6 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0753, -0.0597, -0.0383, -0.0132,  0.0132,  0.0383,  0.0597])\n",
      "The output is: tensor([-0.0081], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0081])\n",
      "The pure output is: tensor([0.0051], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0132)\n",
      "The evaluation loss is: tensor(3.9754e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0365, -0.0234, -0.0081,  0.0081,  0.0234,  0.0365,  0.0459])\n",
      "The output is: tensor([0.0049], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0049])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure output is: tensor([-0.0031], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0081)\n",
      "The evaluation loss is: tensor(3.5917e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0234, -0.0081,  0.0081,  0.0234,  0.0365,  0.0459,  0.0509])\n",
      "The output is: tensor([0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0143])\n",
      "The pure output is: tensor([-0.0091], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0234)\n",
      "The evaluation loss is: tensor(3.6309e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0081,  0.0081,  0.0234,  0.0365,  0.0459,  0.0509,  0.0509])\n",
      "The output is: tensor([0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0223])\n",
      "The pure output is: tensor([-0.0142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0365)\n",
      "The evaluation loss is: tensor(3.5527e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0081, 0.0234, 0.0365, 0.0459, 0.0509, 0.0509, 0.0459])\n",
      "The output is: tensor([0.0280], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0280])\n",
      "The pure output is: tensor([-0.0179], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0459)\n",
      "The evaluation loss is: tensor(3.3773e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0234, 0.0365, 0.0459, 0.0509, 0.0509, 0.0459, 0.0365])\n",
      "The output is: tensor([0.0311], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0311])\n",
      "The pure output is: tensor([-0.0198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0509)\n",
      "The evaluation loss is: tensor(3.1434e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0365, 0.0459, 0.0509, 0.0509, 0.0459, 0.0365, 0.0234])\n",
      "The output is: tensor([0.0311], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0311])\n",
      "The pure output is: tensor([-0.0198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0509)\n",
      "The evaluation loss is: tensor(2.9380e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0459, 0.0509, 0.0509, 0.0459, 0.0365, 0.0234, 0.0081])\n",
      "The output is: tensor([0.0280], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0280])\n",
      "The pure output is: tensor([-0.0179], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0459)\n",
      "The evaluation loss is: tensor(2.7200e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0509,  0.0509,  0.0459,  0.0365,  0.0234,  0.0081, -0.0081])\n",
      "The output is: tensor([0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0223])\n",
      "The pure output is: tensor([-0.0142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0365)\n",
      "The evaluation loss is: tensor(2.6047e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0509,  0.0459,  0.0365,  0.0234,  0.0081, -0.0081, -0.0234])\n",
      "The output is: tensor([0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0143])\n",
      "The pure output is: tensor([-0.0091], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0234)\n",
      "The evaluation loss is: tensor(2.4826e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0459,  0.0365,  0.0234,  0.0081, -0.0081, -0.0234, -0.0365])\n",
      "The output is: tensor([0.0049], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0049])\n",
      "The pure output is: tensor([-0.0031], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0081)\n",
      "The evaluation loss is: tensor(2.3049e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0365,  0.0234,  0.0081, -0.0081, -0.0234, -0.0365, -0.0459])\n",
      "The output is: tensor([-0.0049], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0049])\n",
      "The pure output is: tensor([0.0031], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0081)\n",
      "The evaluation loss is: tensor(2.3139e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0234,  0.0081, -0.0081, -0.0234, -0.0365, -0.0459, -0.0509])\n",
      "The output is: tensor([-0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0143])\n",
      "The pure output is: tensor([0.0091], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0234)\n",
      "The evaluation loss is: tensor(2.1425e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0081, -0.0081, -0.0234, -0.0365, -0.0459, -0.0509, -0.0509])\n",
      "The output is: tensor([-0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0223])\n",
      "The pure output is: tensor([0.0142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0365)\n",
      "The evaluation loss is: tensor(2.4181e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0081, -0.0234, -0.0365, -0.0459, -0.0509, -0.0509, -0.0459])\n",
      "The output is: tensor([-0.0280], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0280])\n",
      "The pure output is: tensor([0.0179], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0459)\n",
      "The evaluation loss is: tensor(2.5668e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0234, -0.0365, -0.0459, -0.0509, -0.0509, -0.0459, -0.0365])\n",
      "The output is: tensor([-0.0311], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0311])\n",
      "The pure output is: tensor([0.0198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0509)\n",
      "The evaluation loss is: tensor(2.5857e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0365, -0.0459, -0.0509, -0.0509, -0.0459, -0.0365, -0.0234])\n",
      "The output is: tensor([-0.0311], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0311])\n",
      "The pure output is: tensor([0.0198], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0509)\n",
      "The evaluation loss is: tensor(2.8181e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0459, -0.0509, -0.0509, -0.0459, -0.0365, -0.0234, -0.0081])\n",
      "The output is: tensor([-0.0280], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0280])\n",
      "The pure output is: tensor([0.0179], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0459)\n",
      "The evaluation loss is: tensor(3.0398e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0509, -0.0509, -0.0459, -0.0365, -0.0234, -0.0081,  0.0081])\n",
      "The output is: tensor([-0.0223], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0223])\n",
      "The pure output is: tensor([0.0142], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0365)\n",
      "The evaluation loss is: tensor(3.2063e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0509, -0.0459, -0.0365, -0.0234, -0.0081,  0.0081,  0.0234])\n",
      "The output is: tensor([-0.0143], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0143])\n",
      "The pure output is: tensor([0.0091], grad_fn=<HardtanhBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The res input is: tensor(-0.0234)\n",
      "The evaluation loss is: tensor(3.2169e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 7 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0459, -0.0365, -0.0234, -0.0081,  0.0081,  0.0234,  0.0365])\n",
      "The output is: tensor([-0.0049], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0049])\n",
      "The pure output is: tensor([0.0031], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0081)\n",
      "The evaluation loss is: tensor(3.5140e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0223, -0.0143, -0.0049,  0.0049,  0.0143,  0.0223,  0.0280])\n",
      "The output is: tensor([0.0030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0030])\n",
      "The pure output is: tensor([-0.0019], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0049)\n",
      "The evaluation loss is: tensor(3.3936e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0143, -0.0049,  0.0049,  0.0143,  0.0223,  0.0280,  0.0311])\n",
      "The output is: tensor([0.0087], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0087])\n",
      "The pure output is: tensor([-0.0056], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0143)\n",
      "The evaluation loss is: tensor(3.2699e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0049,  0.0049,  0.0143,  0.0223,  0.0280,  0.0311,  0.0311])\n",
      "The output is: tensor([0.0136], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0136])\n",
      "The pure output is: tensor([-0.0087], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0223)\n",
      "The evaluation loss is: tensor(3.2699e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0049, 0.0143, 0.0223, 0.0280, 0.0311, 0.0311, 0.0280])\n",
      "The output is: tensor([0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0171])\n",
      "The pure output is: tensor([-0.0109], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0280)\n",
      "The evaluation loss is: tensor(3.1643e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0143, 0.0223, 0.0280, 0.0311, 0.0311, 0.0280, 0.0223])\n",
      "The output is: tensor([0.0190], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0190])\n",
      "The pure output is: tensor([-0.0121], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0311)\n",
      "The evaluation loss is: tensor(3.1017e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0223, 0.0280, 0.0311, 0.0311, 0.0280, 0.0223, 0.0143])\n",
      "The output is: tensor([0.0190], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0190])\n",
      "The pure output is: tensor([-0.0121], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0311)\n",
      "The evaluation loss is: tensor(2.9785e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0280, 0.0311, 0.0311, 0.0280, 0.0223, 0.0143, 0.0049])\n",
      "The output is: tensor([0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0171])\n",
      "The pure output is: tensor([-0.0109], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0280)\n",
      "The evaluation loss is: tensor(2.7983e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0311,  0.0311,  0.0280,  0.0223,  0.0143,  0.0049, -0.0049])\n",
      "The output is: tensor([0.0136], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0136])\n",
      "The pure output is: tensor([-0.0087], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0223)\n",
      "The evaluation loss is: tensor(2.6238e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0311,  0.0280,  0.0223,  0.0143,  0.0049, -0.0049, -0.0143])\n",
      "The output is: tensor([0.0087], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0087])\n",
      "The pure output is: tensor([-0.0056], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0143)\n",
      "The evaluation loss is: tensor(2.7007e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0280,  0.0223,  0.0143,  0.0049, -0.0049, -0.0143, -0.0223])\n",
      "The output is: tensor([0.0030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0030])\n",
      "The pure output is: tensor([-0.0019], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0049)\n",
      "The evaluation loss is: tensor(2.5810e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0223,  0.0143,  0.0049, -0.0049, -0.0143, -0.0223, -0.0280])\n",
      "The output is: tensor([-0.0030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0030])\n",
      "The pure output is: tensor([0.0019], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0049)\n",
      "The evaluation loss is: tensor(2.4780e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0143,  0.0049, -0.0049, -0.0143, -0.0223, -0.0280, -0.0311])\n",
      "The output is: tensor([-0.0087], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0087])\n",
      "The pure output is: tensor([0.0056], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0143)\n",
      "The evaluation loss is: tensor(2.5105e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0049, -0.0049, -0.0143, -0.0223, -0.0280, -0.0311, -0.0311])\n",
      "The output is: tensor([-0.0136], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0136])\n",
      "The pure output is: tensor([0.0087], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0223)\n",
      "The evaluation loss is: tensor(2.5857e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0049, -0.0143, -0.0223, -0.0280, -0.0311, -0.0311, -0.0280])\n",
      "The output is: tensor([-0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0171])\n",
      "The pure output is: tensor([0.0109], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0280)\n",
      "The evaluation loss is: tensor(2.7590e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0143, -0.0223, -0.0280, -0.0311, -0.0311, -0.0280, -0.0223])\n",
      "The output is: tensor([-0.0190], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0190])\n",
      "The pure output is: tensor([0.0121], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0311)\n",
      "The evaluation loss is: tensor(2.7007e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0223, -0.0280, -0.0311, -0.0311, -0.0280, -0.0223, -0.0143])\n",
      "The output is: tensor([-0.0190], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0190])\n",
      "The pure output is: tensor([0.0121], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0311)\n",
      "The evaluation loss is: tensor(2.8577e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0280, -0.0311, -0.0311, -0.0280, -0.0223, -0.0143, -0.0049])\n",
      "The output is: tensor([-0.0171], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0171])\n",
      "The pure output is: tensor([0.0109], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0280)\n",
      "The evaluation loss is: tensor(3.0810e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0311, -0.0311, -0.0280, -0.0223, -0.0143, -0.0049,  0.0049])\n",
      "The output is: tensor([-0.0136], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0136])\n",
      "The pure output is: tensor([0.0087], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0223)\n",
      "The evaluation loss is: tensor(3.0604e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0311, -0.0280, -0.0223, -0.0143, -0.0049,  0.0049,  0.0143])\n",
      "The output is: tensor([-0.0087], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0087])\n",
      "The pure output is: tensor([0.0056], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0143)\n",
      "The evaluation loss is: tensor(3.2275e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 8 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0280, -0.0223, -0.0143, -0.0049,  0.0049,  0.0143,  0.0223])\n",
      "The output is: tensor([-0.0030], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0030])\n",
      "The pure output is: tensor([0.0019], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0049)\n",
      "The evaluation loss is: tensor(3.1905e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0136, -0.0087, -0.0030,  0.0030,  0.0087,  0.0136,  0.0171])\n",
      "The output is: tensor([0.0018], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0018])\n",
      "The pure output is: tensor([-0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0030)\n",
      "The evaluation loss is: tensor(3.1056e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0087, -0.0030,  0.0030,  0.0087,  0.0136,  0.0171,  0.0190])\n",
      "The output is: tensor([0.0053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0053])\n",
      "The pure output is: tensor([-0.0034], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0087)\n",
      "The evaluation loss is: tensor(3.1695e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0030,  0.0030,  0.0087,  0.0136,  0.0171,  0.0190,  0.0190])\n",
      "The output is: tensor([0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0083])\n",
      "The pure output is: tensor([-0.0053], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0136)\n",
      "The evaluation loss is: tensor(3.2699e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0030, 0.0087, 0.0136, 0.0171, 0.0190, 0.0190, 0.0171])\n",
      "The output is: tensor([0.0105], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0105])\n",
      "The pure output is: tensor([-0.0067], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0171)\n",
      "The evaluation loss is: tensor(3.0398e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0087, 0.0136, 0.0171, 0.0190, 0.0190, 0.0171, 0.0136])\n",
      "The output is: tensor([0.0116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0116])\n",
      "The pure output is: tensor([-0.0074], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0190)\n",
      "The evaluation loss is: tensor(3.0091e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0136, 0.0171, 0.0190, 0.0190, 0.0171, 0.0136, 0.0087])\n",
      "The output is: tensor([0.0116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0116])\n",
      "The pure output is: tensor([-0.0074], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0190)\n",
      "The evaluation loss is: tensor(2.9279e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0171, 0.0190, 0.0190, 0.0171, 0.0136, 0.0087, 0.0030])\n",
      "The output is: tensor([0.0105], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0105])\n",
      "The pure output is: tensor([-0.0067], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0171)\n",
      "The evaluation loss is: tensor(2.7983e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0190,  0.0190,  0.0171,  0.0136,  0.0087,  0.0030, -0.0030])\n",
      "The output is: tensor([0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0083])\n",
      "The pure output is: tensor([-0.0053], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0136)\n",
      "The evaluation loss is: tensor(2.8577e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0190,  0.0171,  0.0136,  0.0087,  0.0030, -0.0030, -0.0087])\n",
      "The output is: tensor([0.0053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0053])\n",
      "The pure output is: tensor([-0.0034], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0087)\n",
      "The evaluation loss is: tensor(2.7639e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0171,  0.0136,  0.0087,  0.0030, -0.0030, -0.0087, -0.0136])\n",
      "The output is: tensor([0.0018], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0018])\n",
      "The pure output is: tensor([-0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0030)\n",
      "The evaluation loss is: tensor(2.7043e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0136,  0.0087,  0.0030, -0.0030, -0.0087, -0.0136, -0.0171])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: tensor([-0.0018], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0018])\n",
      "The pure output is: tensor([0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0030)\n",
      "The evaluation loss is: tensor(2.7359e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0087,  0.0030, -0.0030, -0.0087, -0.0136, -0.0171, -0.0190])\n",
      "The output is: tensor([-0.0053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0053])\n",
      "The pure output is: tensor([0.0034], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0087)\n",
      "The evaluation loss is: tensor(2.7542e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0030, -0.0030, -0.0087, -0.0136, -0.0171, -0.0190, -0.0190])\n",
      "The output is: tensor([-0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0083])\n",
      "The pure output is: tensor([0.0053], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0136)\n",
      "The evaluation loss is: tensor(2.6621e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0030, -0.0087, -0.0136, -0.0171, -0.0190, -0.0190, -0.0171])\n",
      "The output is: tensor([-0.0105], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0105])\n",
      "The pure output is: tensor([0.0067], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0171)\n",
      "The evaluation loss is: tensor(2.6429e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0087, -0.0136, -0.0171, -0.0190, -0.0190, -0.0171, -0.0136])\n",
      "The output is: tensor([-0.0116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0116])\n",
      "The pure output is: tensor([0.0074], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0190)\n",
      "The evaluation loss is: tensor(2.7493e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0136, -0.0171, -0.0190, -0.0190, -0.0171, -0.0136, -0.0087])\n",
      "The output is: tensor([-0.0116], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0116])\n",
      "The pure output is: tensor([0.0074], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0190)\n",
      "The evaluation loss is: tensor(2.9078e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0171, -0.0190, -0.0190, -0.0171, -0.0136, -0.0087, -0.0030])\n",
      "The output is: tensor([-0.0105], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0105])\n",
      "The pure output is: tensor([0.0067], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0171)\n",
      "The evaluation loss is: tensor(2.9582e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0190, -0.0190, -0.0171, -0.0136, -0.0087, -0.0030,  0.0030])\n",
      "The output is: tensor([-0.0083], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0083])\n",
      "The pure output is: tensor([0.0053], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0136)\n",
      "The evaluation loss is: tensor(2.9785e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0190, -0.0171, -0.0136, -0.0087, -0.0030,  0.0030,  0.0087])\n",
      "The output is: tensor([-0.0053], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0053])\n",
      "The pure output is: tensor([0.0034], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0087)\n",
      "The evaluation loss is: tensor(3.0758e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 9 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0171, -0.0136, -0.0087, -0.0030,  0.0030,  0.0087,  0.0136])\n",
      "The output is: tensor([-0.0018], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0018])\n",
      "The pure output is: tensor([0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0030)\n",
      "The evaluation loss is: tensor(3.2235e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0083, -0.0053, -0.0018,  0.0018,  0.0053,  0.0083,  0.0105])\n",
      "The output is: tensor([0.0011], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0011])\n",
      "The pure output is: tensor([-0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0018)\n",
      "The evaluation loss is: tensor(3.0501e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0053, -0.0018,  0.0018,  0.0053,  0.0083,  0.0105,  0.0116])\n",
      "The output is: tensor([0.0033], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0033])\n",
      "The pure output is: tensor([-0.0021], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0053)\n",
      "The evaluation loss is: tensor(3.0862e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0018,  0.0018,  0.0053,  0.0083,  0.0105,  0.0116,  0.0116])\n",
      "The output is: tensor([0.0051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0051])\n",
      "The pure output is: tensor([-0.0032], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0083)\n",
      "The evaluation loss is: tensor(2.9683e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0018, 0.0053, 0.0083, 0.0105, 0.0116, 0.0116, 0.0105])\n",
      "The output is: tensor([0.0064], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0064])\n",
      "The pure output is: tensor([-0.0041], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0105)\n",
      "The evaluation loss is: tensor(3.1486e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0053, 0.0083, 0.0105, 0.0116, 0.0116, 0.0105, 0.0083])\n",
      "The output is: tensor([0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0071])\n",
      "The pure output is: tensor([-0.0045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0116)\n",
      "The evaluation loss is: tensor(2.9279e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0083, 0.0105, 0.0116, 0.0116, 0.0105, 0.0083, 0.0053])\n",
      "The output is: tensor([0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0071])\n",
      "The pure output is: tensor([-0.0045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0116)\n",
      "The evaluation loss is: tensor(2.9279e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0105, 0.0116, 0.0116, 0.0105, 0.0083, 0.0053, 0.0018])\n",
      "The output is: tensor([0.0064], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0064])\n",
      "The pure output is: tensor([-0.0041], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0105)\n",
      "The evaluation loss is: tensor(2.9836e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0116,  0.0116,  0.0105,  0.0083,  0.0053,  0.0018, -0.0018])\n",
      "The output is: tensor([0.0051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0051])\n",
      "The pure output is: tensor([-0.0032], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0083)\n",
      "The evaluation loss is: tensor(2.9683e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0116,  0.0105,  0.0083,  0.0053,  0.0018, -0.0018, -0.0053])\n",
      "The output is: tensor([0.0033], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0033])\n",
      "The pure output is: tensor([-0.0021], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0053)\n",
      "The evaluation loss is: tensor(2.8428e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0105,  0.0083,  0.0053,  0.0018, -0.0018, -0.0053, -0.0083])\n",
      "The output is: tensor([0.0011], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0011])\n",
      "The pure output is: tensor([-0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0018)\n",
      "The evaluation loss is: tensor(2.6525e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0083,  0.0053,  0.0018, -0.0018, -0.0053, -0.0083, -0.0105])\n",
      "The output is: tensor([-0.0011], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0011])\n",
      "The pure output is: tensor([0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0018)\n",
      "The evaluation loss is: tensor(2.6333e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0053,  0.0018, -0.0018, -0.0053, -0.0083, -0.0105, -0.0116])\n",
      "The output is: tensor([-0.0033], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0033])\n",
      "The pure output is: tensor([0.0021], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0053)\n",
      "The evaluation loss is: tensor(2.7542e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0018, -0.0018, -0.0053, -0.0083, -0.0105, -0.0116, -0.0116])\n",
      "The output is: tensor([-0.0051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0051])\n",
      "The pure output is: tensor([0.0032], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0083)\n",
      "The evaluation loss is: tensor(2.7885e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0018, -0.0053, -0.0083, -0.0105, -0.0116, -0.0116, -0.0105])\n",
      "The output is: tensor([-0.0064], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0064])\n",
      "The pure output is: tensor([0.0041], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0105)\n",
      "The evaluation loss is: tensor(2.6958e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0053, -0.0083, -0.0105, -0.0116, -0.0116, -0.0105, -0.0083])\n",
      "The output is: tensor([-0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0071])\n",
      "The pure output is: tensor([0.0045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0116)\n",
      "The evaluation loss is: tensor(2.8280e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0083, -0.0105, -0.0116, -0.0116, -0.0105, -0.0083, -0.0053])\n",
      "The output is: tensor([-0.0071], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0071])\n",
      "The pure output is: tensor([0.0045], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0116)\n",
      "The evaluation loss is: tensor(2.8280e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0105, -0.0116, -0.0116, -0.0105, -0.0083, -0.0053, -0.0018])\n",
      "The output is: tensor([-0.0064], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0064])\n",
      "The pure output is: tensor([0.0041], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0105)\n",
      "The evaluation loss is: tensor(2.9329e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0116, -0.0116, -0.0105, -0.0083, -0.0053, -0.0018,  0.0018])\n",
      "The output is: tensor([-0.0051], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0051])\n",
      "The pure output is: tensor([0.0032], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0083)\n",
      "The evaluation loss is: tensor(2.9481e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0116, -0.0105, -0.0083, -0.0053, -0.0018,  0.0018,  0.0053])\n",
      "The output is: tensor([-0.0033], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0033])\n",
      "The pure output is: tensor([0.0021], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0053)\n",
      "The evaluation loss is: tensor(2.9938e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 10 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0105, -0.0083, -0.0053, -0.0018,  0.0018,  0.0053,  0.0083])\n",
      "The output is: tensor([-0.0011], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0011])\n",
      "The pure output is: tensor([0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0018)\n",
      "The evaluation loss is: tensor(3.0295e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0051, -0.0033, -0.0011,  0.0011,  0.0033,  0.0051,  0.0064])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0011)\n",
      "The evaluation loss is: tensor(3.0655e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0033, -0.0011,  0.0011,  0.0033,  0.0051,  0.0064,  0.0071])\n",
      "The output is: tensor([0.0020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0020])\n",
      "The pure output is: tensor([-0.0013], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0033)\n",
      "The evaluation loss is: tensor(2.9002e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0011,  0.0011,  0.0033,  0.0051,  0.0064,  0.0071,  0.0071])\n",
      "The output is: tensor([0.0031], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0031])\n",
      "The pure output is: tensor([-0.0020], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0051)\n",
      "The evaluation loss is: tensor(2.9178e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0011, 0.0033, 0.0051, 0.0064, 0.0071, 0.0071, 0.0064])\n",
      "The output is: tensor([0.0039], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0039])\n",
      "The pure output is: tensor([-0.0025], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0064)\n",
      "The evaluation loss is: tensor(2.8577e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0033, 0.0051, 0.0064, 0.0071, 0.0071, 0.0064, 0.0051])\n",
      "The output is: tensor([0.0043], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0043])\n",
      "The pure output is: tensor([-0.0028], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0071)\n",
      "The evaluation loss is: tensor(2.9329e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0051, 0.0064, 0.0071, 0.0071, 0.0064, 0.0051, 0.0033])\n",
      "The output is: tensor([0.0043], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0043])\n",
      "The pure output is: tensor([-0.0028], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0071)\n",
      "The evaluation loss is: tensor(2.7737e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0064, 0.0071, 0.0071, 0.0064, 0.0051, 0.0033, 0.0011])\n",
      "The output is: tensor([0.0039], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0039])\n",
      "The pure output is: tensor([-0.0025], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0064)\n",
      "The evaluation loss is: tensor(2.8577e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0071,  0.0071,  0.0064,  0.0051,  0.0033,  0.0011, -0.0011])\n",
      "The output is: tensor([0.0031], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0031])\n",
      "The pure output is: tensor([-0.0020], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0051)\n",
      "The evaluation loss is: tensor(2.8379e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0071,  0.0064,  0.0051,  0.0033,  0.0011, -0.0011, -0.0033])\n",
      "The output is: tensor([0.0020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0020])\n",
      "The pure output is: tensor([-0.0013], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0033)\n",
      "The evaluation loss is: tensor(2.8205e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0064,  0.0051,  0.0033,  0.0011, -0.0011, -0.0033, -0.0051])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0011)\n",
      "The evaluation loss is: tensor(2.7444e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0051,  0.0033,  0.0011, -0.0011, -0.0033, -0.0051, -0.0064])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0011)\n",
      "The evaluation loss is: tensor(2.7737e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0033,  0.0011, -0.0011, -0.0033, -0.0051, -0.0064, -0.0071])\n",
      "The output is: tensor([-0.0020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0020])\n",
      "The pure output is: tensor([0.0013], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0033)\n",
      "The evaluation loss is: tensor(2.6982e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0011, -0.0011, -0.0033, -0.0051, -0.0064, -0.0071, -0.0071])\n",
      "The output is: tensor([-0.0031], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0031])\n",
      "The pure output is: tensor([0.0020], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0051)\n",
      "The evaluation loss is: tensor(2.7590e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0011, -0.0033, -0.0051, -0.0064, -0.0071, -0.0071, -0.0064])\n",
      "The output is: tensor([-0.0039], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0039])\n",
      "The pure output is: tensor([0.0025], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0064)\n",
      "The evaluation loss is: tensor(2.8977e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0033, -0.0051, -0.0064, -0.0071, -0.0071, -0.0064, -0.0051])\n",
      "The output is: tensor([-0.0043], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0043])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure output is: tensor([0.0028], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0071)\n",
      "The evaluation loss is: tensor(2.8230e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0051, -0.0064, -0.0071, -0.0071, -0.0064, -0.0051, -0.0033])\n",
      "The output is: tensor([-0.0043], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0043])\n",
      "The pure output is: tensor([0.0028], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0071)\n",
      "The evaluation loss is: tensor(2.9027e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0064, -0.0071, -0.0071, -0.0064, -0.0051, -0.0033, -0.0011])\n",
      "The output is: tensor([-0.0039], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0039])\n",
      "The pure output is: tensor([0.0025], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0064)\n",
      "The evaluation loss is: tensor(2.8977e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0071, -0.0071, -0.0064, -0.0051, -0.0033, -0.0011,  0.0011])\n",
      "The output is: tensor([-0.0031], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0031])\n",
      "The pure output is: tensor([0.0020], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0051)\n",
      "The evaluation loss is: tensor(3.0810e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0071, -0.0064, -0.0051, -0.0033, -0.0011,  0.0011,  0.0033])\n",
      "The output is: tensor([-0.0020], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0020])\n",
      "The pure output is: tensor([0.0013], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0033)\n",
      "The evaluation loss is: tensor(3.0167e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 11 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0064, -0.0051, -0.0033, -0.0011,  0.0011,  0.0033,  0.0051])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0011)\n",
      "The evaluation loss is: tensor(3.0142e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0031, -0.0020, -0.0007,  0.0007,  0.0020,  0.0031,  0.0039])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.9989e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0020, -0.0007,  0.0007,  0.0020,  0.0031,  0.0039,  0.0043])\n",
      "The output is: tensor([0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0012])\n",
      "The pure output is: tensor([-0.0008], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0020)\n",
      "The evaluation loss is: tensor(2.9671e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007,  0.0007,  0.0020,  0.0031,  0.0039,  0.0043,  0.0043])\n",
      "The output is: tensor([0.0019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0019])\n",
      "The pure output is: tensor([-0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0031)\n",
      "The evaluation loss is: tensor(3.1407e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0007, 0.0020, 0.0031, 0.0039, 0.0043, 0.0043, 0.0039])\n",
      "The output is: tensor([0.0024], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0024])\n",
      "The pure output is: tensor([-0.0015], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0039)\n",
      "The evaluation loss is: tensor(2.7983e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0020, 0.0031, 0.0039, 0.0043, 0.0043, 0.0039, 0.0031])\n",
      "The output is: tensor([0.0026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0026])\n",
      "The pure output is: tensor([-0.0017], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0043)\n",
      "The evaluation loss is: tensor(3.0065e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0031, 0.0039, 0.0043, 0.0043, 0.0039, 0.0031, 0.0020])\n",
      "The output is: tensor([0.0026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0026])\n",
      "The pure output is: tensor([-0.0017], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0043)\n",
      "The evaluation loss is: tensor(2.8453e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0039, 0.0043, 0.0043, 0.0039, 0.0031, 0.0020, 0.0007])\n",
      "The output is: tensor([0.0024], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0024])\n",
      "The pure output is: tensor([-0.0015], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0039)\n",
      "The evaluation loss is: tensor(2.9582e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0043,  0.0043,  0.0039,  0.0031,  0.0020,  0.0007, -0.0007])\n",
      "The output is: tensor([0.0019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0019])\n",
      "The pure output is: tensor([-0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0031)\n",
      "The evaluation loss is: tensor(2.8156e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0043,  0.0039,  0.0031,  0.0020,  0.0007, -0.0007, -0.0020])\n",
      "The output is: tensor([0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0012])\n",
      "The pure output is: tensor([-0.0008], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0020)\n",
      "The evaluation loss is: tensor(2.8069e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0039,  0.0031,  0.0020,  0.0007, -0.0007, -0.0020, -0.0031])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.8379e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0031,  0.0020,  0.0007, -0.0007, -0.0020, -0.0031, -0.0039])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.7590e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0020,  0.0007, -0.0007, -0.0020, -0.0031, -0.0039, -0.0043])\n",
      "The output is: tensor([-0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0012])\n",
      "The pure output is: tensor([0.0008], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0020)\n",
      "The evaluation loss is: tensor(2.8690e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0007, -0.0007, -0.0020, -0.0031, -0.0039, -0.0043, -0.0043])\n",
      "The output is: tensor([-0.0019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0019])\n",
      "The pure output is: tensor([0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0031)\n",
      "The evaluation loss is: tensor(2.7811e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007, -0.0020, -0.0031, -0.0039, -0.0043, -0.0043, -0.0039])\n",
      "The output is: tensor([-0.0024], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0024])\n",
      "The pure output is: tensor([0.0015], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0039)\n",
      "The evaluation loss is: tensor(2.7983e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0020, -0.0031, -0.0039, -0.0043, -0.0043, -0.0039, -0.0031])\n",
      "The output is: tensor([-0.0026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0026])\n",
      "The pure output is: tensor([0.0017], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0043)\n",
      "The evaluation loss is: tensor(2.9103e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0031, -0.0039, -0.0043, -0.0043, -0.0039, -0.0031, -0.0020])\n",
      "The output is: tensor([-0.0026], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0026])\n",
      "The pure output is: tensor([0.0017], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0043)\n",
      "The evaluation loss is: tensor(2.9103e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0039, -0.0043, -0.0043, -0.0039, -0.0031, -0.0020, -0.0007])\n",
      "The output is: tensor([-0.0024], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct solution is: tensor([-0.0024])\n",
      "The pure output is: tensor([0.0015], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0039)\n",
      "The evaluation loss is: tensor(2.8777e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0043, -0.0043, -0.0039, -0.0031, -0.0020, -0.0007,  0.0007])\n",
      "The output is: tensor([-0.0019], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0019])\n",
      "The pure output is: tensor([0.0012], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0031)\n",
      "The evaluation loss is: tensor(2.9405e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0043, -0.0039, -0.0031, -0.0020, -0.0007,  0.0007,  0.0020])\n",
      "The output is: tensor([-0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0012])\n",
      "The pure output is: tensor([0.0008], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0020)\n",
      "The evaluation loss is: tensor(2.7897e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 12 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0039, -0.0031, -0.0020, -0.0007,  0.0007,  0.0020,  0.0031])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.9989e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0019, -0.0012, -0.0004,  0.0004,  0.0012,  0.0019,  0.0024])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(2.9667e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0012, -0.0004,  0.0004,  0.0012,  0.0019,  0.0024,  0.0026])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0005], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0012)\n",
      "The evaluation loss is: tensor(2.9052e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0004,  0.0004,  0.0012,  0.0019,  0.0024,  0.0026,  0.0026])\n",
      "The output is: tensor([0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0012])\n",
      "The pure output is: tensor([-0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0019)\n",
      "The evaluation loss is: tensor(2.9417e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0004, 0.0012, 0.0019, 0.0024, 0.0026, 0.0026, 0.0024])\n",
      "The output is: tensor([0.0015], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0015])\n",
      "The pure output is: tensor([-0.0009], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0024)\n",
      "The evaluation loss is: tensor(2.8627e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0012, 0.0019, 0.0024, 0.0026, 0.0026, 0.0024, 0.0019])\n",
      "The output is: tensor([0.0016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0016])\n",
      "The pure output is: tensor([-0.0010], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0026)\n",
      "The evaluation loss is: tensor(2.9709e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0019, 0.0024, 0.0026, 0.0026, 0.0024, 0.0019, 0.0012])\n",
      "The output is: tensor([0.0016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0016])\n",
      "The pure output is: tensor([-0.0010], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0026)\n",
      "The evaluation loss is: tensor(2.8106e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0024, 0.0026, 0.0026, 0.0024, 0.0019, 0.0012, 0.0004])\n",
      "The output is: tensor([0.0015], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0015])\n",
      "The pure output is: tensor([-0.0009], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0024)\n",
      "The evaluation loss is: tensor(2.9430e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0026,  0.0026,  0.0024,  0.0019,  0.0012,  0.0004, -0.0004])\n",
      "The output is: tensor([0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0012])\n",
      "The pure output is: tensor([-0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0019)\n",
      "The evaluation loss is: tensor(2.7823e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0026,  0.0024,  0.0019,  0.0012,  0.0004, -0.0004, -0.0012])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0005], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0012)\n",
      "The evaluation loss is: tensor(2.8255e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0024,  0.0019,  0.0012,  0.0004, -0.0004, -0.0012, -0.0019])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(2.8861e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0019,  0.0012,  0.0004, -0.0004, -0.0012, -0.0019, -0.0024])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8693e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0012,  0.0004, -0.0004, -0.0012, -0.0019, -0.0024, -0.0026])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0005], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0012)\n",
      "The evaluation loss is: tensor(2.7713e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0004, -0.0004, -0.0012, -0.0019, -0.0024, -0.0026, -0.0026])\n",
      "The output is: tensor([-0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0012])\n",
      "The pure output is: tensor([0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0019)\n",
      "The evaluation loss is: tensor(2.8144e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0004, -0.0012, -0.0019, -0.0024, -0.0026, -0.0026, -0.0024])\n",
      "The output is: tensor([-0.0015], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0015])\n",
      "The pure output is: tensor([0.0009], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0024)\n",
      "The evaluation loss is: tensor(2.8131e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0012, -0.0019, -0.0024, -0.0026, -0.0026, -0.0024, -0.0019])\n",
      "The output is: tensor([-0.0016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0016])\n",
      "The pure output is: tensor([0.0010], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0026)\n",
      "The evaluation loss is: tensor(2.9455e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0019, -0.0024, -0.0026, -0.0026, -0.0024, -0.0019, -0.0012])\n",
      "The output is: tensor([-0.0016], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0016])\n",
      "The pure output is: tensor([0.0010], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0026)\n",
      "The evaluation loss is: tensor(3.0270e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0024, -0.0026, -0.0026, -0.0024, -0.0019, -0.0012, -0.0004])\n",
      "The output is: tensor([-0.0015], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0015])\n",
      "The pure output is: tensor([0.0009], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0024)\n",
      "The evaluation loss is: tensor(2.9734e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0026, -0.0026, -0.0024, -0.0019, -0.0012, -0.0004,  0.0004])\n",
      "The output is: tensor([-0.0012], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0012])\n",
      "The pure output is: tensor([0.0007], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0019)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation loss is: tensor(2.9747e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0026, -0.0024, -0.0019, -0.0012, -0.0004,  0.0004,  0.0012])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0005], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0012)\n",
      "The evaluation loss is: tensor(2.9304e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 13 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0024, -0.0019, -0.0012, -0.0004,  0.0004,  0.0012,  0.0019])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8693e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0012, -0.0007, -0.0003,  0.0003,  0.0007,  0.0012,  0.0015])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-9.8757e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.9457e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007, -0.0003,  0.0003,  0.0007,  0.0012,  0.0015,  0.0016])\n",
      "The output is: tensor([0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0005])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.9512e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0003,  0.0003,  0.0007,  0.0012,  0.0015,  0.0016,  0.0016])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0012)\n",
      "The evaluation loss is: tensor(2.9443e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0003, 0.0007, 0.0012, 0.0015, 0.0016, 0.0016, 0.0015])\n",
      "The output is: tensor([0.0009], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0009])\n",
      "The pure output is: tensor([-0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0015)\n",
      "The evaluation loss is: tensor(2.9291e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0007, 0.0012, 0.0015, 0.0016, 0.0016, 0.0015, 0.0012])\n",
      "The output is: tensor([0.0010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0010])\n",
      "The pure output is: tensor([-0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0016)\n",
      "The evaluation loss is: tensor(2.8553e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0012, 0.0015, 0.0016, 0.0016, 0.0015, 0.0012, 0.0007])\n",
      "The output is: tensor([0.0010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0010])\n",
      "The pure output is: tensor([-0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0016)\n",
      "The evaluation loss is: tensor(2.8553e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0015, 0.0016, 0.0016, 0.0015, 0.0012, 0.0007, 0.0003])\n",
      "The output is: tensor([0.0009], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0009])\n",
      "The pure output is: tensor([-0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0015)\n",
      "The evaluation loss is: tensor(2.9291e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0016,  0.0016,  0.0015,  0.0012,  0.0007,  0.0003, -0.0003])\n",
      "The output is: tensor([0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0007])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0012)\n",
      "The evaluation loss is: tensor(2.7848e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0016,  0.0015,  0.0012,  0.0007,  0.0003, -0.0003, -0.0007])\n",
      "The output is: tensor([0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0005])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.9512e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0015,  0.0012,  0.0007,  0.0003, -0.0003, -0.0007, -0.0012])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-9.8765e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.8654e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0012,  0.0007,  0.0003, -0.0003, -0.0007, -0.0012, -0.0015])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([9.9830e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8105e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0007,  0.0003, -0.0003, -0.0007, -0.0012, -0.0015, -0.0016])\n",
      "The output is: tensor([-0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0005])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.8846e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0003, -0.0003, -0.0007, -0.0012, -0.0015, -0.0016, -0.0016])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0012)\n",
      "The evaluation loss is: tensor(2.8915e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0003, -0.0007, -0.0012, -0.0015, -0.0016, -0.0016, -0.0015])\n",
      "The output is: tensor([-0.0009], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0009])\n",
      "The pure output is: tensor([0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0015)\n",
      "The evaluation loss is: tensor(2.8267e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007, -0.0012, -0.0015, -0.0016, -0.0016, -0.0015, -0.0012])\n",
      "The output is: tensor([-0.0010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0010])\n",
      "The pure output is: tensor([0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0016)\n",
      "The evaluation loss is: tensor(2.9002e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0012, -0.0015, -0.0016, -0.0016, -0.0015, -0.0012, -0.0007])\n",
      "The output is: tensor([-0.0010], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0010])\n",
      "The pure output is: tensor([0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0016)\n",
      "The evaluation loss is: tensor(2.9810e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0015, -0.0016, -0.0016, -0.0015, -0.0012, -0.0007, -0.0003])\n",
      "The output is: tensor([-0.0009], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0009])\n",
      "The pure output is: tensor([0.0006], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0015)\n",
      "The evaluation loss is: tensor(2.9874e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0016, -0.0016, -0.0015, -0.0012, -0.0007, -0.0003,  0.0003])\n",
      "The output is: tensor([-0.0007], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0007])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0012)\n",
      "The evaluation loss is: tensor(2.8119e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0016, -0.0015, -0.0012, -0.0007, -0.0003,  0.0003,  0.0007])\n",
      "The output is: tensor([-0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0005])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.8846e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 14 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0015, -0.0012, -0.0007, -0.0003,  0.0003,  0.0007,  0.0012])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([9.9830e-05], grad_fn=<HardtanhBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8105e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007, -0.0005, -0.0002,  0.0002,  0.0005,  0.0007,  0.0009])\n",
      "The output is: tensor([9.5552e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([9.5019e-05])\n",
      "The pure output is: tensor([-6.0089e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8477e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0005, -0.0002,  0.0002,  0.0005,  0.0007,  0.0009,  0.0010])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0005)\n",
      "The evaluation loss is: tensor(2.9099e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0002,  0.0002,  0.0005,  0.0007,  0.0009,  0.0010,  0.0010])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.8565e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0002, 0.0005, 0.0007, 0.0009, 0.0010, 0.0010, 0.0009])\n",
      "The output is: tensor([0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0005])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0009)\n",
      "The evaluation loss is: tensor(2.7915e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0005, 0.0007, 0.0009, 0.0010, 0.0010, 0.0009, 0.0007])\n",
      "The output is: tensor([0.0006], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0006])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0010)\n",
      "The evaluation loss is: tensor(2.9272e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0007, 0.0009, 0.0010, 0.0010, 0.0009, 0.0007, 0.0005])\n",
      "The output is: tensor([0.0006], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0006])\n",
      "The pure output is: tensor([-0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0010)\n",
      "The evaluation loss is: tensor(2.9272e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0009, 0.0010, 0.0010, 0.0009, 0.0007, 0.0005, 0.0002])\n",
      "The output is: tensor([0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0005])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0009)\n",
      "The evaluation loss is: tensor(2.8708e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0010,  0.0010,  0.0009,  0.0007,  0.0005,  0.0002, -0.0002])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0007)\n",
      "The evaluation loss is: tensor(2.8565e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0010,  0.0009,  0.0007,  0.0005,  0.0002, -0.0002, -0.0005])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0005)\n",
      "The evaluation loss is: tensor(2.8301e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0009,  0.0007,  0.0005,  0.0002, -0.0002, -0.0005, -0.0007])\n",
      "The output is: tensor([9.5560e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([9.5019e-05])\n",
      "The pure output is: tensor([-6.0081e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.9278e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0007,  0.0005,  0.0002, -0.0002, -0.0005, -0.0007, -0.0009])\n",
      "The output is: tensor([-9.4479e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-9.5019e-05])\n",
      "The pure output is: tensor([6.1162e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.9078e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0005,  0.0002, -0.0002, -0.0005, -0.0007, -0.0009, -0.0010])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0005)\n",
      "The evaluation loss is: tensor(2.9257e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 0.0002, -0.0002, -0.0005, -0.0007, -0.0009, -0.0010, -0.0010])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.8990e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0002, -0.0005, -0.0007, -0.0009, -0.0010, -0.0010, -0.0009])\n",
      "The output is: tensor([-0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0005])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0009)\n",
      "The evaluation loss is: tensor(2.8846e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0005, -0.0007, -0.0009, -0.0010, -0.0010, -0.0009, -0.0007])\n",
      "The output is: tensor([-0.0006], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0006])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0010)\n",
      "The evaluation loss is: tensor(2.9084e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0007, -0.0009, -0.0010, -0.0010, -0.0009, -0.0007, -0.0005])\n",
      "The output is: tensor([-0.0006], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0006])\n",
      "The pure output is: tensor([0.0004], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0010)\n",
      "The evaluation loss is: tensor(2.8286e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0009, -0.0010, -0.0010, -0.0009, -0.0007, -0.0005, -0.0002])\n",
      "The output is: tensor([-0.0005], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0005])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0009)\n",
      "The evaluation loss is: tensor(2.9652e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0010, -0.0010, -0.0009, -0.0007, -0.0005, -0.0002,  0.0002])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0003], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0007)\n",
      "The evaluation loss is: tensor(2.8990e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0010, -0.0009, -0.0007, -0.0005, -0.0002,  0.0002,  0.0005])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0005)\n",
      "The evaluation loss is: tensor(2.8456e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 15 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0009, -0.0007, -0.0005, -0.0002,  0.0002,  0.0005,  0.0007])\n",
      "The output is: tensor([-9.4479e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-9.5019e-05])\n",
      "The pure output is: tensor([6.1162e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation loss is: tensor(2.9078e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-4.2950e-04, -2.7575e-04, -9.5019e-05,  9.5019e-05,  2.7575e-04,\n",
      "         4.2950e-04,  5.4120e-04])\n",
      "The output is: tensor([5.8548e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.8009e-05])\n",
      "The pure output is: tensor([-3.6471e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(9.5019e-05)\n",
      "The evaluation loss is: tensor(2.9092e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.7575e-04, -9.5019e-05,  9.5019e-05,  2.7575e-04,  4.2950e-04,\n",
      "         5.4120e-04,  5.9992e-04])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.9530e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-9.5019e-05,  9.5019e-05,  2.7575e-04,  4.2950e-04,  5.4120e-04,\n",
      "         5.9992e-04,  5.9992e-04])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(2.7471e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([9.5019e-05, 2.7575e-04, 4.2950e-04, 5.4120e-04, 5.9992e-04, 5.9992e-04,\n",
      "        5.4120e-04])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0005)\n",
      "The evaluation loss is: tensor(2.8671e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0003, 0.0004, 0.0005, 0.0006, 0.0006, 0.0005, 0.0004])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0006)\n",
      "The evaluation loss is: tensor(2.8686e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0004, 0.0005, 0.0006, 0.0006, 0.0005, 0.0004, 0.0003])\n",
      "The output is: tensor([0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0004])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0006)\n",
      "The evaluation loss is: tensor(2.8686e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([5.4120e-04, 5.9992e-04, 5.9992e-04, 5.4120e-04, 4.2950e-04, 2.7575e-04,\n",
      "        9.5019e-05])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0005)\n",
      "The evaluation loss is: tensor(2.8671e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 5.9992e-04,  5.9992e-04,  5.4120e-04,  4.2950e-04,  2.7575e-04,\n",
      "         9.5019e-05, -9.5019e-05])\n",
      "The output is: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0003])\n",
      "The pure output is: tensor([-0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(2.9056e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 5.9992e-04,  5.4120e-04,  4.2950e-04,  2.7575e-04,  9.5019e-05,\n",
      "        -9.5019e-05, -2.7575e-04])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.8725e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 5.4120e-04,  4.2950e-04,  2.7575e-04,  9.5019e-05, -9.5019e-05,\n",
      "        -2.7575e-04, -4.2950e-04])\n",
      "The output is: tensor([5.8541e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.8009e-05])\n",
      "The pure output is: tensor([-3.6478e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(9.5019e-05)\n",
      "The evaluation loss is: tensor(2.8294e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 4.2950e-04,  2.7575e-04,  9.5019e-05, -9.5019e-05, -2.7575e-04,\n",
      "        -4.2950e-04, -5.4120e-04])\n",
      "The output is: tensor([-5.7475e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.8009e-05])\n",
      "The pure output is: tensor([3.7543e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-9.5019e-05)\n",
      "The evaluation loss is: tensor(2.8464e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.7575e-04,  9.5019e-05, -9.5019e-05, -2.7575e-04, -4.2950e-04,\n",
      "        -5.4120e-04, -5.9992e-04])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8829e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 9.5019e-05, -9.5019e-05, -2.7575e-04, -4.2950e-04, -5.4120e-04,\n",
      "        -5.9992e-04, -5.9992e-04])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8500e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-9.5019e-05, -2.7575e-04, -4.2950e-04, -5.4120e-04, -5.9992e-04,\n",
      "        -5.9992e-04, -5.4120e-04])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0005)\n",
      "The evaluation loss is: tensor(2.8883e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0003, -0.0004, -0.0005, -0.0006, -0.0006, -0.0005, -0.0004])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0006)\n",
      "The evaluation loss is: tensor(2.8073e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0004, -0.0005, -0.0006, -0.0006, -0.0005, -0.0004, -0.0003])\n",
      "The output is: tensor([-0.0004], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0004])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0006)\n",
      "The evaluation loss is: tensor(2.8868e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.4120e-04, -5.9992e-04, -5.9992e-04, -5.4120e-04, -4.2950e-04,\n",
      "        -2.7575e-04, -9.5019e-05])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0005)\n",
      "The evaluation loss is: tensor(2.8883e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.9992e-04, -5.9992e-04, -5.4120e-04, -4.2950e-04, -2.7575e-04,\n",
      "        -9.5019e-05,  9.5019e-05])\n",
      "The output is: tensor([-0.0003], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0003])\n",
      "The pure output is: tensor([0.0002], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8500e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.9992e-04, -5.4120e-04, -4.2950e-04, -2.7575e-04, -9.5019e-05,\n",
      "         9.5019e-05,  2.7575e-04])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.9634e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 16 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.4120e-04, -4.2950e-04, -2.7575e-04, -9.5019e-05,  9.5019e-05,\n",
      "         2.7575e-04,  4.2950e-04])\n",
      "The output is: tensor([-5.7475e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.8009e-05])\n",
      "The pure output is: tensor([3.7543e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-9.5019e-05)\n",
      "The evaluation loss is: tensor(2.8464e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.6221e-04, -1.6835e-04, -5.8009e-05,  5.8009e-05,  1.6835e-04,\n",
      "         2.6221e-04,  3.3040e-04])\n",
      "The output is: tensor([3.5948e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.5414e-05])\n",
      "The pure output is: tensor([-2.2061e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(5.8009e-05)\n",
      "The evaluation loss is: tensor(2.8445e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.6835e-04, -5.8009e-05,  5.8009e-05,  1.6835e-04,  2.6221e-04,\n",
      "         3.3040e-04,  3.6625e-04])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-6.5029e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.9500e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.8009e-05,  5.8009e-05,  1.6835e-04,  2.6221e-04,  3.3040e-04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3.6625e-04,  3.6625e-04])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(3.0170e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([5.8009e-05, 1.6835e-04, 2.6221e-04, 3.3040e-04, 3.6625e-04, 3.6625e-04,\n",
      "        3.3040e-04])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.8568e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0002, 0.0003, 0.0003, 0.0004, 0.0004, 0.0003, 0.0003])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(3.0380e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0003, 0.0003, 0.0004, 0.0004, 0.0003, 0.0003, 0.0002])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0004)\n",
      "The evaluation loss is: tensor(2.8760e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([3.3040e-04, 3.6625e-04, 3.6625e-04, 3.3040e-04, 2.6221e-04, 1.6835e-04,\n",
      "        5.8009e-05])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.9370e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 3.6625e-04,  3.6625e-04,  3.3040e-04,  2.6221e-04,  1.6835e-04,\n",
      "         5.8009e-05, -5.8009e-05])\n",
      "The output is: tensor([0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0002])\n",
      "The pure output is: tensor([-0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0003)\n",
      "The evaluation loss is: tensor(2.9358e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 3.6625e-04,  3.3040e-04,  2.6221e-04,  1.6835e-04,  5.8009e-05,\n",
      "        -5.8009e-05, -1.6835e-04])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-6.5036e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8697e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 3.3040e-04,  2.6221e-04,  1.6835e-04,  5.8009e-05, -5.8009e-05,\n",
      "        -1.6835e-04, -2.6221e-04])\n",
      "The output is: tensor([3.5948e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.5414e-05])\n",
      "The pure output is: tensor([-2.2061e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(5.8009e-05)\n",
      "The evaluation loss is: tensor(2.8445e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.6221e-04,  1.6835e-04,  5.8009e-05, -5.8009e-05, -1.6835e-04,\n",
      "        -2.6221e-04, -3.3040e-04])\n",
      "The output is: tensor([-3.4875e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.5414e-05])\n",
      "The pure output is: tensor([2.3134e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-5.8009e-05)\n",
      "The evaluation loss is: tensor(2.9111e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.6835e-04,  5.8009e-05, -5.8009e-05, -1.6835e-04, -2.6221e-04,\n",
      "        -3.3040e-04, -3.6625e-04])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([6.6109e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.8857e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 5.8009e-05, -5.8009e-05, -1.6835e-04, -2.6221e-04, -3.3040e-04,\n",
      "        -3.6625e-04, -3.6625e-04])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.9807e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.8009e-05, -1.6835e-04, -2.6221e-04, -3.3040e-04, -3.6625e-04,\n",
      "        -3.6625e-04, -3.3040e-04])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8987e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0002, -0.0003, -0.0003, -0.0004, -0.0004, -0.0003, -0.0003])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8794e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0003, -0.0003, -0.0004, -0.0004, -0.0003, -0.0003, -0.0002])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0004)\n",
      "The evaluation loss is: tensor(2.8794e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.3040e-04, -3.6625e-04, -3.6625e-04, -3.3040e-04, -2.6221e-04,\n",
      "        -1.6835e-04, -5.8009e-05])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8190e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.6625e-04, -3.6625e-04, -3.3040e-04, -2.6221e-04, -1.6835e-04,\n",
      "        -5.8009e-05,  5.8009e-05])\n",
      "The output is: tensor([-0.0002], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0002])\n",
      "The pure output is: tensor([0.0001], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0003)\n",
      "The evaluation loss is: tensor(2.8202e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.6625e-04, -3.3040e-04, -2.6221e-04, -1.6835e-04, -5.8009e-05,\n",
      "         5.8009e-05,  1.6835e-04])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([6.6116e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.9663e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 17 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.3040e-04, -2.6221e-04, -1.6835e-04, -5.8009e-05,  5.8009e-05,\n",
      "         1.6835e-04,  2.6221e-04])\n",
      "The output is: tensor([-3.4882e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.5414e-05])\n",
      "The pure output is: tensor([2.3127e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-5.8009e-05)\n",
      "The evaluation loss is: tensor(2.8312e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.6008e-04, -1.0278e-04, -3.5414e-05,  3.5414e-05,  1.0278e-04,\n",
      "         1.6008e-04,  2.0171e-04])\n",
      "The output is: tensor([2.2175e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([2.1620e-05])\n",
      "The pure output is: tensor([-1.3240e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(3.5414e-05)\n",
      "The evaluation loss is: tensor(3.0716e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.0278e-04, -3.5414e-05,  3.5414e-05,  1.0278e-04,  1.6008e-04,\n",
      "         2.0171e-04,  2.2360e-04])\n",
      "The output is: tensor([6.3280e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([6.2745e-05])\n",
      "The pure output is: tensor([-3.9496e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.8722e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.5414e-05,  3.5414e-05,  1.0278e-04,  1.6008e-04,  2.0171e-04,\n",
      "         2.2360e-04,  2.2360e-04])\n",
      "The output is: tensor([9.8260e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([9.7727e-05])\n",
      "The pure output is: tensor([-6.1817e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8409e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([3.5414e-05, 1.0278e-04, 1.6008e-04, 2.0171e-04, 2.2360e-04, 2.2360e-04,\n",
      "        2.0171e-04])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-7.8030e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8755e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-8.6553e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation loss is: tensor(2.8930e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-8.6561e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8134e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([2.0171e-04, 2.2360e-04, 2.2360e-04, 2.0171e-04, 1.6008e-04, 1.0278e-04,\n",
      "        3.5414e-05])\n",
      "The output is: tensor([0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([0.0001])\n",
      "The pure output is: tensor([-7.8037e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.7962e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.2360e-04,  2.2360e-04,  2.0171e-04,  1.6008e-04,  1.0278e-04,\n",
      "         3.5414e-05, -3.5414e-05])\n",
      "The output is: tensor([9.8260e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([9.7727e-05])\n",
      "The pure output is: tensor([-6.1817e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0002)\n",
      "The evaluation loss is: tensor(2.8409e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.2360e-04,  2.0171e-04,  1.6008e-04,  1.0278e-04,  3.5414e-05,\n",
      "        -3.5414e-05, -1.0278e-04])\n",
      "The output is: tensor([6.3288e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([6.2745e-05])\n",
      "The pure output is: tensor([-3.9488e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.9527e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.0171e-04,  1.6008e-04,  1.0278e-04,  3.5414e-05, -3.5414e-05,\n",
      "        -1.0278e-04, -1.6008e-04])\n",
      "The output is: tensor([2.2160e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([2.1620e-05])\n",
      "The pure output is: tensor([-1.3255e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(3.5414e-05)\n",
      "The evaluation loss is: tensor(2.9086e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.6008e-04,  1.0278e-04,  3.5414e-05, -3.5414e-05, -1.0278e-04,\n",
      "        -1.6008e-04, -2.0171e-04])\n",
      "The output is: tensor([-2.1087e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-2.1620e-05])\n",
      "The pure output is: tensor([1.4327e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-3.5414e-05)\n",
      "The evaluation loss is: tensor(2.8469e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.0278e-04,  3.5414e-05, -3.5414e-05, -1.0278e-04, -1.6008e-04,\n",
      "        -2.0171e-04, -2.2360e-04])\n",
      "The output is: tensor([-6.2208e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-6.2745e-05])\n",
      "The pure output is: tensor([4.0568e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(2.8832e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 3.5414e-05, -3.5414e-05, -1.0278e-04, -1.6008e-04, -2.0171e-04,\n",
      "        -2.2360e-04, -2.2360e-04])\n",
      "The output is: tensor([-9.7187e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-9.7727e-05])\n",
      "The pure output is: tensor([6.2890e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.9147e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.5414e-05, -1.0278e-04, -1.6008e-04, -2.0171e-04, -2.2360e-04,\n",
      "        -2.2360e-04, -2.0171e-04])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([7.9103e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.8799e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0001, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([8.7626e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.8624e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0001])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([8.7626e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.8624e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.0171e-04, -2.2360e-04, -2.2360e-04, -2.0171e-04, -1.6008e-04,\n",
      "        -1.0278e-04, -3.5414e-05])\n",
      "The output is: tensor([-0.0001], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-0.0001])\n",
      "The pure output is: tensor([7.9110e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.9604e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.2360e-04, -2.2360e-04, -2.0171e-04, -1.6008e-04, -1.0278e-04,\n",
      "        -3.5414e-05,  3.5414e-05])\n",
      "The output is: tensor([-9.7187e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-9.7727e-05])\n",
      "The pure output is: tensor([6.2890e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0002)\n",
      "The evaluation loss is: tensor(2.9147e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.2360e-04, -2.0171e-04, -1.6008e-04, -1.0278e-04, -3.5414e-05,\n",
      "         3.5414e-05,  1.0278e-04])\n",
      "The output is: tensor([-6.2208e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-6.2745e-05])\n",
      "The pure output is: tensor([4.0568e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(2.8832e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 18 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.0171e-04, -1.6008e-04, -1.0278e-04, -3.5414e-05,  3.5414e-05,\n",
      "         1.0278e-04,  1.6008e-04])\n",
      "The output is: tensor([-2.1087e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-2.1620e-05])\n",
      "The pure output is: tensor([1.4327e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-3.5414e-05)\n",
      "The evaluation loss is: tensor(2.8469e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-9.7727e-05, -6.2745e-05, -2.1620e-05,  2.1620e-05,  6.2745e-05,\n",
      "         9.7727e-05,  1.2314e-04])\n",
      "The output is: tensor([1.3738e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([1.3199e-05])\n",
      "The pure output is: tensor([-7.8827e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(2.1620e-05)\n",
      "The evaluation loss is: tensor(2.8991e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-6.2745e-05, -2.1620e-05,  2.1620e-05,  6.2745e-05,  9.7727e-05,\n",
      "         1.2314e-04,  1.3651e-04])\n",
      "The output is: tensor([3.8843e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.8305e-05])\n",
      "The pure output is: tensor([-2.3901e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(6.2745e-05)\n",
      "The evaluation loss is: tensor(2.8909e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.1620e-05,  2.1620e-05,  6.2745e-05,  9.7727e-05,  1.2314e-04,\n",
      "         1.3651e-04,  1.3651e-04])\n",
      "The output is: tensor([6.0206e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.9662e-05])\n",
      "The pure output is: tensor([-3.7521e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(9.7727e-05)\n",
      "The evaluation loss is: tensor(2.9563e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([2.1620e-05, 6.2745e-05, 9.7727e-05, 1.2314e-04, 1.3651e-04, 1.3651e-04,\n",
      "        1.2314e-04])\n",
      "The output is: tensor([7.5713e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([7.5179e-05])\n",
      "The pure output is: tensor([-4.7430e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.8527e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([6.2745e-05, 9.7727e-05, 1.2314e-04, 1.3651e-04, 1.3651e-04, 1.2314e-04,\n",
      "        9.7727e-05])\n",
      "The output is: tensor([8.3874e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([8.3336e-05])\n",
      "The pure output is: tensor([-5.2631e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.8961e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([9.7727e-05, 1.2314e-04, 1.3651e-04, 1.3651e-04, 1.2314e-04, 9.7727e-05,\n",
      "        6.2745e-05])\n",
      "The output is: tensor([8.3867e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([8.3336e-05])\n",
      "The pure output is: tensor([-5.2638e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.8164e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is: tensor([1.2314e-04, 1.3651e-04, 1.3651e-04, 1.2314e-04, 9.7727e-05, 6.2745e-05,\n",
      "        2.1620e-05])\n",
      "The output is: tensor([7.5713e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([7.5179e-05])\n",
      "The pure output is: tensor([-4.7430e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(0.0001)\n",
      "The evaluation loss is: tensor(2.8527e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.3651e-04,  1.3651e-04,  1.2314e-04,  9.7727e-05,  6.2745e-05,\n",
      "         2.1620e-05, -2.1620e-05])\n",
      "The output is: tensor([6.0198e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.9662e-05])\n",
      "The pure output is: tensor([-3.7529e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(9.7727e-05)\n",
      "The evaluation loss is: tensor(2.8758e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.3651e-04,  1.2314e-04,  9.7727e-05,  6.2745e-05,  2.1620e-05,\n",
      "        -2.1620e-05, -6.2745e-05])\n",
      "The output is: tensor([3.8836e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.8305e-05])\n",
      "The pure output is: tensor([-2.3909e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(6.2745e-05)\n",
      "The evaluation loss is: tensor(2.8113e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.2314e-04,  9.7727e-05,  6.2745e-05,  2.1620e-05, -2.1620e-05,\n",
      "        -6.2745e-05, -9.7727e-05])\n",
      "The output is: tensor([1.3738e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([1.3199e-05])\n",
      "The pure output is: tensor([-7.8827e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(2.1620e-05)\n",
      "The evaluation loss is: tensor(2.8991e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 9.7727e-05,  6.2745e-05,  2.1620e-05, -2.1620e-05, -6.2745e-05,\n",
      "        -9.7727e-05, -1.2314e-04])\n",
      "The output is: tensor([-1.2665e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-1.3199e-05])\n",
      "The pure output is: tensor([8.9556e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-2.1620e-05)\n",
      "The evaluation loss is: tensor(2.8563e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 6.2745e-05,  2.1620e-05, -2.1620e-05, -6.2745e-05, -9.7727e-05,\n",
      "        -1.2314e-04, -1.3651e-04])\n",
      "The output is: tensor([-3.7763e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.8305e-05])\n",
      "The pure output is: tensor([2.4982e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-6.2745e-05)\n",
      "The evaluation loss is: tensor(2.9448e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 2.1620e-05, -2.1620e-05, -6.2745e-05, -9.7727e-05, -1.2314e-04,\n",
      "        -1.3651e-04, -1.3651e-04])\n",
      "The output is: tensor([-5.9125e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.9662e-05])\n",
      "The pure output is: tensor([3.8601e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-9.7727e-05)\n",
      "The evaluation loss is: tensor(2.8796e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-2.1620e-05, -6.2745e-05, -9.7727e-05, -1.2314e-04, -1.3651e-04,\n",
      "        -1.3651e-04, -1.2314e-04])\n",
      "The output is: tensor([-7.4647e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-7.5179e-05])\n",
      "The pure output is: tensor([4.8496e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(2.8231e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-6.2745e-05, -9.7727e-05, -1.2314e-04, -1.3651e-04, -1.3651e-04,\n",
      "        -1.2314e-04, -9.7727e-05])\n",
      "The output is: tensor([-8.2801e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-8.3336e-05])\n",
      "The pure output is: tensor([5.3704e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(2.8594e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-9.7727e-05, -1.2314e-04, -1.3651e-04, -1.3651e-04, -1.2314e-04,\n",
      "        -9.7727e-05, -6.2745e-05])\n",
      "The output is: tensor([-8.2787e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-8.3336e-05])\n",
      "The pure output is: tensor([5.3719e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(3.0210e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.2314e-04, -1.3651e-04, -1.3651e-04, -1.2314e-04, -9.7727e-05,\n",
      "        -6.2745e-05, -2.1620e-05])\n",
      "The output is: tensor([-7.4647e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-7.5179e-05])\n",
      "The pure output is: tensor([4.8496e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-0.0001)\n",
      "The evaluation loss is: tensor(2.8231e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.3651e-04, -1.3651e-04, -1.2314e-04, -9.7727e-05, -6.2745e-05,\n",
      "        -2.1620e-05,  2.1620e-05])\n",
      "The output is: tensor([-5.9125e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.9662e-05])\n",
      "The pure output is: tensor([3.8601e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-9.7727e-05)\n",
      "The evaluation loss is: tensor(2.8796e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.3651e-04, -1.2314e-04, -9.7727e-05, -6.2745e-05, -2.1620e-05,\n",
      "         2.1620e-05,  6.2745e-05])\n",
      "The output is: tensor([-3.7763e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.8305e-05])\n",
      "The pure output is: tensor([2.4982e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-6.2745e-05)\n",
      "The evaluation loss is: tensor(2.9448e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 19 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.2314e-04, -9.7727e-05, -6.2745e-05, -2.1620e-05,  2.1620e-05,\n",
      "         6.2745e-05,  9.7727e-05])\n",
      "The output is: tensor([-1.2665e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-1.3199e-05])\n",
      "The pure output is: tensor([8.9556e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-2.1620e-05)\n",
      "The evaluation loss is: tensor(2.8563e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.9662e-05, -3.8305e-05, -1.3199e-05,  1.3199e-05,  3.8305e-05,\n",
      "         5.9662e-05,  7.5179e-05])\n",
      "The output is: tensor([8.5872e-06], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([8.0581e-06])\n",
      "The pure output is: tensor([-4.6119e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(1.3199e-05)\n",
      "The evaluation loss is: tensor(2.8004e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.8305e-05, -1.3199e-05,  1.3199e-05,  3.8305e-05,  5.9662e-05,\n",
      "         7.5179e-05,  8.3336e-05])\n",
      "The output is: tensor([2.3933e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([2.3385e-05])\n",
      "The pure output is: tensor([-1.4372e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(3.8305e-05)\n",
      "The evaluation loss is: tensor(3.0016e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.3199e-05,  1.3199e-05,  3.8305e-05,  5.9662e-05,  7.5179e-05,\n",
      "         8.3336e-05,  8.3336e-05])\n",
      "The output is: tensor([3.6960e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.6424e-05])\n",
      "The pure output is: tensor([-2.2702e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(5.9662e-05)\n",
      "The evaluation loss is: tensor(2.8793e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([1.3199e-05, 3.8305e-05, 5.9662e-05, 7.5179e-05, 8.3336e-05, 8.3336e-05,\n",
      "        7.5179e-05])\n",
      "The output is: tensor([4.6427e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([4.5896e-05])\n",
      "The pure output is: tensor([-2.8752e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(7.5179e-05)\n",
      "The evaluation loss is: tensor(2.8136e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([3.8305e-05, 5.9662e-05, 7.5179e-05, 8.3336e-05, 8.3336e-05, 7.5179e-05,\n",
      "        5.9662e-05])\n",
      "The output is: tensor([5.1410e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.0877e-05])\n",
      "The pure output is: tensor([-3.1926e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(8.3336e-05)\n",
      "The evaluation loss is: tensor(2.8501e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([5.9662e-05, 7.5179e-05, 8.3336e-05, 8.3336e-05, 7.5179e-05, 5.9662e-05,\n",
      "        3.8305e-05])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: tensor([5.1410e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([5.0877e-05])\n",
      "The pure output is: tensor([-3.1926e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(8.3336e-05)\n",
      "The evaluation loss is: tensor(2.8501e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([7.5179e-05, 8.3336e-05, 8.3336e-05, 7.5179e-05, 5.9662e-05, 3.8305e-05,\n",
      "        1.3199e-05])\n",
      "The output is: tensor([4.6442e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([4.5896e-05])\n",
      "The pure output is: tensor([-2.8737e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(7.5179e-05)\n",
      "The evaluation loss is: tensor(2.9739e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 8.3336e-05,  8.3336e-05,  7.5179e-05,  5.9662e-05,  3.8305e-05,\n",
      "         1.3199e-05, -1.3199e-05])\n",
      "The output is: tensor([3.6960e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([3.6424e-05])\n",
      "The pure output is: tensor([-2.2702e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(5.9662e-05)\n",
      "The evaluation loss is: tensor(2.8793e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 8.3336e-05,  7.5179e-05,  5.9662e-05,  3.8305e-05,  1.3199e-05,\n",
      "        -1.3199e-05, -3.8305e-05])\n",
      "The output is: tensor([2.3926e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([2.3385e-05])\n",
      "The pure output is: tensor([-1.4380e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(3.8305e-05)\n",
      "The evaluation loss is: tensor(2.9205e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 7.5179e-05,  5.9662e-05,  3.8305e-05,  1.3199e-05, -1.3199e-05,\n",
      "        -3.8305e-05, -5.9662e-05])\n",
      "The output is: tensor([8.5947e-06], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([8.0581e-06])\n",
      "The pure output is: tensor([-4.6045e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(1.3199e-05)\n",
      "The evaluation loss is: tensor(2.8798e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 5.9662e-05,  3.8305e-05,  1.3199e-05, -1.3199e-05, -3.8305e-05,\n",
      "        -5.9662e-05, -7.5179e-05])\n",
      "The output is: tensor([-7.5144e-06], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-8.0581e-06])\n",
      "The pure output is: tensor([5.6848e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-1.3199e-05)\n",
      "The evaluation loss is: tensor(2.9561e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 3.8305e-05,  1.3199e-05, -1.3199e-05, -3.8305e-05, -5.9662e-05,\n",
      "        -7.5179e-05, -8.3336e-05])\n",
      "The output is: tensor([-2.2845e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-2.3385e-05])\n",
      "The pure output is: tensor([1.5460e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-3.8305e-05)\n",
      "The evaluation loss is: tensor(2.9151e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([ 1.3199e-05, -1.3199e-05, -3.8305e-05, -5.9662e-05, -7.5179e-05,\n",
      "        -8.3336e-05, -8.3336e-05])\n",
      "The output is: tensor([-3.5887e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.6424e-05])\n",
      "The pure output is: tensor([2.3775e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-5.9662e-05)\n",
      "The evaluation loss is: tensor(2.8761e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-1.3199e-05, -3.8305e-05, -5.9662e-05, -7.5179e-05, -8.3336e-05,\n",
      "        -8.3336e-05, -7.5179e-05])\n",
      "The output is: tensor([-4.5354e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-4.5896e-05])\n",
      "The pure output is: tensor([2.9825e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-7.5179e-05)\n",
      "The evaluation loss is: tensor(2.9425e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-3.8305e-05, -5.9662e-05, -7.5179e-05, -8.3336e-05, -8.3336e-05,\n",
      "        -7.5179e-05, -5.9662e-05])\n",
      "The output is: tensor([-5.0338e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.0877e-05])\n",
      "The pure output is: tensor([3.2999e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-8.3336e-05)\n",
      "The evaluation loss is: tensor(2.9054e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-5.9662e-05, -7.5179e-05, -8.3336e-05, -8.3336e-05, -7.5179e-05,\n",
      "        -5.9662e-05, -3.8305e-05])\n",
      "The output is: tensor([-5.0338e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-5.0877e-05])\n",
      "The pure output is: tensor([3.2999e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-8.3336e-05)\n",
      "The evaluation loss is: tensor(2.9054e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-7.5179e-05, -8.3336e-05, -8.3336e-05, -7.5179e-05, -5.9662e-05,\n",
      "        -3.8305e-05, -1.3199e-05])\n",
      "The output is: tensor([-4.5369e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-4.5896e-05])\n",
      "The pure output is: tensor([2.9810e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-7.5179e-05)\n",
      "The evaluation loss is: tensor(2.7831e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-8.3336e-05, -8.3336e-05, -7.5179e-05, -5.9662e-05, -3.8305e-05,\n",
      "        -1.3199e-05,  1.3199e-05])\n",
      "The output is: tensor([-3.5872e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-3.6424e-05])\n",
      "The pure output is: tensor([2.3790e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-5.9662e-05)\n",
      "The evaluation loss is: tensor(3.0381e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-8.3336e-05, -7.5179e-05, -5.9662e-05, -3.8305e-05, -1.3199e-05,\n",
      "         1.3199e-05,  3.8305e-05])\n",
      "The output is: tensor([-2.2845e-05], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-2.3385e-05])\n",
      "The pure output is: tensor([1.5460e-05], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-3.8305e-05)\n",
      "The evaluation loss is: tensor(2.9151e-13, grad_fn=<MseLossBackward>)\n",
      "============================================================\n",
      "This is 20 times of iteration\n",
      "Evaluating...\n",
      "The input is: tensor([-7.5179e-05, -5.9662e-05, -3.8305e-05, -1.3199e-05,  1.3199e-05,\n",
      "         3.8305e-05,  5.9662e-05])\n",
      "The output is: tensor([-7.5144e-06], grad_fn=<AddBackward0>)\n",
      "The correct solution is: tensor([-8.0581e-06])\n",
      "The pure output is: tensor([5.6848e-06], grad_fn=<HardtanhBackward0>)\n",
      "The res input is: tensor(-1.3199e-05)\n",
      "The evaluation loss is: tensor(2.9561e-13, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "training_the_model(\n",
    "    delta_x=1/10, delta_t=1/20, xmin=0, tmin=0, xmax=2, tmax=1, learning_rate=0.00001, layer_data=[6], active=nn.Hardtanh(-1, 1),\n",
    "    folder_name=\"20 20 control group [Hardtanh(-1, 1)] [x1000]\", iteration=1000, printTraining=True, printEval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
