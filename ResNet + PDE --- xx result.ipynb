{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numpy import exp,arange\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the analytical representation of exact solution\n",
    "def heat_equ_analytical_solu(x, t):\n",
    "    return np.sin(np.pi * x) * np.exp(-np.power(np.pi, 2) * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========\n",
    "# helping methods\n",
    "# ==========\n",
    "\n",
    "# generate a list from lower and upper bound\n",
    "def gen_list(p0, pn, delta, dig=5):\n",
    "    ret = []\n",
    "    i = p0\n",
    "    while i < pn:\n",
    "        ret.append(float(i))\n",
    "        i += delta\n",
    "        i = round(i, dig)\n",
    "    return ret\n",
    "\n",
    "# padding and zero padding\n",
    "def padding(origin, a_list, b_list):\n",
    "    return np.hstack((a_list, origin, b_list))\n",
    "\n",
    "def zero_padding(origin, num):\n",
    "    zero_list = [0 for i in range(num)]\n",
    "    return padding(origin, zero_list, zero_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# getting trainning data\n",
    "# ==============\n",
    "\n",
    "# trainning pairs\n",
    "def gen_pair(u, x, t, length=3, num=1000):\n",
    "    pairs = []\n",
    "    for i in range(num):\n",
    "        r = random.randint(0, t-2)\n",
    "        current_t = u[r]\n",
    "        next_t = u[r+1]\n",
    "        p = random.randint(length, x-1-length)\n",
    "        train = current_t[p-length:p+length+1]\n",
    "        solu = next_t[p]\n",
    "        pair = {'input': train, 'solu': solu}\n",
    "        pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "# trainning pairs (in average)\n",
    "def gen_pair_ave(u, x, t, length=3, num=1000):\n",
    "    pairs = []\n",
    "    for i in range(num):\n",
    "        r = random.randint(0, t-2)\n",
    "        current_t = u[r]\n",
    "        next_t = u[r+1]\n",
    "        p = random.randint(length, x-2-length)\n",
    "        train0 = current_t[p-length:p+length+2]\n",
    "        solu1 = next_t[p]\n",
    "        solu2 = next_t[p+1]\n",
    "        train = []\n",
    "        for j in range(len(train0)-1):\n",
    "                train.append(0.5 * (train0[j] + train0[j+1]))\n",
    "        solu = 0.5 * (solu1 + solu2)\n",
    "        pair = {'input': train, 'solu': solu}\n",
    "        pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "# trainning pairs (in cell average)\n",
    "def gen_pair_cell_ave(u, x, t, delta_x, delta_y, length=3, num=1000):\n",
    "    pairs = []\n",
    "    for i in range(num):\n",
    "        t_index = random.randint(0, len(t)-2)\n",
    "        x_s = random.randint(0, len(x)-2*length-3)\n",
    "        x_e = x_s+2*length+2\n",
    "        starting = x[x_s]\n",
    "        ending = x[x_e]\n",
    "        input_data = []\n",
    "        for i in range(x_s, x_e-1):\n",
    "            value = integrate.quad(lambda x: heat_equ_analytical_solu(x, t[0]), x[i], x[i+1])\n",
    "            value = value[0] * (1/delta_x)\n",
    "            input_data.append(value)\n",
    "        target_data = integrate.quad(lambda x: heat_equ_analytical_solu(x, t[t_index+1]), x[x_s+length], x[x_s+length+1])\n",
    "        target_data = target_data[0] * (1/delta_x)\n",
    "        pair = {'input': input_data, 'solu': target_data}\n",
    "        pairs.append(pair)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restnet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, i, h1, h2, o, twolayers):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(i, h1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear21 = nn.Linear(h1, h2)\n",
    "        self.relu21 = nn.ReLU()\n",
    "        self.linear22 = nn.Linear(h2, o)\n",
    "        self.relu22 = nn.ReLU()\n",
    "        self.linear23 = nn.Linear(h1, o)\n",
    "        self.relu23 = nn.ReLU()\n",
    "        self.twolayers = twolayers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.twolayers == True:\n",
    "            out = self.linear1(x)\n",
    "            out = self.relu1(out)\n",
    "            out = self.linear21(out)\n",
    "            out = self.relu21(out)\n",
    "            out = self.linear22(out)\n",
    "            out = self.relu22(out)\n",
    "        else:\n",
    "            out = self.linear1(x)\n",
    "            out = self.relu1(out)\n",
    "            out = self.linear23(out)\n",
    "            out = self.relu23(out)\n",
    "        return out + torch.mean(x)\n",
    "\n",
    "    def load_model(self, save_path):\n",
    "        self.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_next_time(x, t, delta_x, delta_t, current, model, length=3):\n",
    "    ret = []\n",
    "    padding = np.hstack(([0 for i in range(length)], current, [0 for i in range(length)])).tolist()\n",
    "    padding_x = np.hstack(([0 for i in range(length)], x, [0 for i in range(length)])).tolist()\n",
    "    padding_t = np.hstack(([0 for i in range(length)], t, [0 for i in range(length)])).tolist()\n",
    "    for index in range(len(current)-1):\n",
    "        j = index + length\n",
    "        input_data = []\n",
    "        print(\"---\", j, \"---\")\n",
    "        for i in range(j-length, j+length+1):\n",
    "            value = integrate.quad(lambda x: heat_equ_analytical_solu(x, t[0]), padding_x[i], padding_x[i+1])\n",
    "            value = value[0] * (1/delta_x)\n",
    "            input_data.append(value)\n",
    "#         tensor_seg = torch.FloatTensor(seg)\n",
    "#         out = model(tensor_seg)\n",
    "#         ret.append(out.item())\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3 ---\n",
      "[0.0, 0.0, 0.0, 0.07837845807790614, 0.23320543647265152, 0.38229012305696985, 0.5219615580634472]\n",
      "--- 4 ---\n",
      "[0.0, 0.0, 0.07837845807790614, 0.23320543647265152, 0.38229012305696985, 0.5219615580634472, 0.6487805672193082]\n",
      "--- 5 ---\n",
      "[0.0, 0.07837845807790614, 0.23320543647265152, 0.38229012305696985, 0.5219615580634472, 0.6487805672193082, 0.7596244456309749]\n",
      "--- 6 ---\n",
      "[0.07837845807790614, 0.23320543647265152, 0.38229012305696985, 0.5219615580634472, 0.6487805672193082, 0.7596244456309749, 0.8517638491422085]\n",
      "--- 7 ---\n",
      "[0.23320543647265152, 0.38229012305696985, 0.5219615580634472, 0.6487805672193082, 0.7596244456309749, 0.8517638491422085, 0.9229299998454156]\n",
      "--- 8 ---\n",
      "[0.38229012305696985, 0.5219615580634472, 0.6487805672193082, 0.7596244456309749, 0.8517638491422085, 0.9229299998454156, 0.9713705509233703]\n",
      "--- 9 ---\n",
      "[0.5219615580634472, 0.6487805672193082, 0.7596244456309749, 0.8517638491422085, 0.9229299998454156, 0.9713705509233703, 0.9958927352435611]\n",
      "--- 10 ---\n",
      "[0.6487805672193082, 0.7596244456309749, 0.8517638491422085, 0.9229299998454156, 0.9713705509233703, 0.9958927352435611, 0.9958927352435623]\n",
      "--- 11 ---\n",
      "[0.7596244456309749, 0.8517638491422085, 0.9229299998454156, 0.9713705509233703, 0.9958927352435611, 0.9958927352435623, 0.9713705509233712]\n",
      "--- 12 ---\n",
      "[0.8517638491422085, 0.9229299998454156, 0.9713705509233703, 0.9958927352435611, 0.9958927352435623, 0.9713705509233712, 0.9229299998454146]\n",
      "--- 13 ---\n",
      "[0.9229299998454156, 0.9713705509233703, 0.9958927352435611, 0.9958927352435623, 0.9713705509233712, 0.9229299998454146, 0.851763849142209]\n",
      "--- 14 ---\n",
      "[0.9713705509233703, 0.9958927352435611, 0.9958927352435623, 0.9713705509233712, 0.9229299998454146, 0.851763849142209, 0.7596244456309731]\n",
      "--- 15 ---\n",
      "[0.9958927352435611, 0.9958927352435623, 0.9713705509233712, 0.9229299998454146, 0.851763849142209, 0.7596244456309731, 0.6487805672193091]\n",
      "--- 16 ---\n",
      "[0.9958927352435623, 0.9713705509233712, 0.9229299998454146, 0.851763849142209, 0.7596244456309731, 0.6487805672193091, 0.5219615580634478]\n",
      "--- 17 ---\n",
      "[0.9713705509233712, 0.9229299998454146, 0.851763849142209, 0.7596244456309731, 0.6487805672193091, 0.5219615580634478, 0.3822901230569694]\n",
      "--- 18 ---\n",
      "[0.9229299998454146, 0.851763849142209, 0.7596244456309731, 0.6487805672193091, 0.5219615580634478, 0.3822901230569694, 0.23320543647265168]\n",
      "--- 19 ---\n",
      "[0.851763849142209, 0.7596244456309731, 0.6487805672193091, 0.5219615580634478, 0.3822901230569694, 0.23320543647265168, 0.07837845807790582]\n",
      "--- 20 ---\n",
      "[0.7596244456309731, 0.6487805672193091, 0.5219615580634478, 0.3822901230569694, 0.23320543647265168, 0.07837845807790582, -0.07837845807790579]\n",
      "--- 21 ---\n",
      "[0.6487805672193091, 0.5219615580634478, 0.3822901230569694, 0.23320543647265168, 0.07837845807790582, -0.07837845807790579, -0.23320543647265207]\n",
      "--- 22 ---\n",
      "[0.5219615580634478, 0.3822901230569694, 0.23320543647265168, 0.07837845807790582, -0.07837845807790579, -0.23320543647265207, -0.38229012305696997]\n",
      "--- 23 ---\n",
      "[0.3822901230569694, 0.23320543647265168, 0.07837845807790582, -0.07837845807790579, -0.23320543647265207, -0.38229012305696997, -0.5219615580634485]\n",
      "--- 24 ---\n",
      "[0.23320543647265168, 0.07837845807790582, -0.07837845807790579, -0.23320543647265207, -0.38229012305696997, -0.5219615580634485, -0.648780567219306]\n",
      "--- 25 ---\n",
      "[0.07837845807790582, -0.07837845807790579, -0.23320543647265207, -0.38229012305696997, -0.5219615580634485, -0.648780567219306, -0.7596244456309746]\n",
      "--- 26 ---\n",
      "[-0.07837845807790579, -0.23320543647265207, -0.38229012305696997, -0.5219615580634485, -0.648780567219306, -0.7596244456309746, -0.8517638491422093]\n",
      "--- 27 ---\n",
      "[-0.23320543647265207, -0.38229012305696997, -0.5219615580634485, -0.648780567219306, -0.7596244456309746, -0.8517638491422093, -0.9229299998454166]\n",
      "--- 28 ---\n",
      "[-0.38229012305696997, -0.5219615580634485, -0.648780567219306, -0.7596244456309746, -0.8517638491422093, -0.9229299998454166, -0.9713705509233717]\n",
      "--- 29 ---\n",
      "[-0.5219615580634485, -0.648780567219306, -0.7596244456309746, -0.8517638491422093, -0.9229299998454166, -0.9713705509233717, -0.9958927352435578]\n",
      "--- 30 ---\n",
      "[-0.648780567219306, -0.7596244456309746, -0.8517638491422093, -0.9229299998454166, -0.9713705509233717, -0.9958927352435578, -0.9958927352435623]\n",
      "--- 31 ---\n",
      "[-0.7596244456309746, -0.8517638491422093, -0.9229299998454166, -0.9713705509233717, -0.9958927352435578, -0.9958927352435623, -0.9713705509233712]\n",
      "--- 32 ---\n",
      "[-0.8517638491422093, -0.9229299998454166, -0.9713705509233717, -0.9958927352435578, -0.9958927352435623, -0.9713705509233712, -0.9229299998454167]\n",
      "--- 33 ---\n",
      "[-0.9229299998454166, -0.9713705509233717, -0.9958927352435578, -0.9958927352435623, -0.9713705509233712, -0.9229299998454167, -0.8517638491422087]\n",
      "--- 34 ---\n",
      "[-0.9713705509233717, -0.9958927352435578, -0.9958927352435623, -0.9713705509233712, -0.9229299998454167, -0.8517638491422087, -0.7596244456309714]\n",
      "--- 35 ---\n",
      "[-0.9958927352435578, -0.9958927352435623, -0.9713705509233712, -0.9229299998454167, -0.8517638491422087, -0.7596244456309714, -0.6487805672193092]\n",
      "--- 36 ---\n",
      "[-0.9958927352435623, -0.9713705509233712, -0.9229299998454167, -0.8517638491422087, -0.7596244456309714, -0.6487805672193092, -0.5219615580634476]\n",
      "--- 37 ---\n",
      "[-0.9713705509233712, -0.9229299998454167, -0.8517638491422087, -0.7596244456309714, -0.6487805672193092, -0.5219615580634476, -0.3822901230569703]\n",
      "--- 38 ---\n",
      "[-0.9229299998454167, -0.8517638491422087, -0.7596244456309714, -0.6487805672193092, -0.5219615580634476, -0.3822901230569703, -0.23320543647265113]\n",
      "--- 39 ---\n",
      "[-0.8517638491422087, -0.7596244456309714, -0.6487805672193092, -0.5219615580634476, -0.3822901230569703, -0.23320543647265113, -0.07837845807790583]\n",
      "--- 40 ---\n",
      "[-0.7596244456309714, -0.6487805672193092, -0.5219615580634476, -0.3822901230569703, -0.23320543647265113, -0.07837845807790583, 0.07837845807790736]\n",
      "--- 41 ---\n",
      "[-0.6487805672193092, -0.5219615580634476, -0.3822901230569703, -0.23320543647265113, -0.07837845807790583, 0.07837845807790736, 0.2332054364726509]\n",
      "--- 42 ---\n",
      "[-0.5219615580634476, -0.3822901230569703, -0.23320543647265113, -0.07837845807790583, 0.07837845807790736, 0.2332054364726509, 0.38229012305696813]\n",
      "--- 43 ---\n",
      "[-0.3822901230569703, -0.23320543647265113, -0.07837845807790583, 0.07837845807790736, 0.2332054364726509, 0.38229012305696813, 0.5219615580634496]\n",
      "--- 44 ---\n",
      "[-0.23320543647265113, -0.07837845807790583, 0.07837845807790736, 0.2332054364726509, 0.38229012305696813, 0.5219615580634496, 0.6487805672193059]\n",
      "--- 45 ---\n",
      "[-0.07837845807790583, 0.07837845807790736, 0.2332054364726509, 0.38229012305696813, 0.5219615580634496, 0.6487805672193059, 0.7596244456309788]\n",
      "--- 46 ---\n",
      "[0.07837845807790736, 0.2332054364726509, 0.38229012305696813, 0.5219615580634496, 0.6487805672193059, 0.7596244456309788, 0.8517638491422054]\n",
      "--- 47 ---\n",
      "[0.2332054364726509, 0.38229012305696813, 0.5219615580634496, 0.6487805672193059, 0.7596244456309788, 0.8517638491422054, 0.9229299998454206]\n",
      "--- 48 ---\n",
      "[0.38229012305696813, 0.5219615580634496, 0.6487805672193059, 0.7596244456309788, 0.8517638491422054, 0.9229299998454206, 0.9713705509233673]\n",
      "--- 49 ---\n",
      "[0.5219615580634496, 0.6487805672193059, 0.7596244456309788, 0.8517638491422054, 0.9229299998454206, 0.9713705509233673, 0.9958927352435578]\n",
      "--- 50 ---\n",
      "[0.6487805672193059, 0.7596244456309788, 0.8517638491422054, 0.9229299998454206, 0.9713705509233673, 0.9958927352435578, 0.9958927352435666]\n",
      "--- 51 ---\n",
      "[0.7596244456309788, 0.8517638491422054, 0.9229299998454206, 0.9713705509233673, 0.9958927352435578, 0.9958927352435666, 0.971370550923367]\n",
      "--- 52 ---\n",
      "[0.8517638491422054, 0.9229299998454206, 0.9713705509233673, 0.9958927352435578, 0.9958927352435666, 0.971370550923367, 0.9229299998454209]\n",
      "--- 53 ---\n",
      "[0.9229299998454206, 0.9713705509233673, 0.9958927352435578, 0.9958927352435666, 0.971370550923367, 0.9229299998454209, 0.851763849142205]\n",
      "--- 54 ---\n",
      "[0.9713705509233673, 0.9958927352435578, 0.9958927352435666, 0.971370550923367, 0.9229299998454209, 0.851763849142205, 0.7596244456309715]\n",
      "--- 55 ---\n",
      "[0.9958927352435578, 0.9958927352435666, 0.971370550923367, 0.9229299998454209, 0.851763849142205, 0.7596244456309715, 0.6487805672193112]\n",
      "--- 56 ---\n",
      "[0.9958927352435666, 0.971370550923367, 0.9229299998454209, 0.851763849142205, 0.7596244456309715, 0.6487805672193112, 0.5219615580634454]\n",
      "--- 57 ---\n",
      "[0.971370550923367, 0.9229299998454209, 0.851763849142205, 0.7596244456309715, 0.6487805672193112, 0.5219615580634454, 0.3822901230569721]\n",
      "--- 58 ---\n",
      "[0.9229299998454209, 0.851763849142205, 0.7596244456309715, 0.6487805672193112, 0.5219615580634454, 0.3822901230569721, 0.23320543647265018]\n",
      "--- 59 ---\n",
      "[0.851763849142205, 0.7596244456309715, 0.6487805672193112, 0.5219615580634454, 0.3822901230569721, 0.23320543647265018, 0.07837845807790597]\n",
      "--- 60 ---\n",
      "[0.7596244456309715, 0.6487805672193112, 0.5219615580634454, 0.3822901230569721, 0.23320543647265018, 0.07837845807790597, -0.0783784580779073]\n",
      "--- 61 ---\n",
      "[0.6487805672193112, 0.5219615580634454, 0.3822901230569721, 0.23320543647265018, 0.07837845807790597, -0.0783784580779073, -0.23320543647265088]\n",
      "--- 62 ---\n",
      "[0.5219615580634454, 0.3822901230569721, 0.23320543647265018, 0.07837845807790597, -0.0783784580779073, -0.23320543647265088, -0.38229012305697146]\n",
      "--- 63 ---\n",
      "[0.3822901230569721, 0.23320543647265018, 0.07837845807790597, -0.0783784580779073, -0.23320543647265088, -0.38229012305697146, -0.521961558063446]\n",
      "--- 64 ---\n",
      "[0.23320543647265018, 0.07837845807790597, -0.0783784580779073, -0.23320543647265088, -0.38229012305697146, -0.521961558063446, -0.6487805672193059]\n",
      "--- 65 ---\n",
      "[0.07837845807790597, -0.0783784580779073, -0.23320543647265088, -0.38229012305697146, -0.521961558063446, -0.6487805672193059, -0.7596244456309788]\n",
      "--- 66 ---\n",
      "[-0.0783784580779073, -0.23320543647265088, -0.38229012305697146, -0.521961558063446, -0.6487805672193059, -0.7596244456309788, -0.8517638491422054]\n",
      "--- 67 ---\n",
      "[-0.23320543647265088, -0.38229012305697146, -0.521961558063446, -0.6487805672193059, -0.7596244456309788, -0.8517638491422054, -0.9229299998454208]\n",
      "--- 68 ---\n",
      "[-0.38229012305697146, -0.521961558063446, -0.6487805672193059, -0.7596244456309788, -0.8517638491422054, -0.9229299998454208, -0.9713705509233673]\n",
      "--- 69 ---\n",
      "[-0.521961558063446, -0.6487805672193059, -0.7596244456309788, -0.8517638491422054, -0.9229299998454208, -0.9713705509233673, -0.9958927352435578]\n",
      "--- 70 ---\n",
      "[-0.6487805672193059, -0.7596244456309788, -0.8517638491422054, -0.9229299998454208, -0.9713705509233673, -0.9958927352435578, -0.9958927352435666]\n",
      "--- 71 ---\n",
      "[-0.7596244456309788, -0.8517638491422054, -0.9229299998454208, -0.9713705509233673, -0.9958927352435578, -0.9958927352435666, -0.971370550923367]\n",
      "--- 72 ---\n",
      "[-0.8517638491422054, -0.9229299998454208, -0.9713705509233673, -0.9958927352435578, -0.9958927352435666, -0.971370550923367, -0.9229299998454209]\n",
      "--- 73 ---\n",
      "[-0.9229299998454208, -0.9713705509233673, -0.9958927352435578, -0.9958927352435666, -0.971370550923367, -0.9229299998454209, -0.851763849142205]\n",
      "--- 74 ---\n",
      "[-0.9713705509233673, -0.9958927352435578, -0.9958927352435666, -0.971370550923367, -0.9229299998454209, -0.851763849142205, -0.7596244456309715]\n",
      "--- 75 ---\n",
      "[-0.9958927352435578, -0.9958927352435666, -0.971370550923367, -0.9229299998454209, -0.851763849142205, -0.7596244456309715, -0.6487805672193113]\n",
      "--- 76 ---\n",
      "[-0.9958927352435666, -0.971370550923367, -0.9229299998454209, -0.851763849142205, -0.7596244456309715, -0.6487805672193113, -0.5219615580634454]\n",
      "--- 77 ---\n",
      "[-0.971370550923367, -0.9229299998454209, -0.851763849142205, -0.7596244456309715, -0.6487805672193113, -0.5219615580634454, -0.3822901230569723]\n",
      "--- 78 ---\n",
      "[-0.9229299998454209, -0.851763849142205, -0.7596244456309715, -0.6487805672193113, -0.5219615580634454, -0.3822901230569723, -0.2332054364726503]\n",
      "--- 79 ---\n",
      "[-0.851763849142205, -0.7596244456309715, -0.6487805672193113, -0.5219615580634454, -0.3822901230569723, -0.2332054364726503, -0.07837845807790608]\n",
      "--- 80 ---\n",
      "[-0.7596244456309715, -0.6487805672193113, -0.5219615580634454, -0.3822901230569723, -0.2332054364726503, -0.07837845807790608, 0.07837845807790636]\n",
      "--- 81 ---\n",
      "[-0.6487805672193113, -0.5219615580634454, -0.3822901230569723, -0.2332054364726503, -0.07837845807790608, 0.07837845807790636, 0.23320543647265504]\n",
      "--- 82 ---\n",
      "[-0.5219615580634454, -0.3822901230569723, -0.2332054364726503, -0.07837845807790608, 0.07837845807790636, 0.23320543647265504, 0.382290123056968]\n",
      "--- 83 ---\n",
      "[-0.3822901230569723, -0.2332054364726503, -0.07837845807790608, 0.07837845807790636, 0.23320543647265504, 0.382290123056968, 0.5219615580634471]\n",
      "--- 84 ---\n",
      "[-0.2332054364726503, -0.07837845807790608, 0.07837845807790636, 0.23320543647265504, 0.382290123056968, 0.5219615580634471, 0.6487805672193047]\n",
      "--- 85 ---\n",
      "[-0.07837845807790608, 0.07837845807790636, 0.23320543647265504, 0.382290123056968, 0.5219615580634471, 0.6487805672193047, 0.7596244456309721]\n",
      "--- 86 ---\n",
      "[0.07837845807790636, 0.23320543647265504, 0.382290123056968, 0.5219615580634471, 0.6487805672193047, 0.7596244456309721, 0.8517638491422204]\n",
      "--- 87 ---\n",
      "[0.23320543647265504, 0.382290123056968, 0.5219615580634471, 0.6487805672193047, 0.7596244456309721, 0.8517638491422204, 0.9229299998454124]\n",
      "--- 88 ---\n",
      "[0.382290123056968, 0.5219615580634471, 0.6487805672193047, 0.7596244456309721, 0.8517638491422204, 0.9229299998454124, 0.9713705509233677]\n",
      "--- 89 ---\n",
      "[0.5219615580634471, 0.6487805672193047, 0.7596244456309721, 0.8517638491422204, 0.9229299998454124, 0.9713705509233677, 0.9958927352435578]\n",
      "--- 90 ---\n",
      "[0.6487805672193047, 0.7596244456309721, 0.8517638491422204, 0.9229299998454124, 0.9713705509233677, 0.9958927352435578, 0.9958927352435578]\n",
      "--- 91 ---\n",
      "[0.7596244456309721, 0.8517638491422204, 0.9229299998454124, 0.9713705509233677, 0.9958927352435578, 0.9958927352435578, 0.9713705509233843]\n",
      "--- 92 ---\n",
      "[0.8517638491422204, 0.9229299998454124, 0.9713705509233677, 0.9958927352435578, 0.9958927352435578, 0.9713705509233843, 0.9229299998454127]\n",
      "--- 93 ---\n",
      "[0.9229299998454124, 0.9713705509233677, 0.9958927352435578, 0.9958927352435578, 0.9713705509233843, 0.9229299998454127, 0.8517638491422043]\n",
      "--- 94 ---\n",
      "[0.9713705509233677, 0.9958927352435578, 0.9958927352435578, 0.9713705509233843, 0.9229299998454127, 0.8517638491422043, 0.7596244456309726]\n",
      "--- 95 ---\n",
      "[0.9958927352435578, 0.9958927352435578, 0.9713705509233843, 0.9229299998454127, 0.8517638491422043, 0.7596244456309726, 0.648780567219317]\n",
      "--- 96 ---\n",
      "[0.9958927352435578, 0.9713705509233843, 0.9229299998454127, 0.8517638491422043, 0.7596244456309726, 0.648780567219317, 0.5219615580634431]\n",
      "--- 97 ---\n",
      "[0.9713705509233843, 0.9229299998454127, 0.8517638491422043, 0.7596244456309726, 0.648780567219317, 0.5219615580634431, 0.38229012305696897]\n",
      "--- 98 ---\n",
      "[0.9229299998454127, 0.8517638491422043, 0.7596244456309726, 0.648780567219317, 0.5219615580634431, 0.38229012305696897, 0.23320543647264907]\n",
      "--- 99 ---\n",
      "[0.8517638491422043, 0.7596244456309726, 0.648780567219317, 0.5219615580634431, 0.38229012305696897, 0.23320543647264907, 0.07837845807790747]\n",
      "--- 100 ---\n",
      "[0.7596244456309726, 0.648780567219317, 0.5219615580634431, 0.38229012305696897, 0.23320543647264907, 0.07837845807790747, -0.07837845807790762]\n",
      "--- 101 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.648780567219317, 0.5219615580634431, 0.38229012305696897, 0.23320543647264907, 0.07837845807790747, -0.07837845807790762, -0.233205436472653]\n",
      "--- 102 ---\n",
      "[0.5219615580634431, 0.38229012305696897, 0.23320543647264907, 0.07837845807790747, -0.07837845807790762, -0.233205436472653, -0.3822901230569676]\n",
      "--- 103 ---\n",
      "[0.38229012305696897, 0.23320543647264907, 0.07837845807790747, -0.07837845807790762, -0.233205436472653, -0.3822901230569676, -0.5219615580634471]\n",
      "--- 104 ---\n",
      "[0.23320543647264907, 0.07837845807790747, -0.07837845807790762, -0.233205436472653, -0.3822901230569676, -0.5219615580634471, -0.6487805672193048]\n",
      "--- 105 ---\n",
      "[0.07837845807790747, -0.07837845807790762, -0.233205436472653, -0.3822901230569676, -0.5219615580634471, -0.6487805672193048, -0.7596244456309853]\n",
      "--- 106 ---\n",
      "[-0.07837845807790762, -0.233205436472653, -0.3822901230569676, -0.5219615580634471, -0.6487805672193048, -0.7596244456309853, -0.8517638491422065]\n",
      "--- 107 ---\n",
      "[-0.233205436472653, -0.3822901230569676, -0.5219615580634471, -0.6487805672193048, -0.7596244456309853, -0.8517638491422065, -0.9229299998454122]\n",
      "--- 108 ---\n",
      "[-0.3822901230569676, -0.5219615580634471, -0.6487805672193048, -0.7596244456309853, -0.8517638491422065, -0.9229299998454122, -0.9713705509233677]\n",
      "--- 109 ---\n",
      "[-0.5219615580634471, -0.6487805672193048, -0.7596244456309853, -0.8517638491422065, -0.9229299998454122, -0.9713705509233677, -0.9958927352435577]\n",
      "--- 110 ---\n",
      "[-0.6487805672193048, -0.7596244456309853, -0.8517638491422065, -0.9229299998454122, -0.9713705509233677, -0.9958927352435577, -0.9958927352435754]\n",
      "--- 111 ---\n",
      "[-0.7596244456309853, -0.8517638491422065, -0.9229299998454122, -0.9713705509233677, -0.9958927352435577, -0.9958927352435754, -0.9713705509233667]\n",
      "--- 112 ---\n",
      "[-0.8517638491422065, -0.9229299998454122, -0.9713705509233677, -0.9958927352435577, -0.9958927352435754, -0.9713705509233667, -0.9229299998454127]\n",
      "--- 113 ---\n",
      "[-0.9229299998454122, -0.9713705509233677, -0.9958927352435577, -0.9958927352435754, -0.9713705509233667, -0.9229299998454127, -0.8517638491422046]\n",
      "--- 114 ---\n",
      "[-0.9713705509233677, -0.9958927352435577, -0.9958927352435754, -0.9713705509233667, -0.9229299998454127, -0.8517638491422046, -0.7596244456309726]\n",
      "--- 115 ---\n",
      "[-0.9958927352435577, -0.9958927352435754, -0.9713705509233667, -0.9229299998454127, -0.8517638491422046, -0.7596244456309726, -0.6487805672193172]\n",
      "--- 116 ---\n",
      "[-0.9958927352435754, -0.9713705509233667, -0.9229299998454127, -0.8517638491422046, -0.7596244456309726, -0.6487805672193172, -0.5219615580634432]\n",
      "--- 117 ---\n",
      "[-0.9713705509233667, -0.9229299998454127, -0.8517638491422046, -0.7596244456309726, -0.6487805672193172, -0.5219615580634432, -0.38229012305696886]\n",
      "--- 118 ---\n",
      "[-0.9229299998454127, -0.8517638491422046, -0.7596244456309726, -0.6487805672193172, -0.5219615580634432, -0.38229012305696886, -0.2332054364726489]\n",
      "--- 119 ---\n",
      "[-0.8517638491422046, -0.7596244456309726, -0.6487805672193172, -0.5219615580634432, -0.38229012305696886, -0.2332054364726489, -0.07837845807790753]\n",
      "--- 120 ---\n",
      "[-0.7596244456309726, -0.6487805672193172, -0.5219615580634432, -0.38229012305696886, -0.2332054364726489, -0.07837845807790753, 0.0783784580779074]\n",
      "--- 121 ---\n",
      "[-0.6487805672193172, -0.5219615580634432, -0.38229012305696886, -0.2332054364726489, -0.07837845807790753, 0.0783784580779074, 0.23320543647265335]\n",
      "--- 122 ---\n",
      "[-0.5219615580634432, -0.38229012305696886, -0.2332054364726489, -0.07837845807790753, 0.0783784580779074, 0.23320543647265335, 0.3822901230569675]\n",
      "--- 123 ---\n",
      "[-0.38229012305696886, -0.2332054364726489, -0.07837845807790753, 0.0783784580779074, 0.23320543647265335, 0.3822901230569675, 0.5219615580634468]\n",
      "--- 124 ---\n",
      "[-0.2332054364726489, -0.07837845807790753, 0.0783784580779074, 0.23320543647265335, 0.3822901230569675, 0.5219615580634468, 0.6487805672193048]\n",
      "--- 125 ---\n",
      "[-0.07837845807790753, 0.0783784580779074, 0.23320543647265335, 0.3822901230569675, 0.5219615580634468, 0.6487805672193048, -1.864616142890283]\n",
      "--- 126 ---\n",
      "[0.0783784580779074, 0.23320543647265335, 0.3822901230569675, 0.5219615580634468, 0.6487805672193048, -1.864616142890283, 0.0]\n",
      "--- 127 ---\n",
      "[0.23320543647265335, 0.3822901230569675, 0.5219615580634468, 0.6487805672193048, -1.864616142890283, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "x = arange(0, 2 * np.pi, 1/20)\n",
    "t = arange(0, 2 * np.pi, 1/20)\n",
    "X,T = meshgrid(x, t) # grid of point\n",
    "Z = heat_equ_analytical_solu(X, T) # evaluation of the function on the grid\n",
    "calc_next_time(x, t, 1/20, 1/20, Z[0], ResNet(7, 6, 6, 1, twolayers=False), length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_the_model(delta_x=1/20, delta_t=1/20, xmin=0, ymin=0, xmax=2 * np.pi, ymax=2 * np.pi,\n",
    "                      padding_num=3, hidden=6, twolayers=False, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False,\n",
    "                      model_name=\"model_xx delta x=1 20 delta t=1 20\"):\n",
    "    x = arange(xmin, xmax, delta_x)\n",
    "    t = arange(ymin, ymax, delta_y)\n",
    "    print(\"Generating meshes...\")\n",
    "    X,T = meshgrid(x, t) # grid of point\n",
    "    print(\"Generating analytical solution...\")\n",
    "    Z = heat_equ_analytical_solu(X, T) # evaluation of the function on the grid\n",
    "    print(\"Preparing the model and the optimizer...\")\n",
    "    model = ResNet(7, hidden, hidden, 1, twolayers=twolayers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    print(\"Updating data...\")\n",
    "    model.load_model(model_name)\n",
    "    prediction = []\n",
    "    prediction.append(torch.FloatTensor(Z[0]).tolist())\n",
    "    for i in range(len(Z)-1):\n",
    "        prediction.append(calc_next_time(x, t, delta_x, delta_t, Z[i], model))\n",
    "        print(\"time\", i, \"is done\", '\", an example is:\"', prediction[i+1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
